<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>学习笔记记录感悟</title>
  
  <subtitle>不乱于心，不困于情，不念过往，不畏将来。</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2024-11-29T17:06:27.581Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Jack Zhu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>秋招面试总结分享</title>
    <link href="http://example.com/2024/11/30/%E7%A7%8B%E6%8B%9B%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93%E5%88%86%E4%BA%AB/"/>
    <id>http://example.com/2024/11/30/%E7%A7%8B%E6%8B%9B%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93%E5%88%86%E4%BA%AB/</id>
    <published>2024-11-30T00:27:37.000Z</published>
    <updated>2024-11-29T17:06:27.581Z</updated>
    
    <content type="html"><![CDATA[<p>秋招基本也结束了，这里对整个过程进行复盘和总结，也是提前备战明年的春招。</p><h1 id="面试前的内容"><a href="#面试前的内容" class="headerlink" title="面试前的内容"></a>面试前的内容</h1><p>对于算法和开发的选择，我还是选择了算法，他们都说算法要有顶会，但是其实这个因素影响没有那么大的，我觉得不一定需要顶会，但是论文还是要有的，毕竟算法岗。没有顶会的情况下最重要的就是实习了，实习一定要把握住，这个可比顶会好拿到多了。我看往前几届的师兄师姐都去的开发岗，基本都是Java，但是这块我又不擅长，突击几个月还不一定有本科生学的好，干脆all in 算法了。毕竟算法还是比开发高很多的，还是可以冲下的。</p><p>对于算法的准备，主要从以下几个方面展开，大致有力扣，简历，实习，秋招等。</p><h2 id="力扣"><a href="#力扣" class="headerlink" title="力扣"></a>力扣</h2><p>力扣这是最基本的准备，毕竟除了人才计划，其他无论算法开发岗位都有力扣的考察，所以这个是一定要准备的。力扣的内容基本刷几遍hot100就差不多了，基本面试的手撕都是hot100这个难度，基本从前一年的12月就可以开始每天一道题了，开始的时候会很慢，后面慢慢熟练了就快了。之所以要开始这么早是因为实习是第二年三月就开始了，提前三个月准备刷题还是有必要的。很多人刷300题，基本肯定是够用了，有的人甚至刷了600题，其实不是特别有必要，力扣题主要起到的是一个门槛的作用，笔试不过直接pass，过的情况下主要看面试了。</p><h2 id="简历"><a href="#简历" class="headerlink" title="简历"></a>简历</h2><p>简历是非常重要的，决定了简历筛选后面能不能进笔试和面试，我简历凑合吧，投了90家，进面大概30家，正常水平吧。简历一般是先教育经历，之后最好是要有实习经历，然后是论文和科研部分，后面是项目可以放几个，后面是比赛获奖那些，主体就这些吧，具体根据不同人，优势不同，做的好的放前面一些。根据篇幅，后面可以加一些个人技能，比如编程语言和计算机工具比如git什么的掌握情况，最后篇幅不够可以放自我评价，这个不是必须，可有可无。</p><p>对于简历是一页还是两页，我看不同HR喜好并不同，有的认为一页简单明了，有的觉得一页太单薄。总之校招一般不超过两页（博士除外），实际来看如果确实有内容建议充实两页，排版不要过于空旷，适当紧凑一些。</p><h1 id="面试内容"><a href="#面试内容" class="headerlink" title="面试内容"></a>面试内容</h1><p>一般一面或者二面技术面，自我介绍之后，如果有比较有含金量的实习或者论文会先讲这部分，之后会问项目之类的，之后有的会问一些八股，这个八股有的是算法八股比如transformer、CNN、RNN卷积等什么的，这块需要背下。有的会问到计算机基础比如进程线程还有python基础比如装饰器，线程锁啥的，这块只是有时候会问到。</p><p>然后就是面试中的手撕了，这个不是必须，有的面试会有手撕，这个因岗位和公司不同，手撕大部分是力扣，当然也有例外，比如淘天，投实习的时候手撕是手写多头注意力，交叉熵等题目，还有k-means的，这个不提前准备的话想快速写出来也不太容易。比如华子正式面试二面就出了个数字图像处理的手撕，很难，就蚌埠住了，这种题不多见。</p><p>技术面之后一般主管面，这块可能的问题很多，从个人信息到家里情况，到抗压测试，了解新信息的途径，其他还有比如人工智能对各行各业的影响，大模型在不同行业的应用，甚至包括盈利模式啥的等产品问题，不同的侧重点也不同，需要随机应变。这个部分不可小视，相关问题要整理下，大致想想如何回答。有的公司比如华子是技术面了可以捞，但是主管面挂了就不行。</p><h2 id="实习"><a href="#实习" class="headerlink" title="实习"></a>实习</h2><p>实习的重要程度可以说是第一了，毕竟一般如果组内条件不具备的话，是发不出来顶会的，尤其对于硕士，所以实习就成为了性价比最高而且最可以获取到的了。</p><p>准备实习第一步是要提前刷力扣题，然后准备简历润色，之后到三月下实习基本就开始了，四五月是最主要的时间，六月基本就不多了，建议尽早投递，一般越早越容易拿到offer，前期看哪些先开，最开始的可以不投特别大的厂，因为没有相关经验，如果面的很差的话确实会影响面评，影响后面，不过大部分好像影响不大的，可以先从小厂开始，虽然很多时候大厂先开。在面试的过程中不断复盘，总结经验，不断提高，投递尽量不要拖太后，后面很多没有hc，即使准备的好也没用了。</p><p>我前面投递实习的时候技术面其实不会特别难，不过也有例外，比如淘天的，还有腾讯AILab这种，不过多面还是有好处的，对于秋招面试也是积累经验的过程。</p><p>如果实在没有实习经历，也是可以把一些横向的项目加进去，包括校企合作，实践活动，这种有的也是算实习的。</p><p>实习看能不能转正，如果能转正就要好好准备，不能的话就趁早想想后路，实习的经历如何整理成体系，面试的时候问答到相关的问题如何回答，把工作点整理好，面试的时候就不慌。</p><h2 id="秋招"><a href="#秋招" class="headerlink" title="秋招"></a>秋招</h2><p>如果有实习的话一般八九月就要回去准备秋招了，除非对自己非常自信能实习转正。对于有实习的有经历，但是秋招的准备会少一些时间，因为实习很多时候也挺忙的，个别实习好像能直接在公司刷力扣，不过这种极少，看部门和主管。没有实习的人秋招七八月的时候有比较完整的时间准备秋招的内容比如力扣八股，把项目好好复盘。</p><p>建议还是尽早投递，确实是越早越容易，所以早点开始准备秋招的时候就可以占有不少优势，前后期难度确实不同，基本上八月份面试的都容易进。然后整理一个表格，不同公司的啥时候开始投递，有些相关的群要关注下，有的学长学姐会进行整理，自己这个表格记录好公司、投递时间、岗位、base地，笔试面试情况和时间啥的，方便自己查看。</p><h1 id="算法方向"><a href="#算法方向" class="headerlink" title="算法方向"></a>算法方向</h1><p>对于算法方向，主要从以下几个方向展开。</p><h2 id="视觉方向"><a href="#视觉方向" class="headerlink" title="视觉方向"></a>视觉方向</h2><p>这个方向也是前面做的人最多的方向，虽然很多人现在做的还是视觉的项目或者科研，但是确实不建议用这个来找工作，除非你能发CCF-C及以上的论文吧，虽然C也很勉强。现在视觉的岗位太少了，所以必须是做的比较深，有一定的研究才行，不然相关的算法都很成熟了，不太好用来找工作。</p><p>以下是两个半可以做的方向，说是两个半是因为第三个方向部署推理这块的hc远远不如前面两个的。</p><h2 id="大模型"><a href="#大模型" class="headerlink" title="大模型"></a>大模型</h2><p>这个方向是目前算法最好找工作的方向了，大语言模型和AIGC这块的需求很多。很多人都说自己没做过，可问题是22年11月底ChatGPT出来之前，有几个人是做大模型的？现在做大模型的人99.9%的都是大模型出来之后开始学的，这块的上手门槛没有那么高的。很多人准备一两个月做一个大致像样的项目，用来参加比如书生浦语，或者阿里这种的大模型比赛，差不多获奖就可以拿来简历用了，只要被问到的时候能讲清楚就还是可以的。现在各行各业都在用大模型做一遍，仍然是个可以做的风口，虽然风口过去并不知道能做成啥样，但是这几年自己能赚到就可以了。、</p><p>学习这个并不需要一上来直接看论文，看看相关的项目，和一些相对比较容易的开源课程，先上手了解整个体系，然后尝试做个玩具微调下，之后再去认真研究，是个比较好的学习方法。</p><h2 id="搜广推"><a href="#搜广推" class="headerlink" title="搜广推"></a>搜广推</h2><p>这个方向作为互联网的基础，有非常稳定的基础，但是对于应届生来说学校期间往往不做这块的内容，不过要是突击两个月还是可以做下的，不算特别热，但是hc还可以，互联网都招。</p><h2 id="部署推理"><a href="#部署推理" class="headerlink" title="部署推理"></a>部署推理</h2><p>这个方向涉及模型的量化、剪枝、蒸馏、推理、部署、推理框架、推理引擎，还要AI Infra这些，这些方向其实还是可以做的，尤其现在大模型落地对这块的需求还是不少的，即使不是大模型的部署，小模型的部署也是有需求的。不过这块就要深挖下了，很多时候涉及C++，难度就上来了，不过这块的hc数就远比不上前面了，而且相对不太好转方向，有的开的价还可以，有的不如算法，但是还是比开发高的，也算是一个可以尝试的方向。tensorrt、ncnn、tvm、onnnx，还有vllm、turbomind、triton这些都是可以学习的。</p><h2 id="面试内容总结"><a href="#面试内容总结" class="headerlink" title="面试内容总结"></a>面试内容总结</h2><blockquote><h1 id="简历学习内容"><a href="#简历学习内容" class="headerlink" title="简历学习内容"></a>简历学习内容</h1><h2 id="大模型-1"><a href="#大模型-1" class="headerlink" title="大模型"></a>大模型</h2><h3 id="实习相关"><a href="#实习相关" class="headerlink" title="实习相关"></a>实习相关</h3><h4 id="实验评价指标"><a href="#实验评价指标" class="headerlink" title="实验评价指标"></a>实验评价指标</h4><ul><li>正则匹配如何做的</li><li>类别非常不均的情况下 <code>acc</code> 指标是否足够，不足使用了什么</li><li>语义理解的评价指标</li><li>具体指标</li><li>为什么这样用</li><li>这一指标达到多少，什么意义</li><li><code>badcase</code> 有多少，是什么原因，如何处理的</li></ul><h4 id="如何根据实验结果调整-prompt"><a href="#如何根据实验结果调整-prompt" class="headerlink" title="如何根据实验结果调整 prompt"></a>如何根据实验结果调整 <code>prompt</code></h4><h4 id="数据构造"><a href="#数据构造" class="headerlink" title="数据构造"></a>数据构造</h4><ul><li>数据量</li><li>构造方法</li><li>实际上下文长度是多少</li><li>数据截断是什么问题</li></ul><h4 id="数据如何标注的"><a href="#数据如何标注的" class="headerlink" title="数据如何标注的"></a>数据如何标注的</h4><ul><li>真值从哪里来</li><li>标注的数据有什么问题</li></ul><h4 id="采用大模型而不是之前的机器学习方法的意义、优点"><a href="#采用大模型而不是之前的机器学习方法的意义、优点" class="headerlink" title="采用大模型而不是之前的机器学习方法的意义、优点"></a>采用大模型而不是之前的机器学习方法的意义、优点</h4><h4 id="改进和上线所需措施"><a href="#改进和上线所需措施" class="headerlink" title="改进和上线所需措施"></a>改进和上线所需措施</h4><ul><li>模型是否满足上线需要</li><li>如果不满足是因为什么，效果或速度还是其他</li><li>上线需要解决其他什么问题，后续需要做什么</li></ul><h3 id="相关理论"><a href="#相关理论" class="headerlink" title="相关理论"></a>相关理论</h3><ul><li>主流的大模型参数、量级、结构、最大上下文长度，如何选取<ul><li>Llama 系列</li><li>千问</li><li>盘古智子</li><li>chatglm</li><li>internlm</li><li>其他</li><li>openai o1</li></ul></li><li>大模型评测方法</li><li>CoT 和实习中的应用</li><li>微调方法<ul><li>LoRA、QLoRA 等多种方法<ul><li>多头 LoRA</li><li>LoRA</li><li>QLoRA</li></ul></li><li>训练了哪些层</li><li>设置了哪些超参数，如 <code>r</code>、 <code>alpha</code>等</li><li>如何根据实际情况调整这些参数</li></ul></li><li>分布式训练方法<ul><li>deepspeed</li><li>zero</li></ul></li></ul><h3 id="RAG-相关"><a href="#RAG-相关" class="headerlink" title="RAG 相关"></a>RAG 相关</h3><ul><li>原理</li><li>解决什么问题，为什么用 RAG</li><li>RAG 的向量表征方法都有哪些，怎么做的</li></ul><h3 id="视觉"><a href="#视觉" class="headerlink" title="视觉"></a>视觉</h3><h4 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h4><ul><li>模型<ul><li>YOLOv1~v11</li><li>各代演进和区别</li><li>总体发展理论</li><li>DETR 等无 <code>nms</code> 的模型</li></ul></li><li>模型架构<ul><li>主干网络的变化和区别</li><li>金字塔融合方式的多种</li><li>中间模块和处理方法</li></ul></li><li>图像增强<ul><li>一般的几种</li><li>mosaic 等多种方法</li></ul></li><li>量化<ul><li>量化方法</li><li>参数量</li><li>速度精度</li></ul></li><li>剪枝<ul><li>方法</li><li>对网络什么部分进行剪枝</li><li>参数量变化</li><li>速度变化</li></ul></li><li>CPP 部分主要包括哪些<ul><li>具体这部分如何用的</li></ul></li></ul><h4 id="人脸识别"><a href="#人脸识别" class="headerlink" title="人脸识别"></a>人脸识别</h4><ul><li>人脸识别和检测部分</li><li>构建索引和检索理论</li><li>向量表征</li><li>相似度检索</li><li>活体识别</li></ul><h3 id="算法八股"><a href="#算法八股" class="headerlink" title="算法八股"></a>算法八股</h3><h4 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h4><ul><li>Transformer 模型讲解</li><li>LayerNorm 等多种 <code>norm</code> 方式如 BatchNorm</li><li>Encoder 和 Decoder 相关</li><li>RNN、LSTM、Transformer 变化</li><li>大模型中激活函数等多种常用的结构<ul><li>GQA</li><li>MQA</li><li>RMSNorm</li><li>SwiGLU</li><li>RoPE</li></ul></li><li>激活函数<ul><li>ReLU</li><li>Leaky ReLU</li><li>GELU</li><li>tanh</li><li>sigmoid</li><li>swish</li><li>ELU</li></ul></li><li>特征工程包括什么，如何做<ul><li>常见的数据预处理方法有哪些</li></ul></li><li>分布式数据处理原理（如 Hadoop）</li><li>计算机理论相关（如堆和栈的区别）</li></ul><h4 id="手撕"><a href="#手撕" class="headerlink" title="手撕"></a>手撕</h4><ul><li>Transformer</li><li>注意力</li><li>LayerNorm</li><li>KMeans</li><li>NMS</li><li>IOU 计算</li></ul></blockquote><h1 id="最后补个学习的内容：算法工程师面试常考手撕题"><a href="#最后补个学习的内容：算法工程师面试常考手撕题" class="headerlink" title="最后补个学习的内容：算法工程师面试常考手撕题"></a>最后补个学习的内容：算法工程师面试常考手撕题</h1><p>引用链接<a href="https://mp.weixin.qq.com/s/TAFvUlqdyqP-W6C10F1Hzw">https://mp.weixin.qq.com/s/TAFvUlqdyqP-W6C10F1Hzw</a></p><ul><li>算法工程师面试常考手撕题<ul><li>注意力（Attention）篇<ul><li>手撕单头注意力机制（ScaledDotProductAttention）函数</li><li>手撕多头注意力（MultiHeadAttention）</li><li>手撕自注意力机制函数（SelfAttention）</li></ul></li><li>基础机器学习算法篇<ul><li>手撕 k-means 算法</li></ul></li><li>手撕 Layer Normalization 算法</li><li>手撕 Batch Normalization 算法</li><li>解码算法篇<ul><li>手撕 贪心搜索 （greedy search）</li></ul></li><li>神经网络篇<ul><li>手撕 卷积神经网络(CNN)法</li><li>手撕 二维卷积 算法</li></ul></li><li>位置编码篇<ul><li>手撕 绝对位置编码 算法</li><li>手撕 可学习位置编码 算法</li><li>手撕 相对位置编码 算法</li><li>手撕 rope 算法</li></ul></li><li>面试题汇总</li><li>致谢</li></ul></li></ul><h2 id="注意力（Attention）篇"><a href="#注意力（Attention）篇" class="headerlink" title="注意力（Attention）篇"></a><strong>注意力（Attention）篇</strong></h2><h3 id="手撕单头注意力机制（ScaledDotProductAttention）函数"><a href="#手撕单头注意力机制（ScaledDotProductAttention）函数" class="headerlink" title="手撕单头注意力机制（ScaledDotProductAttention）函数"></a><strong>手撕单头注意力机制（ScaledDotProductAttention）函数</strong></h3><p>输入是query和 key-value，注意力机制首先计算query与每个key的关联性（compatibility），每个关联性作为每个value的权重（weight），各个权重与value的乘积相加得到输出。<br><img src="https://cdn.nlark.com/yuque/0/2024/jpeg/1574965/1714410444477-8e426dd3-37ed-473f-ab5f-7d445ed7592b.jpeg#clientId=u8884b877-175c-4&from=paste&id=u147acd2d&originHeight=75&originWidth=390&originalType=url&ratio=1&rotation=0&showTitle=false&size=4542&status=done&style=none&taskId=u5130429b-212c-4651-83d6-557bf8c86d9&title=" alt="image.jpg"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">class ScaledDotProductAttention(nn.Module):</span><br><span class="line">    &quot;&quot;&quot; Scaled Dot-Product Attention &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def __init__(self, scale):</span><br><span class="line">        super().__init__()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.scale = scale</span><br><span class="line">        self.softmax = nn.Softmax(dim=2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def forward(self, q, k, v, mask=None):</span><br><span class="line">        u = torch.bmm(q, k.transpose(1, 2)) # 1.Matmul</span><br><span class="line">        u = u / self.scale # 2.Scale</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        if mask is not None:</span><br><span class="line">            u = u.masked_fill(mask, -np.inf) # 3.Mask</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        attn = self.softmax(u) # 4.Softmax</span><br><span class="line">        output = torch.bmm(attn, v) # 5.Output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        return attn, output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    n_q, n_k, n_v = 2, 4, 4</span><br><span class="line">    d_q, d_k, d_v = 128, 128, 64</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    q = torch.randn(batch, n_q, d_q)</span><br><span class="line">    k = torch.randn(batch, n_k, d_k)</span><br><span class="line">    v = torch.randn(batch, n_v, d_v)</span><br><span class="line">    mask = torch.zeros(batch, n_q, n_k).bool()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    attention = ScaledDotProductAttention(scale=np.power(d_k, 0.5))</span><br><span class="line">    attn, output = attention(q, k, v, mask=mask)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    print(attn)</span><br><span class="line">    print(output)</span><br></pre></td></tr></table></figure><h3 id="手撕多头注意力（MultiHeadAttention）"><a href="#手撕多头注意力（MultiHeadAttention）" class="headerlink" title="手撕多头注意力（MultiHeadAttention）"></a><strong>手撕多头注意力（MultiHeadAttention）</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">class MultiHeadAttention(nn.Module):</span><br><span class="line">    &quot;&quot;&quot; Multi-Head Attention &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def __init__(self, n_head, d_k_, d_v_, d_k, d_v, d_o):</span><br><span class="line">        super().__init__()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.n_head = n_head</span><br><span class="line">        self.d_k = d_k</span><br><span class="line">        self.d_v = d_v</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.fc_q = nn.Linear(d_k_, n_head * d_k)</span><br><span class="line">        self.fc_k = nn.Linear(d_k_, n_head * d_k)</span><br><span class="line">        self.fc_v = nn.Linear(d_v_, n_head * d_v)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.attention = ScaledDotProductAttention(scale=np.power(d_k, 0.5))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.fc_o = nn.Linear(n_head * d_v, d_o)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def forward(self, q, k, v, mask=None):</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        n_head, d_q, d_k, d_v = self.n_head, self.d_k, self.d_k, self.d_v</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        batch, n_q, d_q_ = q.size()</span><br><span class="line">        batch, n_k, d_k_ = k.size()</span><br><span class="line">        batch, n_v, d_v_ = v.size()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        q = self.fc_q(q) # 1.单头变多头</span><br><span class="line">        k = self.fc_k(k)</span><br><span class="line">        v = self.fc_v(v)</span><br><span class="line">        q = q.view(batch, n_q, n_head, d_q).permute(2, 0, 1, 3).contiguous().view(-1, n_q, d_q)</span><br><span class="line">        k = k.view(batch, n_k, n_head, d_k).permute(2, 0, 1, 3).contiguous().view(-1, n_k, d_k)</span><br><span class="line">        v = v.view(batch, n_v, n_head, d_v).permute(2, 0, 1, 3).contiguous().view(-1, n_v, d_v)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        if mask is not None:</span><br><span class="line">            mask = mask.repeat(n_head, 1, 1)</span><br><span class="line">        attn, output = self.attention(q, k, v, mask=mask) # 2.当成单头注意力求输出</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        output = output.view(n_head, batch, n_q, d_v).permute(1, 2, 0, 3).contiguous().view(batch, n_q, -1) # 3.Concat</span><br><span class="line">        output = self.fc_o(output) # 4.仿射变换得到最终输出</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        return attn, output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    n_q, n_k, n_v = 2, 4, 4</span><br><span class="line">    d_q_, d_k_, d_v_ = 128, 128, 64</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    q = torch.randn(batch, n_q, d_q_)</span><br><span class="line">    k = torch.randn(batch, n_k, d_k_)</span><br><span class="line">    v = torch.randn(batch, n_v, d_v_)    </span><br><span class="line">    mask = torch.zeros(batch, n_q, n_k).bool()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    mha = MultiHeadAttention(n_head=8, d_k_=128, d_v_=64, d_k=256, d_v=128, d_o=128)</span><br><span class="line">    attn, output = mha(q, k, v, mask=mask)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    print(attn.size())</span><br><span class="line">    print(output.size())</span><br></pre></td></tr></table></figure><h3 id="手撕自注意力机制函数（SelfAttention）"><a href="#手撕自注意力机制函数（SelfAttention）" class="headerlink" title="手撕自注意力机制函数（SelfAttention）"></a><strong>手撕自注意力机制函数（SelfAttention）</strong></h3><p>Self-Attention。和Attention类似，他们都是一种注意力机制。不同的是Attention是source对target，输入的source和输出的target内容不同。例如英译中，输入英文，输出中文。而Self-Attention是source对source，是source内部元素之间或者target内部元素之间发生的Attention机制，也可以理解为Target&#x3D;Source这种特殊情况下的注意力机制。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">class SelfAttention(nn.Module):</span><br><span class="line">    &quot;&quot;&quot; Self-Attention &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def __init__(self, n_head, d_k, d_v, d_x, d_o):</span><br><span class="line">        self.wq = nn.Parameter(torch.Tensor(d_x, d_k))</span><br><span class="line">        self.wk = nn.Parameter(torch.Tensor(d_x, d_k))</span><br><span class="line">        self.wv = nn.Parameter(torch.Tensor(d_x, d_v))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.mha = MultiHeadAttention(n_head=n_head, d_k_=d_k, d_v_=d_v, d_k=d_k, d_v=d_v, d_o=d_o)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.init_parameters()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def init_parameters(self):</span><br><span class="line">        for param in self.parameters():</span><br><span class="line">            stdv = 1. / np.power(param.size(-1), 0.5)</span><br><span class="line">            param.data.uniform_(-stdv, stdv)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def forward(self, x, mask=None):</span><br><span class="line">        q = torch.matmul(x, self.wq)   </span><br><span class="line">        k = torch.matmul(x, self.wk)</span><br><span class="line">        v = torch.matmul(x, self.wv)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        attn, output = self.mha(q, k, v, mask=mask)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        return attn, output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    n_x = 4</span><br><span class="line">    d_x = 80</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    x = torch.randn(batch, n_x, d_x)</span><br><span class="line">    mask = torch.zeros(batch, n_x, n_x).bool()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    selfattn = SelfAttention(n_head=8, d_k=128, d_v=64, d_x=80, d_o=80)</span><br><span class="line">    attn, output = selfattn(x, mask=mask)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    print(attn.size())</span><br><span class="line">    print(output.size())</span><br></pre></td></tr></table></figure><h2 id="基础机器学习算法篇"><a href="#基础机器学习算法篇" class="headerlink" title="基础机器学习算法篇"></a><strong>基础机器学习算法篇</strong></h2><h3 id="手撕-k-means-算法"><a href="#手撕-k-means-算法" class="headerlink" title="手撕 k-means 算法"></a><strong>手撕 k-means 算法</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">def kmeans(data, k, thresh=1, max_iterations=100):</span><br><span class="line">  # 随机初始化k个中心点</span><br><span class="line">  centers = data[np.random.choice(data.shape[0], k, replace=False)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  for _ in range(max_iterations):</span><br><span class="line">    # 计算每个样本到各个中心点的距离</span><br><span class="line">    distances = np.linalg.norm(data[:, None] - centers, axis=2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 根据距离最近的中心点将样本分配到对应的簇</span><br><span class="line">    labels = np.argmin(distances, axis=1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 更新中心点为每个簇的平均值</span><br><span class="line">    new_centers = np.array([data[labels == i].mean(axis=0) for i in range(k)])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 判断中心点是否收敛，多种收敛条件可选</span><br><span class="line">    # 条件1：中心点不再改变</span><br><span class="line">    if np.all(centers == new_centers):</span><br><span class="line">      break</span><br><span class="line">    # 条件2：中心点的阈值小于某个阈值</span><br><span class="line">    # center_change = np.linalg.norm(new_centers - centers)</span><br><span class="line">    # if center_change &lt; thresh:</span><br><span class="line">    #     break</span><br><span class="line">    centers = new_centers</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  return labels, centers</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 生成一些随机数据作为示例输入</span><br><span class="line">data = np.random.rand(100, 2)  # 100个样本，每个样本有两个特征</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 手动实现K均值算法</span><br><span class="line">k = 3  # 聚类数为3</span><br><span class="line">labels, centers = kmeans(data, k)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 打印簇标签和聚类中心点</span><br><span class="line">print(&quot;簇标签:&quot;, labels)</span><br><span class="line">print(&quot;聚类中心点:&quot;, centers)</span><br></pre></td></tr></table></figure><h2 id="手撕-Layer-Normalization-算法"><a href="#手撕-Layer-Normalization-算法" class="headerlink" title="手撕 Layer Normalization 算法"></a><strong>手撕 Layer Normalization 算法</strong></h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torch import nn</span><br><span class="line"> </span><br><span class="line">class LN(nn.Module):</span><br><span class="line">    # 初始化</span><br><span class="line">    def __init__(self, normalized_shape,  # 在哪个维度上做LN</span><br><span class="line">                 eps:float = 1e-5, # 防止分母为0</span><br><span class="line">                 elementwise_affine:bool = True):  # 是否使用可学习的缩放因子和偏移因子</span><br><span class="line">        super(LN, self).__init__()</span><br><span class="line">        # 需要对哪个维度的特征做LN, torch.size查看维度</span><br><span class="line">        self.normalized_shape = normalized_shape  # [c,w*h]</span><br><span class="line">        self.eps = eps</span><br><span class="line">        self.elementwise_affine = elementwise_affine</span><br><span class="line">        # 构造可训练的缩放因子和偏置</span><br><span class="line">        if self.elementwise_affine:  </span><br><span class="line">            self.gain = nn.Parameter(torch.ones(normalized_shape))  # [c,w*h]</span><br><span class="line">            self.bias = nn.Parameter(torch.zeros(normalized_shape))  # [c,w*h]</span><br><span class="line"> </span><br><span class="line">    # 前向传播</span><br><span class="line">    def forward(self, x: torch.Tensor): # [b,c,w*h]</span><br><span class="line">        # 需要做LN的维度和输入特征图对应维度的shape相同</span><br><span class="line">        assert self.normalized_shape == x.shape[-len(self.normalized_shape):]  # [-2:]</span><br><span class="line">        # 需要做LN的维度索引</span><br><span class="line">        dims = [-(i+1) for i in range(len(self.normalized_shape))]  # [b,c,w*h]维度上取[-1,-2]维度，即[c,w*h]</span><br><span class="line">        # 计算特征图对应维度的均值和方差</span><br><span class="line">        mean = x.mean(dim=dims, keepdims=True)  # [b,1,1]</span><br><span class="line">        mean_x2 = (x**2).mean(dim=dims, keepdims=True)  # [b,1,1]</span><br><span class="line">        var = mean_x2 - mean**2  # [b,c,1,1]</span><br><span class="line">        x_norm = (x-mean) / torch.sqrt(var+self.eps)  # [b,c,w*h]</span><br><span class="line">        # 线性变换</span><br><span class="line">        if self.elementwise_affine:</span><br><span class="line">            x_norm = self.gain * x_norm + self.bias  # [b,c,w*h]</span><br><span class="line">        return x_norm</span><br><span class="line"> </span><br><span class="line"># ------------------------------- #</span><br><span class="line"># 验证</span><br><span class="line"># ------------------------------- #</span><br><span class="line"> </span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line"> </span><br><span class="line">    x = torch.linspace(0, 23, 24, dtype=torch.float32)  # 构造输入层</span><br><span class="line">    x = x.reshape([2,3,2*2])  # [b,c,w*h]</span><br><span class="line">    # 实例化</span><br><span class="line">    ln = LN(x.shape[1:])</span><br><span class="line">    # 前向传播</span><br><span class="line">    x = ln(x)</span><br><span class="line">    print(x.shape)</span><br></pre></td></tr></table></figure><h3 id="手撕-Batch-Normalization-算法"><a href="#手撕-Batch-Normalization-算法" class="headerlink" title="手撕 Batch Normalization 算法"></a><strong>手撕 Batch Normalization 算法</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">class MyBN:</span><br><span class="line">    def __init__(self, momentum=0.01, eps=1e-5, feat_dim=2):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        初始化参数值</span><br><span class="line">        :param momentum: 动量，用于计算每个batch均值和方差的滑动均值</span><br><span class="line">        :param eps: 防止分母为0</span><br><span class="line">        :param feat_dim: 特征维度</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 均值和方差的滑动均值</span><br><span class="line">        self._running_mean = np.zeros(shape=(feat_dim, ))</span><br><span class="line">        self._running_var = np.ones((shape=(feat_dim, ))</span><br><span class="line">        # 更新self._running_xxx时的动量</span><br><span class="line">        self._momentum = momentum</span><br><span class="line">        # 防止分母计算为0</span><br><span class="line">        self._eps = eps</span><br><span class="line">        # 对应Batch Norm中需要更新的beta和gamma，采用pytorch文档中的初始化值</span><br><span class="line">        self._beta = np.zeros(shape=(feat_dim, ))</span><br><span class="line">        self._gamma = np.ones(shape=(feat_dim, ))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def batch_norm(self, x):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        BN向传播</span><br><span class="line">        :param x: 数据</span><br><span class="line">        :return: BN输出</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        if self.training:</span><br><span class="line">            x_mean = x.mean(axis=0)</span><br><span class="line">            x_var = x.var(axis=0)</span><br><span class="line">            # 对应running_mean的更新公式</span><br><span class="line">            self._running_mean = (1-self._momentum)*x_mean + self._momentum*self._running_mean</span><br><span class="line">            self._running_var = (1-self._momentum)*x_var + self._momentum*self._running_var</span><br><span class="line">            # 对应论文中计算BN的公式</span><br><span class="line">            x_hat = (x-x_mean)/np.sqrt(x_var+self._eps)</span><br><span class="line">        else:</span><br><span class="line">            x_hat = (x-self._running_mean)/np.sqrt(self._running_var+self._eps)</span><br><span class="line">        return self._gamma*x_hat + self._beta</span><br></pre></td></tr></table></figure><h2 id="解码算法篇"><a href="#解码算法篇" class="headerlink" title="解码算法篇"></a><strong>解码算法篇</strong></h2><h3 id="手撕-贪心搜索-（greedy-search）"><a href="#手撕-贪心搜索-（greedy-search）" class="headerlink" title="手撕 贪心搜索 （greedy search）"></a><strong>手撕 贪心搜索 （greedy search）</strong></h3><p>贪心搜索（greedy search）在每个时间步 t 都选取当前概率分布中概率最大的词，即<br><img src="https://cdn.nlark.com/yuque/0/2024/jpeg/1574965/1714410444607-da855304-da72-4fa6-8f9b-fd9cf3440b94.jpeg#clientId=u8884b877-175c-4&from=paste&id=ud89f8e75&originHeight=59&originWidth=273&originalType=url&ratio=1&rotation=0&showTitle=false&size=2641&status=done&style=none&taskId=ub3f3a342-b73d-485d-8964-e14e29f56aa&title=" alt="image.jpg"><br>直到 yt 为或达到预设最大长度时停止生成。<br>贪心搜索本质上是局部最优策略，但并不能保证最终结果一定是全局最优的。由于贪心搜索在解码的任意时刻只保留一条候选序列，所以在搜索效率上，贪心搜索的复杂度显著低于穷举搜索。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def greedy_decoding(input_ids, max_tokens=300):</span><br><span class="line"> with torch.inference_mode():</span><br><span class="line"> for _ in range(max_tokens):</span><br><span class="line">            outputs = model(input_ids)</span><br><span class="line">            next_token_logits = outputs.logits[:, -1, :]</span><br><span class="line">            next_token = torch.argmax(next_token_logits, dim=-1)</span><br><span class="line"> if next_token == tokenizer.eos_token_id:</span><br><span class="line"> break</span><br><span class="line">            input_ids = torch.cat([input_ids, rearrange(next_token, &#x27;c -&gt; 1 c&#x27;)], dim=-1)</span><br><span class="line">        generated_text = tokenizer.decode(input_ids[0])</span><br><span class="line"> return generated_text</span><br></pre></td></tr></table></figure><h3 id="手撕-Top-K-Sampling算法"><a href="#手撕-Top-K-Sampling算法" class="headerlink" title="手撕 Top-K Sampling算法"></a><strong>手撕 Top-K Sampling算法</strong></h3><p>Top-K 采样（在每个时间步选择条件概率排名前 K 的词语，然后在这 K 个词语中进行随机采样。这种方法既能保持一定的生成质量，又能增加文本的多样性，并且可以通过限制候选词语的数量来控制生成文本的多样性。<br>这个过程使得生成的文本在保持一定的生成质量的同时，也具有一定的多样性，因为在候选词语中仍然存在一定的竞争性。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def top_k_sampling(input_ids, max_tokens=100, top_k=50, temperature=1.0):</span><br><span class="line"> for _ in range(max_tokens):</span><br><span class="line"> with torch.inference_mode():</span><br><span class="line">            outputs = model(input_ids)</span><br><span class="line">            next_token_logits = outputs.logits[:, -1, :]</span><br><span class="line">            top_k_logits, top_k_indices = torch.topk(next_token_logits, top_k)</span><br><span class="line">            top_k_probs = F.softmax(top_k_logits / temperature, dim=-1)</span><br><span class="line">            next_token_index = torch.multinomial(top_k_probs, num_samples=1)</span><br><span class="line">            next_token = top_k_indices.gather(-1, next_token_index)</span><br><span class="line">            input_ids = torch.cat([input_ids, next_token], dim=-1)</span><br><span class="line">    generated_text = tokenizer.decode(input_ids[0])</span><br><span class="line"> return generated_text</span><br></pre></td></tr></table></figure><h2 id="神经网络篇"><a href="#神经网络篇" class="headerlink" title="神经网络篇"></a><strong>神经网络篇</strong></h2><h3 id="手撕-卷积神经网络-CNN-法"><a href="#手撕-卷积神经网络-CNN-法" class="headerlink" title="手撕 卷积神经网络(CNN)法"></a><strong>手撕 卷积神经网络(CNN)法</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn.functional as F #使用functional中的ReLu激活函数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#CNN模型</span><br><span class="line">class CNNNet(torch.nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(CNNNet, self).__init__()</span><br><span class="line">        #两个卷积层</span><br><span class="line">        self.conv1 = torch.nn.Conv2d(1, 10, kernel_size=5)  #1为in_channels 10为out_channels</span><br><span class="line">        self.conv2 = torch.nn.Conv2d(10, 20, kernel_size=5)</span><br><span class="line">        #池化层</span><br><span class="line">        self.pooling = torch.nn.MaxPool2d(2)  #2为分组大小2*2</span><br><span class="line">        #全连接层 320 = 20 * 4 * 4</span><br><span class="line">        self.fc = torch.nn.Linear(320, 10)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        #先从x数据维度中得到batch_size</span><br><span class="line">        batch_size = x.size(0)</span><br><span class="line">        #卷积层-&gt;池化层-&gt;激活函数</span><br><span class="line">        x = F.relu(self.pooling(self.conv1(x)))</span><br><span class="line">        x = F.relu(self.pooling(self.conv2(x)))</span><br><span class="line">        x = x.view(batch_size, -1)  #将数据展开，为输入全连接层做准备</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        return x</span><br><span class="line">model = CNNNet()</span><br></pre></td></tr></table></figure><h3 id="手撕-二维卷积-算法"><a href="#手撕-二维卷积-算法" class="headerlink" title="手撕 二维卷积 算法"></a><strong>手撕 二维卷积 算法</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np </span><br><span class="line">def conv2d(img, in_channels, out_channels ,kernels, bias, stride=1, padding=0):</span><br><span class="line">    N, C, H, W = img.shape </span><br><span class="line">    kh, kw = kernels.shape</span><br><span class="line">    p = padding</span><br><span class="line">    assert C == in_channels, &quot;kernels&#x27; input channels do not match with img&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    if p:</span><br><span class="line">        img = np.pad(img, ((0,0),(0,0),(p,p),(p,p)), &#x27;constant&#x27;) # padding along with all axis</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    out_h = (H + 2*padding - kh) // stride + 1</span><br><span class="line">    out_w = (W + 2*padding - kw) // stride + 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    outputs = np.zeros([N, out_channels, out_h, out_w])</span><br><span class="line">    # print(img)</span><br><span class="line">    for n in range(N):</span><br><span class="line">        for out in range(out_channels):</span><br><span class="line">            for i in range(in_channels):</span><br><span class="line">                for h in range(out_h):</span><br><span class="line">                    for w in range(out_w):</span><br><span class="line">                        for x in range(kh):</span><br><span class="line">                            for y in range(kw):</span><br><span class="line">                                outputs[n][out][h][w] += img[n][i][h * stride + x][w * stride + y] * kernels[x][y]</span><br><span class="line">                if i == in_channels - 1:</span><br><span class="line">                    outputs[n][out][:][:] += bias[n][out]</span><br><span class="line">    return outputs</span><br></pre></td></tr></table></figure><h2 id="位置编码篇"><a href="#位置编码篇" class="headerlink" title="位置编码篇"></a><strong>位置编码篇</strong></h2><h3 id="手撕-绝对位置编码-算法"><a href="#手撕-绝对位置编码-算法" class="headerlink" title="手撕 绝对位置编码 算法"></a><strong>手撕 绝对位置编码 算法</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">class SinPositionEncoding(nn.Module):</span><br><span class="line">    def __init__(self, max_sequence_length, d_model, base=10000):</span><br><span class="line">        super().__init__()</span><br><span class="line">        self.max_sequence_length = max_sequence_length</span><br><span class="line">        self.d_model = d_model</span><br><span class="line">        self.base = base</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def forward(self):</span><br><span class="line">        pe = torch.zeros(self.max_sequence_length, self.d_model, dtype=torch.float)  # size(max_sequence_length, d_model)</span><br><span class="line">        exp_1 = torch.arange(self.d_model // 2, dtype=torch.float)  # 初始化一半维度，sin位置编码的维度被分为了两部分</span><br><span class="line">        exp_value = exp_1 / (self.d_model / 2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        alpha = 1 / (self.base ** exp_value)  # size(dmodel/2)</span><br><span class="line">        out = torch.arange(self.max_sequence_length, dtype=torch.float)[:, None] @ alpha[None, :]  # size(max_sequence_length, d_model/2)</span><br><span class="line">        embedding_sin = torch.sin(out)</span><br><span class="line">        embedding_cos = torch.cos(out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        pe[:, 0::2] = embedding_sin  # 奇数位置设置为sin</span><br><span class="line">        pe[:, 1::2] = embedding_cos  # 偶数位置设置为cos</span><br><span class="line">        return pe</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">SinPositionEncoding(d_model=4, max_sequence_length=10, base=10000).forward()</span><br></pre></td></tr></table></figure><h3 id="手撕-可学习位置编码-算法"><a href="#手撕-可学习位置编码-算法" class="headerlink" title="手撕 可学习位置编码 算法"></a><strong>手撕 可学习位置编码 算法</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">class TrainablePositionEncoding(nn.Module):</span><br><span class="line">    def __init__(self, max_sequence_length, d_model):</span><br><span class="line">        super().__init__()</span><br><span class="line">        self.max_sequence_length = max_sequence_length</span><br><span class="line">        self.d_model = d_model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def forward(self):</span><br><span class="line">        pe = nn.Embedding(self.max_sequence_length, self.d_model)</span><br><span class="line">        nn.init.constant(pe.weight, 0.)</span><br><span class="line">        return pe</span><br></pre></td></tr></table></figure><h3 id="手撕-相对位置编码-算法"><a href="#手撕-相对位置编码-算法" class="headerlink" title="手撕 相对位置编码 算法"></a><strong>手撕 相对位置编码 算法</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line">class RelativePosition(nn.Module):</span><br><span class="line">    def __init__(self, num_units, max_relative_position):</span><br><span class="line">        super().__init__()</span><br><span class="line">        self.num_units = num_units</span><br><span class="line">        self.max_relative_position = max_relative_position</span><br><span class="line">        self.embeddings_table = nn.Parameter(torch.Tensor(max_relative_position * 2 + 1, num_units))</span><br><span class="line">        nn.init.xavier_uniform_(self.embeddings_table)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def forward(self, length_q, length_k):</span><br><span class="line">        range_vec_q = torch.arange(length_q)</span><br><span class="line">        range_vec_k = torch.arange(length_k)</span><br><span class="line">        distance_mat = range_vec_k[None, :] - range_vec_q[:, None]</span><br><span class="line">        distance_mat_clipped = torch.clamp(distance_mat, -self.max_relative_position, self.max_relative_position)</span><br><span class="line">        final_mat = distance_mat_clipped + self.max_relative_position</span><br><span class="line">        final_mat = torch.LongTensor(final_mat).cuda()</span><br><span class="line">        embeddings = self.embeddings_table[final_mat].cuda()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        return embeddings</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class RelativeMultiHeadAttention(nn.Module):</span><br><span class="line">    def __init__(self, d_model, n_heads, dropout=0.1, batch_size=6):</span><br><span class="line">        &quot;Take in model size and number of heads.&quot;</span><br><span class="line">        super(RelativeMultiHeadAttention, self).__init__()</span><br><span class="line">        self.d_model = d_model</span><br><span class="line">        self.n_heads = n_heads</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        assert d_model % n_heads == 0</span><br><span class="line">        self.head_dim = d_model // n_heads</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.linears = _get_clones(nn.Linear(d_model, d_model), 4)</span><br><span class="line">        self.dropout = nn.Dropout(p=dropout)</span><br><span class="line">        self.relative_position_k = RelativePosition(self.head_dim, max_relative_position=16)</span><br><span class="line">        self.relative_position_v = RelativePosition(self.head_dim, max_relative_position=16)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).cuda()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def forward(self, query, key, value):</span><br><span class="line">        # embedding</span><br><span class="line">        # query, key, value = [batch_size, len, hid_dim]</span><br><span class="line">        query, key, value = [l(x).view(self.batch_size, -1, self.d_model) for l, x in</span><br><span class="line">                             zip(self.linears, (query, key, value))]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        len_k = query.shape[1]</span><br><span class="line">        len_q = query.shape[1]</span><br><span class="line">        len_v = value.shape[1]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        # Self-Attention</span><br><span class="line">        # r_q1, r_k1 = [batch_size, len, n_heads, head_dim]</span><br><span class="line">        r_q1 = query.view(self.batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)</span><br><span class="line">        r_k1 = key.view(self.batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)</span><br><span class="line">        attn1 = torch.matmul(r_q1, r_k1.permute(0, 1, 3, 2))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        r_q2 = query.permute(1, 0, 2).contiguous().view(len_q, self.batch_size * self.n_heads, self.head_dim)</span><br><span class="line">        r_k2 = self.relative_position_k(len_q, len_k)</span><br><span class="line">        attn2 = torch.matmul(r_q2, r_k2.transpose(1, 2)).transpose(0, 1)</span><br><span class="line">        attn2 = attn2.contiguous().view(self.batch_size, self.n_heads, len_q, len_k)</span><br><span class="line">        attn = (attn1 + attn2) / self.scale</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        attn = self.dropout(torch.softmax(attn, dim=-1))</span><br><span class="line">        # attn = [batch_size, n_heads, len, len]</span><br><span class="line">        r_v1 = value.view(self.batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)</span><br><span class="line">        weight1 = torch.matmul(attn, r_v1)</span><br><span class="line">        r_v2 = self.relative_position_v(len_q, len_v)</span><br><span class="line">        weight2 = attn.permute(2, 0, 1, 3).contiguous().view(len_q, self.batch_size * self.n_heads, len_k)</span><br><span class="line">        weight2 = torch.matmul(weight2, r_v2)</span><br><span class="line">        weight2 = weight2.transpose(0, 1).contiguous().view(self.batch_size, self.n_heads, len_q, self.head_dim)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        x = weight1 + weight2</span><br><span class="line">        # x = [batch size, n heads, query len, head dim]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        x = x.permute(0, 2, 1, 3).contiguous()</span><br><span class="line">        # x = [batch size, query len, n heads, head dim]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        x = x.view(self.batch_size * len_q, self.d_model)</span><br><span class="line">        # x = [batch size * query len, hid dim]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        return self.linears[-1](x)</span><br></pre></td></tr></table></figure><h3 id="手撕-rope-算法"><a href="#手撕-rope-算法" class="headerlink" title="手撕 rope 算法"></a><strong>手撕 rope 算法</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def sinusoidal_position_embedding(batch_size, nums_head, max_len, output_dim, device):</span><br><span class="line">    # (max_len, 1)</span><br><span class="line">    position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(-1)</span><br><span class="line">    # (output_dim//2)</span><br><span class="line">    ids = torch.arange(0, output_dim // 2, dtype=torch.float)  # 即公式里的i, i的范围是 [0,d/2]</span><br><span class="line">    theta = torch.pow(10000, -2 * ids / output_dim)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # (max_len, output_dim//2)</span><br><span class="line">    embeddings = position * theta  # 即公式里的：pos / (10000^(2i/d))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # (max_len, output_dim//2, 2)</span><br><span class="line">    embeddings = torch.stack([torch.sin(embeddings), torch.cos(embeddings)], dim=-1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # (bs, head, max_len, output_dim//2, 2)</span><br><span class="line">    embeddings = embeddings.repeat((batch_size, nums_head, *([1] * len(embeddings.shape))))  # 在bs维度重复，其他维度都是1不重复</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # (bs, head, max_len, output_dim)</span><br><span class="line">    # reshape后就是：偶数sin, 奇数cos了</span><br><span class="line">    embeddings = torch.reshape(embeddings, (batch_size, nums_head, max_len, output_dim))</span><br><span class="line">    embeddings = embeddings.to(device)</span><br><span class="line">    return embeddings</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line">def RoPE(q, k):</span><br><span class="line">    # q,k: (bs, head, max_len, output_dim)</span><br><span class="line">    batch_size = q.shape[0]</span><br><span class="line">    nums_head = q.shape[1]</span><br><span class="line">    max_len = q.shape[2]</span><br><span class="line">    output_dim = q.shape[-1]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # (bs, head, max_len, output_dim)</span><br><span class="line">    pos_emb = sinusoidal_position_embedding(batch_size, nums_head, max_len, output_dim, q.device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # cos_pos,sin_pos: (bs, head, max_len, output_dim)</span><br><span class="line">    # 看rope公式可知，相邻cos，sin之间是相同的，所以复制一遍。如(1,2,3)变成(1,1,2,2,3,3)</span><br><span class="line">    cos_pos = pos_emb[...,  1::2].repeat_interleave(2, dim=-1)  # 将奇数列信息抽取出来也就是cos 拿出来并复制</span><br><span class="line">    sin_pos = pos_emb[..., ::2].repeat_interleave(2, dim=-1)  # 将偶数列信息抽取出来也就是sin 拿出来并复制</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # q,k: (bs, head, max_len, output_dim)</span><br><span class="line">    q2 = torch.stack([-q[..., 1::2], q[..., ::2]], dim=-1)</span><br><span class="line">    q2 = q2.reshape(q.shape)  # reshape后就是正负交替了</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 更新qw, *对应位置相乘</span><br><span class="line">    q = q * cos_pos + q2 * sin_pos</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    k2 = torch.stack([-k[..., 1::2], k[..., ::2]], dim=-1)</span><br><span class="line">    k2 = k2.reshape(k.shape)</span><br><span class="line">    # 更新kw, *对应位置相乘</span><br><span class="line">    k = k * cos_pos + k2 * sin_pos</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    return q, k</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line">def attention(q, k, v, mask=None, dropout=None, use_RoPE=True):</span><br><span class="line">    # q.shape: (bs, head, seq_len, dk)</span><br><span class="line">    # k.shape: (bs, head, seq_len, dk)</span><br><span class="line">    # v.shape: (bs, head, seq_len, dk)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    if use_RoPE:</span><br><span class="line">        q, k = RoPE(q, k)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    d_k = k.size()[-1]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    att_logits = torch.matmul(q, k.transpose(-2, -1))  # (bs, head, seq_len, seq_len)</span><br><span class="line">    att_logits /= math.sqrt(d_k)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    if mask is not None:</span><br><span class="line">        att_logits = att_logits.masked_fill(mask == 0, -1e9)  # mask掉为0的部分，设为无穷大</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    att_scores = F.softmax(att_logits, dim=-1)  # (bs, head, seq_len, seq_len)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    if dropout is not None:</span><br><span class="line">        att_scores = dropout(att_scores)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # (bs, head, seq_len, seq_len) * (bs, head, seq_len, dk) = (bs, head, seq_len, dk)</span><br><span class="line">    return torch.matmul(att_scores, v), att_scores</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    # (bs, head, seq_len, dk)</span><br><span class="line">    q = torch.randn((8, 12, 10, 32))</span><br><span class="line">    k = torch.randn((8, 12, 10, 32))</span><br><span class="line">    v = torch.randn((8, 12, 10, 32))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    res, att_scores = attention(q, k, v, mask=None, dropout=None, use_RoPE=True)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # (bs, head, seq_len, dk),  (bs, head, seq_len, seq_len)</span><br></pre></td></tr></table></figure><pre><code>print(res.shape, att_scores.shape)</code></pre><h2 id="面试题汇总"><a href="#面试题汇总" class="headerlink" title="面试题汇总"></a><strong>面试题汇总</strong></h2><ul><li><a href="https://mp.weixin.qq.com/s?__biz=MzkyNTY0Mjg0OQ==&mid=2247483957&idx=1&sn=abec4b75b9865b754f8a303c340c13a3&scene=21#wechat_redirect">大模型微调的经验与感想分享</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzkyNTY0Mjg0OQ==&mid=2247483942&idx=1&sn=a5ba1da8459df0b76e1ea70bfa4dc068&scene=21#wechat_redirect">百度-NLP算法工程师面经</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzkyNTY0Mjg0OQ==&mid=2247483919&idx=1&sn=c9a530ecce9e60af4fad4c06062ec9ce&scene=21#wechat_redirect">美团-大模型算法工程师面经</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzkyNTY0Mjg0OQ==&mid=2247483896&idx=1&sn=6b79f7eb585cc1d91a1f61010941477c&scene=21#wechat_redirect">小米-NLP算法工程师面试题</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzkyNTY0Mjg0OQ==&mid=2247483884&idx=1&sn=e1f4d13589606786f2d2467e11b4e2dc&scene=21#wechat_redirect">好未来-NLP算法工程师面经</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzkyNTY0Mjg0OQ==&mid=2247483862&idx=1&sn=0dc0ee080532d397b2b00bdd20c86260&scene=21#wechat_redirect">百度大模型算法工程师面经</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzkyNTY0Mjg0OQ==&mid=2247483853&idx=2&sn=f717767538329ce17325de72aa58ba1b&scene=21#wechat_redirect">昆仑天工大模型算法工程师</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzkyNTY0Mjg0OQ==&mid=2247483839&idx=1&sn=b66447f92f4dbfa8be7922f53aa8ba4b&scene=21#wechat_redirect">阿里大模型算法工程师一面</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzkyNTY0Mjg0OQ==&mid=2247483790&idx=1&sn=308fb18b66cc66b78f7e15822cdd6eff&scene=21#wechat_redirect">算法工程师面试常考手撕题</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzkyNTY0Mjg0OQ==&mid=2247483773&idx=1&sn=003c347fc05e1a3fa4328ac09dddb797&scene=21#wechat_redirect">搜狐大模型算法工程师</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzkyNTY0Mjg0OQ==&mid=2247483757&idx=1&sn=79394fd14e39948d1fc98aa09e031561&scene=21#wechat_redirect">字节大模型算法实习生</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzkyNTY0Mjg0OQ==&mid=2247483750&idx=1&sn=18d9c270e8d58a32dc4792fbc5f8f6e8&scene=21#wechat_redirect">理想汽车大模型算法实习生</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzkyNTY0Mjg0OQ==&mid=2247483745&idx=1&sn=ee37c895b25bf2a1f8387edf1d687e30&scene=21#wechat_redirect">百度大模型算法实习生面试题</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzkyNTY0Mjg0OQ==&mid=2247483731&idx=1&sn=08cb4b390e80f3ca4a1e0fa2dd5a3020&scene=21#wechat_redirect">腾讯大模型算法实习生面试题</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzkyNTY0Mjg0OQ==&mid=2247483723&idx=1&sn=baa9b82a7ac4f12e936ff8b58dcf8977&scene=21#wechat_redirect">阿里大模型算法工程师一面</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzkyNTY0Mjg0OQ==&mid=2247483713&idx=1&sn=c90af03630f92999eed214d5dc9f06a3&scene=21#wechat_redirect">某大厂大模型算法工程师面试题</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzkyNTY0Mjg0OQ==&mid=2247483697&idx=1&sn=82e8cbb46aa2a0a656ae6f76ed225b03&scene=21#wechat_redirect">说说百度大模型算法工程师二面经历</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzkyNTY0Mjg0OQ==&mid=2247483686&idx=1&sn=79b3d0eb8a034cf7fe8746cd5e362899&scene=21#wechat_redirect">阿里大模型算法工程师面试小结</a></li></ul><h2 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a><strong>致谢</strong></h2><ul><li>LLMs 千面郎君 更新版 <a href="https://mp.weixin.qq.com/s/C6NdO_Ebj3DQx2AVAAgQRQ">https://mp.weixin.qq.com/s/C6NdO_Ebj3DQx2AVAAgQRQ</a></li><li>LLMs九层妖塔 <a href="https://mp.weixin.qq.com/s/Eh0tY1zx2FqXQqIGa2dIBA">https://mp.weixin.qq.com/s/Eh0tY1zx2FqXQqIGa2dIBA</a></li><li>NLP 面无不过 <a href="https://github.com/km1994/NLP-Interview-Notes">https://github.com/km1994/NLP-Interview-Notes</a></li></ul><blockquote><p>来自: <a href="https://mp.weixin.qq.com/s/TAFvUlqdyqP-W6C10F1Hzw">算法工程师面试常考手撕题（更新）</a></p></blockquote>]]></content>
    
    
    <summary type="html">秋招结束后的面试总结分享。</summary>
    
    
    
    <category term="面试总结" scheme="http://example.com/categories/%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="面试总结" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>秋招金山面试分享</title>
    <link href="http://example.com/2024/11/06/%E7%A7%8B%E6%8B%9B%E9%87%91%E5%B1%B1%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/"/>
    <id>http://example.com/2024/11/06/%E7%A7%8B%E6%8B%9B%E9%87%91%E5%B1%B1%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/</id>
    <published>2024-11-06T11:40:37.000Z</published>
    <updated>2024-11-29T17:06:27.581Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h2><p>今天9.30面的金山，金山这个面试基本是我面试过程最难的几个了，本来面试计划时间半小时，结果面了一个小时，面试官非常深挖项目，问的非常细，而且非常的耐心，里面就问了两个八股，看来要准备的还真的需要很多。</p><p>首先是自我介绍，然后问了下我的实习，第一部分主要是针对实习的具体内容展开，我先讲完做了啥，</p><p>用了什么模型，参数是多少，量级是多少，为什么用千问，盘古智子，千问大模型版本，结构，最大上下文长度是多少，怎么评测，选取哪个大模型。大模型训练出来的结果如何评价，用的什么指标。</p><p>LoRA微调原理，训练哪些层，都哪些超参数，超参数怎么设置的。</p><p>前面这块我了解的不是特别深入，然后就开始讲Prompt这块关于具体任务的内容，数据集怎么构造的，为什么这么构建，标注数据有什么问题，数据量多少，这个项目最终的好坏如何评价。</p><p>后面上线需要解决什么问题，是效果达不到，还是速度达不到，还是其他问题，千问的模型是否可以上线，解决方案是什么，后续怎么做。</p><p>还问了大模型的分布式这块了解不，我问是不是deepspeed这种，是，这块说了两句，不是特别懂。</p><p>然后问我后面哪个项目感觉做的比较深入，然后我说了第一个项目做的深入而且有论文，然后他就开始问了我最后一个项目，这个项目做的比较浅。问到这个项目，量化和剪枝如何做的，参数量是多少，剪枝之后是多少，速度提升多少。量化如何做的，量化之后的参数量是多少，速度提升多少。其中的CPP需要写哪些部分。</p><p>最后是八股，问了下现在各个大模型的架构是啥，主流都是哪些模型，都是啥样的。除了Transformer之外还了解mamba和kan不。</p><p>反问问了他们主要是大模型还是传统，说都有。</p><p>被拷打的很惨，感觉这次面试是最难的，感觉肯定G了。</p><p>结果没想到，过了，这次面试真的是很难，感觉自己很多地方都答的不好，但是还是过了，感觉有点意外。</p><h2 id="二面"><a href="#二面" class="headerlink" title="二面"></a>二面</h2><p>10.15今天金山二面，面了一个小时，过去自我介绍，然后面试官说让找一个印象最深的项目深入的讲。</p><p>然后我就讲了我做的第一个项目，也有论文，就屏幕共享讲论文，这次讲比第一次讲论文好多了，大致是讲清楚了，虽然后面面试官说可延展性不太行，不过确实，一个横向项目论文，确实挺水的，但也没办法。</p><p>然后是手撕，还是屏幕共享，让打开IDE，然后我Pycharm手撕一道题，这次问的是数组中找两个数之和，使其和target之差最小，然后用的双指针，说了下思路，然后写了出来，然后问算法复杂度，是O(nlogn)，然后是延伸，是否能用二分查找法做，如果这样做如何来设计，然后我说了下，应该说的没问题，这块也追问了好几个，比如两个数的时候有没有啥问题，边界条件是不是对，差不多都答上来了。</p><p>然后是一个八股，问大模型和小模型的区别，这块见得多了，从实用角度，可解释性，成本，大模型幻觉啥的展开讲，基本没啥问题，面试官差不多还夸了下。</p><p>然后是反问环节，问部门做啥，大模型还是小模型，都有，然后是base，问我报的哪里，他们这边有珠海、武汉、北京，后面会培训然后协商部门和base地。</p><p>然后是问我有没有其他offer，我说有几个在排序中，还在看。</p><p>总体来说感觉也还行，应该是过了吧。</p><h2 id="三面HR面"><a href="#三面HR面" class="headerlink" title="三面HR面"></a>三面HR面</h2><p>11.5HR打电话，问我有没有时间，我说有，然后就直接电话面了。</p><p>首先问了下我实习7~9月华子实习，问结束了没，是结束了。然后问为什么没有华子内部转正，我说华子的不能转正，而且只有特别的可以评A直通三面，但是我一起的都是C9的，然后问那个部门招多少人，这个我不清楚。然后问华子比例多少，我说那个比例不超过20%。然后问实习为什么时间短，没想着转正或者没有机会吗，还是不喜欢工作内容。我说一方面前面在学校老师安排的活和毕设中期，就拖到了7.3；另一方面九月份就要秋招了，后面就没时间了，而且华子本身也不能转正。</p><p>然后问都拿到了哪些公司的offer或者哪家公司已经走到了后面的流程了，我说现在有几家已经到二面三面了，但是地方还没看好，更想去粤港澳地方。然后问头的是珠海，是什么原因呢有家里家人朋友在这边吗？我说不是，因为更看好这边的发展，我家里是河南，但是不是很想回去，粤港澳这边中国发展比较好，从未来考虑。然后问哪些公司比较后面了，我说讯飞理想都在后面了，但是还没有发offer，然后问他们的地点是哪里，我说还没仔细看。</p><p>然后问对未来工作的规划，你应聘的是算法，我说一直在做AI相关的，这块也比较了解。一方面从发展维度来说，进去前两年做技术，后面再考虑带团队，从学校和公司的差异。另一方面从就业的具体内容来说也希望更好的用到前面学的人工智能方面的知识，其他的也是可以快速学习的。然后我问这边工作是偏研发还是工程，他们说偏向工程产品落地。</p><p>然后问前面面试的过程中觉得他们关注的一些方向以及他们去问的一些问题跟您未来的那个发展的规划相符吗。我说基本还是可以。对于他们关注等一些内容有哪些方面女士没有涉及到或者是没有了解和学习接触过的吗？我说主要是从学校和公司的差异，对于性能效率方面的一些差异吧，这个我举了个例子来说的。</p><p>然后问：目前在学校期间的话是在做毕业论文还是做一些什么样的方向的一些学习吗？目前主要是秋招，后面做毕设，也是AI方面的。最近的话最近肯定是还是以秋为主，就是现在还没有就是还没有拿到不错的offer，暂时还没有走到那个offer这一步。</p><p>然后问薪酬的预期，我说我也不知道下面咱们这个行情到底应该是个什么情况。那你身边的同学有啊拿到什么样的一些offer你有了解到吗？我大致说了下，很多在等华为。然后问我为什么不是很想去华子，我说华子应该不算互联网。然后问我身边小米美团他们的薪酬大致多少，我说年三十多到四十多，具体也要看地方。然后问我珠海如何，我说年薪也要30多以上吧，也不知道行情如何。然后问珠海的薪资和深圳的薪资比较比较下来的话会有什么样的差异吗？我说肯定比深圳低。</p><p>然后HR说这边暂时没有其他问题了，晚一点确定录取和信息待遇什么的回尽快打电话，然后反问环节，我就问了下地方，武汉珠海是一样的，可以后面转，然后就结束了。<br><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/img/7162652ed15d942a69859975d27f38d.png" alt="7162652ed15d942a69859975d27f38d"></p><h2 id="oc"><a href="#oc" class="headerlink" title="oc"></a>oc</h2><p>11.6早晨HR打电话，谈了下薪酬福利，工作时间，这种类似的。</p>]]></content>
    
    
    <summary type="html">秋招正式批金山技术面试分享。</summary>
    
    
    
    <category term="面试记录" scheme="http://example.com/categories/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="面试记录" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>秋招中金所面试分享</title>
    <link href="http://example.com/2024/11/01/%E7%A7%8B%E6%8B%9B%E4%B8%AD%E9%87%91%E6%89%80%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/"/>
    <id>http://example.com/2024/11/01/%E7%A7%8B%E6%8B%9B%E4%B8%AD%E9%87%91%E6%89%80%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/</id>
    <published>2024-11-01T14:39:37.000Z</published>
    <updated>2024-11-29T17:06:27.577Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h2><p>11.1下午这次面的是中金所的子公司，总共就面了15分钟，几乎没问技术。</p><p>过去首先自我介绍，然后问了下华为实习是不是能转正，我说不能，然后说现在华子秋招还没开。</p><p>然后问我是否了解这个公司，我说是金融方面的，具体还不是很了解。</p><p>问我最近在看什么书，我说最近秋招，所以在看人工智能方面的书，根据不不同的阶段和任务看书。</p><p>然后问我找工作有多个offer的时候看重什么，我说第一看公司的发展，第二个人能力的培养，第三个是薪资福利。</p><p>然后让我找一个印象深刻的经历，展开讲讲，我就讲了下实习的内容，讲完他都没问问题，直接就到了反问环节。</p><p>我就反问部门具体是什么业务，哪方面的，他说前沿技术岗，一个是跟踪行业发展，探索落地，各种大模型区块链都有涉及，这个部门是运维的，就是前沿技术在这块的应用。</p><p>然后我问了下后面还有几面，他说如果一面过了的话二面是具体岗位相关的技术，三面是HR面。</p><p>总体来说还是太简短了，相比上午面一个小时还是差很多。</p>]]></content>
    
    
    <summary type="html">秋招正式批中金所面试分享。</summary>
    
    
    
    <category term="面试记录" scheme="http://example.com/categories/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="面试记录" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>秋招蔚来面试分享</title>
    <link href="http://example.com/2024/11/01/%E7%A7%8B%E6%8B%9B%E8%94%9A%E6%9D%A5%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/"/>
    <id>http://example.com/2024/11/01/%E7%A7%8B%E6%8B%9B%E8%94%9A%E6%9D%A5%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/</id>
    <published>2024-11-01T12:08:37.000Z</published>
    <updated>2024-11-29T17:06:27.581Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h2><p>这次面的是蔚来，开始面试官很热情，上来介绍他们部门是自动驾驶的芯片的，然后我自我介绍，然后就开始问问题了。这次面了一个小时，可以说底裤都被扒的干干净净，好多问题都没回答上来，感觉是要G了。</p><p>这次没问实习，毕竟实习是做大模型的，这边完全不做大模型了，纯视觉，所以问的我的项目。</p><p>首先第一个项目，这个是我研究生做的第一个项目，讲完问了效果误差如何，是否满足需要，我说误差1%差不多是可以用了，而且成本低，这块简单问了下，还问了整个过程都用了哪些模型。又问了我用的MMPose框架内部是怎么实现的，这个框架我还真不是特别了解，只是用过，所以回答的不是很好。然后问我这块目标检测用的模型，这块是项目中很小的一个点，我都没准备，结果问到了，我就回答不好了。</p><p>然后第二个项目，这个讲完主体后，让我讲下这个过程用了什么模型，我讲了下还有效果。然后问实时性什么的是否满足需要，我就讲了下整体的流程架构。然后问这个项目的难点是什么，我说主要应该是解决具体的问题。然后问我有没有做边缘部署，我说这个本来有这个需求，但是后面没谈好，就没做了。还问了项目指标到多少，评价指标如何设计的，这块也是回答了个大概。</p><p>然后问第三个项目，这个项目做的浅，问了前面部分用的什么做的，这块用的接口做的，只做了后面的不难的部分，大致说了下，也是说的很水。</p><p>然后问第四个项目，我把整个流程说了下，然后说了下主要的难点和处理方法，也是大致说了下就完了。</p><p>然后开始问卷积内部实现和计算，这块我大致说了，然后又问了参数量规模，大致说了下，回答的一般。然后问我NMS怎么算的，我大致把理论说了下，然后问IOU怎么算的，这个比较容易，我还会手写。</p><p>然后问Python相关的，问了下*args和**kargs什么区别，这块大致说出来了。</p><p>然后问浅拷贝和深拷贝有什么区别，python中有哪些数据类型是浅拷贝，哪些是深拷贝。第一个浅拷贝和深拷贝大致说了下，第二个还真不知道。</p><p>然后问CPP相关的，问虚函数和纯虚函数什么区别，泛型编程是什么，模板是什么。这些就真不会了。</p><p>然后反问，我就问了下部门业务，然后他问我愿不愿意做这种比较底层的，我说还是很有兴趣的，然后就结束了。</p><p>感觉这次面试官开始还是很热情的，但是我回答的不太行，感觉是要G了，这些问题都太底层了，还有很多八股，我都没准备，感觉是要准备下这些问题了。</p>]]></content>
    
    
    <summary type="html">秋招正式批蔚来面试分享。</summary>
    
    
    
    <category term="面试记录" scheme="http://example.com/categories/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="面试记录" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>秋招广联达</title>
    <link href="http://example.com/2024/10/31/%E7%A7%8B%E6%8B%9B%E5%B9%BF%E8%81%94%E8%BE%BE%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/"/>
    <id>http://example.com/2024/10/31/%E7%A7%8B%E6%8B%9B%E5%B9%BF%E8%81%94%E8%BE%BE%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/</id>
    <published>2024-10-31T00:04:37.000Z</published>
    <updated>2024-11-29T17:06:27.577Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h1><ol start="10"><li></li></ol><p>30下午面试的广联达，这是个做建筑设计的公司，过去自我介绍完，他们好像主要是偏视觉一些，所以先问了我第一个项目，讲完之后追问了一些细节，包括问用的什么模型，模型的结构是什么。然后其他的问了下实习的内容，我就把实习的内容讲了一遍，他就问了下相比之前的效果如何，我说主要是业务流程上的改进，用大模型来完成这些事情。</p><p>之后他想问八股，我说计组计网操作系统编译原理都没学过，他就问了下如何处理类别不均的问题，这个我举了我实习时候的例子，再结合了之前做一般小模型时候的一些处理方法，给出了一些回答。</p><p>然后是问他们部门，他介绍了下他们公司主要偏视觉一些，是建筑信息化方面的公司，涉及图文生成和3DGS之类的，我也聊了下先关的内容。</p>]]></content>
    
    
    <summary type="html">秋招正式批广联达技术面试分享。</summary>
    
    
    
    <category term="面试记录" scheme="http://example.com/categories/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="面试记录" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>秋招上海银行面试分享</title>
    <link href="http://example.com/2024/10/25/%E7%A7%8B%E6%8B%9B%E4%B8%8A%E6%B5%B7%E9%93%B6%E8%A1%8C%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/"/>
    <id>http://example.com/2024/10/25/%E7%A7%8B%E6%8B%9B%E4%B8%8A%E6%B5%B7%E9%93%B6%E8%A1%8C%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/</id>
    <published>2024-10-25T14:49:37.000Z</published>
    <updated>2024-11-29T17:06:27.577Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一面AI面"><a href="#一面AI面" class="headerlink" title="一面AI面"></a>一面AI面</h2><p>虽然是AI面试，但是还是记录一下，面试的内容，这个相当于是综合面试的题提前到了技术面之前了。这些内容还是需要总结一下，也是后面面试可能会问的问题。</p><p>具体有7个题分别需要录制两分钟的视频，第一个是自我介绍，包含学校、实习、项目、技能、兴趣爱好这些部分。</p><p>后面有印象最深的项目是什么，具体哪个？</p><p>第五个题目是如何促成他人意见和自己达成一致，会因此感到压力吗？</p><p>第六个题目是你制定过最成功的计划是什么？</p><p>最后一个题目是简述自己的优势和劣势和未来的职业规划？</p><p>这些题目有30秒的思考时间，难度有一些的，还是要提前准备一下的。</p><h2 id="二面人工面"><a href="#二面人工面" class="headerlink" title="二面人工面"></a>二面人工面</h2><p>这次面试大概35分钟，基本问的也算全，不过后面的都没问。线上腾讯会议面试，有两个面试官，第一个面的时候第二个听。</p><p>第一个面试官，过去先自我介绍，然后讲实习做的啥，先讲了背景，然后按照要求说了输入输出和目的，只讲了一个点，中间问了很多细节，数据多少条，正负样本配比是否合适。用的啥模型训练的，现在主流的大模型结构是什么样的，这个我都没回答完，就打断了。然后问我大模型在银行场景中如何应用，我就说了下目前主要在知识库和智能客服结合RAG和Agent这块做的，其他倒是不太多。然后问了我是否会开发，问技术栈，我说主要会Python和Pytorch，C++只会一点，还有就是机器学习和深度学习算法，比如Kmeans啥的。Java不太会，不过学起来应该也问题不大。然后问我是否了解SQL，我说本科用过，速成了一下增删查改，后面没有用过就不太懂了，不过要学应该挺快的。</p><p>然后让第二个面试官问，面试官首先说你既然比较了解Pytorch，那Pytorch中的基本数据结构是什么，我说了下Tensor，他问和numpy中的有什么区别，我说主要是需要计算梯度和更新参数，所以主要是梯度累计记录这块的区别。然后问我前向传播和反向传播有什么区别，简单说了下更新参数和梯度这块的内容。然后说你刚才说Kmeans，那你说一下这个算法，我就介绍了下原理，然后问我距离计算有哪些类型，我就说了下L1和L2欧式距离，还有0范数和无穷范数啥的。然后他问我如何确定聚类数目，我说这是个超参数，不过其他聚类如DBSCAN不需要指定聚类个数，如果Kmeans需要预估的话，需要进行数据分析一下，大致预估。然后是问我大模型在银行中如何应用落地，这块我也是只能从知识库智能客服这块说了下，然后就是结合华为实习的风控场景类似银行场景中也可以进行应用。这个开放性问题其实我回答的不算出彩，感觉这个问题很多领导还是很看重的，还是需要重点准备一下。</p><p>然后是反问，我就说了下我技术栈过去是否适配适应，面试官说这个数据岗主要细分数据分析和人工智能大模型算法应用，然后就结束了。</p>]]></content>
    
    
    <summary type="html">秋招正式批上海银行面试分享。</summary>
    
    
    
    <category term="面试记录" scheme="http://example.com/categories/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="面试记录" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>秋招百信银行面试分享</title>
    <link href="http://example.com/2024/10/21/%E7%A7%8B%E6%8B%9B%E7%99%BE%E4%BF%A1%E9%93%B6%E8%A1%8C%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/"/>
    <id>http://example.com/2024/10/21/%E7%A7%8B%E6%8B%9B%E7%99%BE%E4%BF%A1%E9%93%B6%E8%A1%8C%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/</id>
    <published>2024-10-21T21:35:37.000Z</published>
    <updated>2024-11-29T17:06:27.581Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h2><p>这次面试是电话面试，大概40分钟。</p><p>首先自我介绍，然后问实习，讲完问的问题有，大模型相比传统业务的优势， 样本的评测标准是否和之前的一样，这个项目后面是否可以做成纯大模型提取学习，等等之类的。问了这些就是八股了，现在主流都有哪些大模型，他们的结构是啥样的，我介绍完问ChatGLM为什么不是纯Decoder的，具体是采用了什么结构，这块我就答不上来了。</p><p>然后是问后面的第一个项目，有论文这个，把大致的内容讲了下，这块没怎么问。</p><p>然后就问到最后一个项目，说其中的量化剪枝这块怎么做的，这块我讲的不太清楚，涉及CPP的这块讲了下，还有部署和服务这块怎么做的大致讲了下。</p><p>然后反问，问具体部门做啥，具体是大模型的工程应用团队，然后就结束了。</p>]]></content>
    
    
    <summary type="html">秋招正式批百信银行面试分享。</summary>
    
    
    
    <category term="面试记录" scheme="http://example.com/categories/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="面试记录" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>秋招虾皮面试分享</title>
    <link href="http://example.com/2024/10/19/%E7%A7%8B%E6%8B%9B%E8%99%BE%E7%9A%AE%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/"/>
    <id>http://example.com/2024/10/19/%E7%A7%8B%E6%8B%9B%E8%99%BE%E7%9A%AE%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/</id>
    <published>2024-10-19T18:39:37.000Z</published>
    <updated>2024-11-29T17:06:27.581Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h2><p>这次面了33分钟，过去他先简单介绍他们情况，搜广推部门啥的，自我介绍完，先问了实习做的啥，然后我讲完了点，然后面试官说后面不用讲了，然后开始问，相对之前相比的优点，也问了一些里面的细节，主要还是业务流程方面的，没有仔细问模型本身相关的东西。然后是关于后面是否能上线，有啥问题。还问了大模型实际提高速度如何做，我说选用性能足够的小模型，量化剪枝蒸馏。</p><p>后面的项目好像没问，毕竟确实也不怎么相关。</p><p>然后说既然是搜广推，出个算法题，模型预测的一个排序和实际的排序，如[1,3,2,5,4]和实际的顺序[1,2,3,4,5]，设计一个函数给模型的输出打分，这块我大致思考了下，说了个思路，然后让实现，我就开始写</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    n = <span class="built_in">len</span>(rank1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    rank1_dict = &#123;value: idx <span class="keyword">for</span> idx, value <span class="keyword">in</span> <span class="built_in">enumerate</span>(rank1)&#125;</span><br><span class="line">    rank2_dict = &#123;value: idx <span class="keyword">for</span> idx, value <span class="keyword">in</span> <span class="built_in">enumerate</span>(rank2)&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    loss_sum = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> rank1:</span><br><span class="line">        loss = rank1_dict[value] - rank2_dict[value]  <span class="comment"># 计算排名差</span></span><br><span class="line">        loss_sum += loss ** <span class="number">2</span>  <span class="comment"># 差值平方累计</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>写了这些，然后分数差不多就是损失归一化然后反过来，然后就差不多了。</p><p>然后反问环节，我就问了下我技术栈过去转换是否大，面试官说他们也有大模型岗位，我说大模型不一定能火多少年，不过搜广推是互联网的基础，更看好一些，面试官让回去了解一下搜广推，上手做下项目啥的，毕竟是不能只靠兴趣，我说回去看看。</p><p>总体来看，这是第一个投搜广推给面的，虽然我也基本没怎么投搜广推，感觉面的也凑合，不过匹配程度确实是个问题。</p>]]></content>
    
    
    <summary type="html">秋招正式批虾皮面试分享。</summary>
    
    
    
    <category term="面试记录" scheme="http://example.com/categories/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="面试记录" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>秋招招联面试分享</title>
    <link href="http://example.com/2024/10/19/%E7%A7%8B%E6%8B%9B%E6%8B%9B%E8%81%94%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/"/>
    <id>http://example.com/2024/10/19/%E7%A7%8B%E6%8B%9B%E6%8B%9B%E8%81%94%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/</id>
    <published>2024-10-19T15:39:37.000Z</published>
    <updated>2024-11-29T17:06:27.577Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h2><p>这次面试的时间还挺短的，应该是22分钟，过去自我介绍完，先问了实习做的啥，然后大致讲了讲，然后问效果和之前的比如何，然后问了一些细节，是否上线。</p><p>然后问哪个项目做的深，第一个项目讲了讲，讲了大致背景和做法，都没有讲具体的结构流程，问了几个问题，包括数据、标注，和之前的比做的意义，做出的效果啥的，还有这个项目是不是自己做的，在其中什么角色。</p><p>然后问我如何职业规划和方向，想做啥，我说这些都比较通，都可以做。然后是城市的问题，这些城市我都差不多可以接受。</p><p>然后问我了不了解他们公司，这块我还真不怎么了解。然后问我有没有其他的offer，我说有几个在流程中。</p><p>最后反问，问了公司具体的业务，他们这个包括的比较多，CV、NLP大模型、语音这些都做。</p>]]></content>
    
    
    <summary type="html">秋招正式批招联面试分享。</summary>
    
    
    
    <category term="面试记录" scheme="http://example.com/categories/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="面试记录" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>秋招华为面试分享</title>
    <link href="http://example.com/2024/10/15/%E7%A7%8B%E6%8B%9B%E5%8D%8E%E4%B8%BA%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/"/>
    <id>http://example.com/2024/10/15/%E7%A7%8B%E6%8B%9B%E5%8D%8E%E4%B8%BA%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/</id>
    <published>2024-10-15T13:42:37.000Z</published>
    <updated>2024-11-29T17:06:27.577Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h1><p>15号的比较早，9：30左右，等了一会，叫号，过去面试，自我介绍完，先拿出来了笔试时候的题目让复盘一下，我用的还是投实习时候过的，正式批就没有笔试，简单看下，大致说出了思路。</p><p>然后说重点讲三个项目，我就讲一个实习+两个项目了。</p><p>开始问实习，也是介绍完之后问细节，具体也问了不少，然后讲第一个和第二个项目，讲完让手撕个题目，题目是一段01的比特流字符串，给一个target是0或者1，然后比特流只能变一位，求最多多少个连续的target，想了几分钟双指针写了出来。总体来说，一面还是比较友好的。</p><h2 id="二面"><a href="#二面" class="headerlink" title="二面"></a>二面</h2><p>等了一会就二面了，二面过去自我介绍完，我讲完实习，就问了几个套路性的常用问题，大概不到十分钟，然后就给一个手撕题目，场景题，用卷积算二阶导，对图像做边缘检测。这个没怎么见过，没想出来，要用题目给定的方法做，大致写了下，然后就结束了，写的应该不太对。面试官直接说今天面试结束了可以回去了，然后就短信通知今天的结束了，进入系统一看，果然挂了。</p><p>这种手撕场景题不太好准备，没得办法，二面都没怎么问，手撕g就g了，这题真没见过，太难了，全程都没问八股，二面一堆项目都没问，实习问的比一面还浅，没办法。</p><p>我回头问了我我同学们，还没有见过有二面挂的，他们题目都可以三选一，而且基本都是力扣，还都不是很难的那种，出这个题他们也都不会，让面试官给提示也不给，只报还剩下多少时间。毕竟连项目和八股都不问的面试我还是第一次见，一面的面试官就好的多。</p><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/img/3d0afaab4a49212c06ee3d91bc12e82.jpg" alt="3d0afaab4a49212c06ee3d91bc12e82"></p><p>我回去复盘了一下，这个题大致应该是这样的，总体来说也不能算完全的hard，但是难就难在开始这部分，如何用[1,-1]和$[1,-1]^T$计算拉普拉斯算子，后面的就很容易了。</p><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/img/20241017224856.png" alt="20241017224856"></p><p>ChatGPT给的答案是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">edge_detection_laplacian</span>(<span class="params">image</span>):</span><br><span class="line">    <span class="comment"># 获取图像尺寸</span></span><br><span class="line">    rows, cols = <span class="built_in">len</span>(image), <span class="built_in">len</span>(image[<span class="number">0</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 定义Laplacian卷积核g</span></span><br><span class="line">    g = [[<span class="number">0</span>, -<span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">         [-<span class="number">1</span>, <span class="number">4</span>, -<span class="number">1</span>],</span><br><span class="line">         [<span class="number">0</span>, -<span class="number">1</span>, <span class="number">0</span>]]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 添加padding, 初始化f为图像+2边框的0矩阵</span></span><br><span class="line">    f = [[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(cols + <span class="number">2</span>)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(rows + <span class="number">2</span>)]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将原始图像数据填充到f的中心部分</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(rows):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(cols):</span><br><span class="line">            f[i + <span class="number">1</span>][j + <span class="number">1</span>] = image[i][j]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 创建结果矩阵，用于存储边缘检测的结果</span></span><br><span class="line">    result = [[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(cols)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(rows)]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 主卷积循环，遍历图像中的每一个像素</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, rows + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, cols + <span class="number">1</span>):</span><br><span class="line">            <span class="comment"># 进行卷积操作</span></span><br><span class="line">            conv_sum = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">                <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">                    conv_sum += f[i + m - <span class="number">1</span>][j + n - <span class="number">1</span>] * g[m][n]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 将卷积结果存入结果矩阵</span></span><br><span class="line">            result[i - <span class="number">1</span>][j - <span class="number">1</span>] = conv_sum</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例输入</span></span><br><span class="line">image = [</span><br><span class="line">    [<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">1</span>],</span><br><span class="line">    [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">2</span>],</span><br><span class="line">    [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用Laplacian边缘检测函数</span></span><br><span class="line">edge_result = edge_detection_laplacian(image)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> edge_result:</span><br><span class="line">    <span class="built_in">print</span>(row)</span><br></pre></td></tr></table></figure><p>但是他这个回答没有给出拉普拉斯算子怎么算的，其实这个算子我也是知道，也会用，其实早在投实习的时候一面就问了这个算子，我直接手写了出来，但是如果不给算子，而是用[1,-1]和$[1,-1]^T$计算拉普拉斯算子，再算的话，就不太容易了。我当时只算了水平的，没有算垂直的，水平垂直的叠加其实就可以了，有算子之后后面就容易了。</p><p>chatgpt给出了推导过程：</p><h3 id="1-一阶导数的离散化"><a href="#1-一阶导数的离散化" class="headerlink" title="1. 一阶导数的离散化"></a>1. 一阶导数的离散化</h3><p>在连续情况下，函数 <code>f(x)</code> 的一阶导数是：</p><p>$$<br>f’(x) &#x3D; \frac{d}{dx}f(x)<br>$$</p><p>在离散情况下，我们用差分来近似一阶导数。在离散网格上，假设 <code>f(x)</code> 是一组离散的数值表示（如图像中的像素值），我们可以用<strong>向前差分</strong>或<strong>向后差分</strong>来近似一阶导数。</p><p><strong>向前差分</strong>表示为：</p><p>$$<br>f’(x) \approx f(x+1) - f(x)<br>$$</p><p>这相当于卷积核 <code>[1, -1]</code>，它计算当前点与下一个点的差值。</p><p><strong>向后差分</strong>表示为：</p><p>$$<br>f’(x) \approx f(x) - f(x-1)<br>$$</p><p>这相当于卷积核 <code>[-1, 1]</code>。</p><p>如果我们想取中间值（中心差分），可以将这两个差分的平均值作为一阶导数的离散近似：</p><p>$$<br>f’(x) \approx \frac{f(x+1) - f(x-1)}{2}<br>$$</p><p>这一中心差分可以表示为卷积核 <code>[1, 0, -1]</code>，它计算左右相邻点的差异。</p><h3 id="2-二阶导数的离散化"><a href="#2-二阶导数的离散化" class="headerlink" title="2. 二阶导数的离散化"></a>2. 二阶导数的离散化</h3><p>二阶导数表示的是函数变化的变化率。二阶导数是通过对一阶导数再次求导数得到的。在连续情况下，二阶导数是：</p><p>$$<br>f’’(x) &#x3D; \frac{d^2}{dx^2}f(x)<br>$$</p><p>对于离散网格，我们可以用差分的形式来近似二阶导数。</p><h3 id="3-从一阶导数推导二阶导数"><a href="#3-从一阶导数推导二阶导数" class="headerlink" title="3. 从一阶导数推导二阶导数"></a>3. 从一阶导数推导二阶导数</h3><p>假设我们已经知道一阶导数的离散近似表示为 <code>f&#39;(x) = f(x+1) - f(x)</code>，那么二阶导数可以通过对一阶导数再次取差分来计算：</p><p>$$<br>f’’(x) \approx f’(x+1) - f’(x)<br>$$</p><p>将一阶导数的表达式代入：</p><p>$$<br>f’’(x) \approx (f(x+2) - f(x+1)) - (f(x+1) - f(x))<br>$$</p><p>展开后得到：</p><p>$$<br>f’’(x) \approx f(x+2) - 2f(x+1) + f(x)<br>$$</p><p>这就是二阶导数的离散近似形式。其卷积核为 <code>[1, -2, 1]</code>，它计算当前像素值及其左右两个像素值的加权和，能够检测到亮度变化的速率，也就是图像中的曲率。</p><h3 id="4-解读-1-2-1"><a href="#4-解读-1-2-1" class="headerlink" title="4. 解读 [1, -2, 1]"></a>4. 解读 <code>[1, -2, 1]</code></h3><ul><li><code>1</code>：代表距离当前像素一个单位距离的前后像素值的贡献。</li><li><code>-2</code>：代表当前像素的值，权重大，表示它与左右两个像素的关系。</li><li><code>1</code>：再次代表左右相邻像素的贡献。</li></ul><p>这个差分算子 <code>[1, -2, 1]</code> 通过结合当前像素与其左右像素的值，近似计算二阶导数，检测出图像中变化最剧烈的部分（例如边缘或轮廓）。</p><h3 id="5-二维情况：Laplacian-算子"><a href="#5-二维情况：Laplacian-算子" class="headerlink" title="5. 二维情况：Laplacian 算子"></a>5. 二维情况：Laplacian 算子</h3><p>在二维图像处理的场景下，类似的二阶导数可以推广到多个方向。我们可以分别对 <code>x</code> 方向和 <code>y</code> 方向应用上述 <code>[1, -2, 1]</code> 的差分算子，得到图像在这两个方向的二阶导数。然后通过将两个方向的二阶导数合并，我们得到 <strong>Laplacian 算子</strong>，其标准形式是：</p><p>$$<br>g &#x3D; \begin{bmatrix} 0 &amp; -1 &amp; 0 \ -1 &amp; 4 &amp; -1 \ 0 &amp; -1 &amp; 0 \end{bmatrix}<br>$$</p><p>其中：</p><ul><li>中心位置的 <code>4</code> 对应着当前像素值的权重。</li><li><code>-1</code> 表示与上下左右像素的二阶差分贡献。</li></ul><p>这一卷积核检测的是像素与其邻域的二阶亮度变化，从而可以用于边缘检测。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>总之，这个题不算拉普拉斯的推导就是easy，但是算上的话，就不太容易，我当时算出来了水平的梯度了$[-1,2,-1]$，垂直的应该也是一样的，但是把垂直的和水平的合并就不会了，合并了就是拉普拉斯算子了，后面就没啥了。</p><p>血亏</p>]]></content>
    
    
    <summary type="html">秋招正式批华为面试分享。</summary>
    
    
    
    <category term="面试记录" scheme="http://example.com/categories/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="面试记录" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>秋招携程面试分享</title>
    <link href="http://example.com/2024/10/15/%E7%A7%8B%E6%8B%9B%E6%90%BA%E7%A8%8B%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/"/>
    <id>http://example.com/2024/10/15/%E7%A7%8B%E6%8B%9B%E6%90%BA%E7%A8%8B%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/</id>
    <published>2024-10-15T13:42:37.000Z</published>
    <updated>2024-11-29T17:06:27.577Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h1><p>10.16下午一面，这次面试体验很差，面试官过去之后不开摄像头，然后先自我介绍。</p><p>然后面试官让讲实习，就讲了下，后面问了几个问题，主要是指标相比之前的业务是否有提升，还有如何判断效果如何，和之前的比较有啥区别，这块也问了几个问题。</p><p>然后是讲第一个项目，到这面试官就已经开始不耐烦了，讲完就没问问题，然后开始八股，先问了池化层是什么作用，简单回答了下，然后问平均池化和最大池化的区别，回答完问了解SQL不，我说曾经做过一点，但不是太会，然后给了个SQL题目，我确实不太会，就让改成算法题，然后简单写了下，写完喊面试官几次都不应答，后面基本也都是嗯一下答复。</p><p>然后反问了下部门，面试官说了下，然后就结束了，感觉这次面试官不太耐烦，可能是我回答的不太好，希望能过吧。</p>]]></content>
    
    
    <summary type="html">秋招正式批携程面试分享</summary>
    
    
    
    <category term="面试记录" scheme="http://example.com/categories/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="面试记录" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>秋招荣耀面试分享</title>
    <link href="http://example.com/2024/10/14/%E7%A7%8B%E6%8B%9B%E8%8D%A3%E8%80%80%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/"/>
    <id>http://example.com/2024/10/14/%E7%A7%8B%E6%8B%9B%E8%8D%A3%E8%80%80%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/</id>
    <published>2024-10-14T14:40:37.000Z</published>
    <updated>2024-11-29T17:06:27.581Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h1><p>这次是预定半小时的线上面试，最后面了35分钟，总体还行，首先过去在等候线上会议室签到，签到之后等下进去特定的会议，然后查验学生证和身份证。</p><p>自我介绍，然后面试官说时间紧咱们挑三个项目讲，就挑了实习+两个横向的项目。</p><p>首先问实习，也是先介绍背景和做了啥，然后是问细节，badcase怎么处理的，用大模型做这个流程相比之前的意义和优势，然后问我是否了解多头LoRA，我说不知道。</p><p>然后问了发了论文的项目，讲完主要内容，然后细节，各个模块是如何做的，都用了什么模型，是否进行了创新，然后问是否可以优化更改，我说可以，不过成本会更高，然后面试官问是否可以那样说更好，我说可以。最后问发的论文是不是人工智能领域的，我说是的。</p><p>然后是第二个横向的项目，这个时候时间不多了，让快点讲，我就快速讲完背景和主要方法和思路，问用了什么做的，我说分割，然后问具体用了什么模型，是否自己训练了，我说用的框架啥的，进行了训练，再问了一点细节。</p><p> 最后又问了我是不是会CPP，我说会一点，但不多，涉及部署的用到一点会一些。</p><p> 没有手撕环节。</p><p> 然后反问是问了他们部分是做啥的，都有哪些业务，后面会不会进行部门匹配，就讲了他部门，然后说后续应该还是会进行业务匹配的。</p><h2 id="二面"><a href="#二面" class="headerlink" title="二面"></a>二面</h2><p> 二面就是主管面了，就完全不问技术了，时间也不是很长，大概也就半小时。</p><p> 自我介绍完，问我将来进去想做AI哪方面的，我说之前视觉、大模型、NLP都做过，一方面看个人能力，还看行业发展趋势和需要。</p><p> 问研究生期间遇到了什么困难，如何解决的。</p><p> 问研究生期间什么时候压力最大，怎么解决的。</p><p> 问自己的优点和缺点是什么。</p><p>然后说我填报的是上海，我说一线城市也都是可以的，年轻要多努力打拼。</p><p>然后问我期望薪酬是多少，我说上海的话要年40以上吧，毕竟是算法类，感觉是不是要的有点高了，应该说可以商量的。</p><p>最后问分配部门的情况和进去做什么的内容，说还要后续匹配。</p><p>中间还有其他问题，但是我没有什么印象特别深的，没有特别难的问题，都是之前被问到过的，回答起来也比较顺畅。</p><p>总的来说，倒是不难，没有问什么特别回答不上来的问题，第二天看还没挂，和理想一样都是二面就主管面，几乎不问技术了。</p><p>过了几天看，已经挂了，看样子大概率是我要价太高了，应该评级不到，40以上应该是ssp，但应该不到，所以直接G。</p>]]></content>
    
    
    <summary type="html">秋招正式批荣耀面试分享。</summary>
    
    
    
    <category term="面试记录" scheme="http://example.com/categories/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="面试记录" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>秋招科大讯飞面试分享</title>
    <link href="http://example.com/2024/10/11/%E7%A7%8B%E6%8B%9B%E7%A7%91%E5%A4%A7%E8%AE%AF%E9%A3%9E%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/"/>
    <id>http://example.com/2024/10/11/%E7%A7%8B%E6%8B%9B%E7%A7%91%E5%A4%A7%E8%AE%AF%E9%A3%9E%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/</id>
    <published>2024-10-11T21:56:37.000Z</published>
    <updated>2024-11-29T17:06:27.581Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h2><p>这次的面试和之前的都不一样，这次问的非常宏观，这应该也和我投的岗位有关，我投的是AI研发工程师，这个和之前投的大部分都是算法工程师还是很不一样的，按照他自己的说法，这个岗是做除了模型性能之外的其他事，模型性能当然是网络结构，调参，其他部分应该就包括他们做的数据自动预处理框架，机器学习平台，推理框架，还有推理引擎，吞吐量和服务部署，还有量化剪枝TensorRT、Openvino这种了。</p><p>面试首先问的还是我的最后一个项目，这个项目涉及一些CPP和量化剪枝，这个问法和前面的也很不一样，问数据从哪里来的，如何处理的，模型是用的创新性的还是网上找的，性能调优调了哪些参数，具体部署如何做的，cpp部分有哪些，量化剪枝是否自己做的。项目包括几个人，自己在其中是什么角色，最后部署服务如何做的。</p><p>然后问前面的一个项目，问这个项目是如何设计的，流程是啥样的，还是几个人，自己在其中做的啥，然后部署怎么做的，这个具体涉及几个部分，我就讲了讲这个服务的设计和数据的流程，最终部署上线的情况，在其中如何根据具体的场景做了针对性的改进。他还是问了问这个平台包括什么部分，我做的具体是那块的平台还是其中的一部分，这块讲清楚之后就问部署之后各个模块之间如何写作，http服务如何做的，都传递哪些参数。最后问了问最后的推理时间是多少，我说了后面试官问是否想过要进行性能优化，我说项目没要求就没做。</p><p>然后问第一个项目，也是问了问pipeline包括几个模块，也是不问模型本身的那些八股，然后我说这块没有多少创新，主要是根据任务设计了利用几个模型连起来做了个系统，然后问这个东西最终是否投入使用，我说这个是最终上线了，然后就是关于系统本身的一些问题，这块没有问太多。</p><p>之后就是几乎每个面试都会问的实习经历了，这块问了不少，关于前面的机器学习系统是如何做的，大模型是如何做的，他们之前的业务流程是什么样的，我做了之后业务流程是什么样的，评价指标是什么。然后是最经典的问题，和机器学习模型相比效果如何，然后是关于业务相关的一些问题。</p><p>最后问了问我是否了解python的gc，我说不太懂，然后问了一个东西我没听过，之后问多线程协程，我说这块我处理数据的时候用过，但是没有仔细研究过，然后是给了一个小场景题，有6个cpu，然后一个几百张图片需要处理，如何设计，一个进程和cpu之间的关系对应，这块我就完全不太懂了，这块跟我前面做的还是很不一样的，特别偏向底层了。</p><p>然后是反问，我就问了问算法工程师、AI工程师、AI研发工程师有什么区别，然后这块大致讲了讲，就结束了。</p><p>总的来说，关于模型部署和系统底层这块我了解的还是不太多，关于量化剪枝部署这块还是要好好学习一下，毕竟从纯算法角度我可能优势不大，这次面试关于这块问的还是挺多的，回答的不太行，感觉面试官也是有点失望的样子，不过这次面试问的问题还是很有意思的，也是我之前没有接触过的。</p><p>不过没想到的是一面竟然过了。</p><h2 id="二面"><a href="#二面" class="headerlink" title="二面"></a>二面</h2><p>10.17晚上七点二面，面试官也很忙，面试首先自我介绍，然后跳过了实习，直接问哪个项目认为做的比较深，然后我就讲了第一个项目，从头讲到尾，然后也是不问模型细节，而是关注流程，然后是问效果，还有怎么部署的，然后我就讲了下fastapi和flask启动服务这些，涉及推理部署这块做的不多，但是整体流程还是都做过的。</p><p>然后是问大模型方面都做过哪些，然后我说实习，就讲了下实习做的工作，第一个点讲了一些，也问了数据，评价指标，和之前的对比效果如何，等等，第二个点没讲完面试官就不让讲了，然后问其他还做过哪些，其他的我倒是没怎么做过，也是学了相关的知识。</p><p>然后是问我后面说的做了RAG相关的，就问让我讲讲，我大致讲了下概念和应用，优劣啥的，然后面试官问向量表示这些工具了解如何，这块我只能简单的介绍了下那些milvus、chroma、faiss这些我了解的不是很多，没有系统的研究过。</p><p>然后问Cpp了解的如何，这块我也是初步会用一些，但是不多，然后问我会不会Java、Golong这些，这些开发的我自然是不会的。</p><p>然后问我是想做哪方面的，是效果还是效率，效果就是模型调优，效率是机器学习平台、推理框架这种，我还是更喜欢效率这块，毕竟在学校做改网络调参的活我是不太喜欢的。</p><p>然后是问我对于挑选工作offer看重哪些地方，我说从公司的长期发展、个人具体做的事情和内容、薪酬这些角度来说，然后面试官问我期望薪酬是多少，我说这个要看城市，综合多家比较来看，大城市更高一些，生活成本也是要考虑的。</p><p>然后问我对科大讯飞了解多少，我说语音这块做的比较好，问其他，我说星火大模型也了解一些，然后从未来发展角度来说，语音这个业务总体还是很看好的。</p><p>然后说我github还经常更新，我说有博客，之前会写一些技术博客，现在主要是面试复盘。</p><p>然后反问，我就问了部门具体的内容和技术栈，这块大致说了下，然后就结束了，然后面试官说会综合一面和二面的情况，等HR联系。</p>]]></content>
    
    
    <summary type="html">秋招正式批科大讯飞技术面试分享。</summary>
    
    
    
    <category term="面试记录" scheme="http://example.com/categories/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="面试记录" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>秋招拼多多面试分享</title>
    <link href="http://example.com/2024/10/10/%E7%A7%8B%E6%8B%9B%E6%8B%BC%E5%A4%9A%E5%A4%9A%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/"/>
    <id>http://example.com/2024/10/10/%E7%A7%8B%E6%8B%9B%E6%8B%BC%E5%A4%9A%E5%A4%9A%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/</id>
    <published>2024-10-10T15:03:37.000Z</published>
    <updated>2024-11-29T17:06:27.577Z</updated>
    
    <content type="html"><![CDATA[<p>先说十一期间，十一当天下午阿里达摩院发消息要一会直接面试，我说下午有事，能否改成明天早晨，然后改完一会，面试官说要不你先笔试吧，我看笔试都已经10.12了，感觉不妙，也只能这样了，然后10.10直接被终止流程了，笔试被取消了。虽然达摩院我肯定去不了，但是这样一个笔试和面试的机会直接无也还是很难受，看来面试笔试尽量还是别推，不然一不小心直接无就难受了。</p><p>说到这不得不说科大讯飞了，九月中的线下面试，提前打电话说线下没有我这个岗的面试官了，然后说后面线上，结果过了三周了都没动静了，估计那边也不缺人了吧，应该也是直接g了。</p><h2 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h2><p>拼多多这次面试我面的也比较一般，过去自我介绍完然后开始问实习的内容，讲完之后开始问细节，大模型测评用的什么标准，具体是什么，如何衡量好坏，样本构造正负样本如何设置的，效果如何评价，然后我说主要用的精确率，极度不平衡的情况下结果是否有可参考性。对语义解释部分如何正则化提取，遇到无法提取的多吗，有多少，如何处理的。</p><p>然后是问的LoRA微调是否了解，原理是啥，如何做的，显存和速度是否有提升，如何体现，在推理过程中显存和速度是否有提升。</p><p>然后是八股，问我微调用的什么模型，我说盘古智子，然后让我讲下模型结构，这块我说都差不多，简单说了下，但是说的不详细。然后问我是否了解注意力机制，这块大致讲了讲，不是很细，然后追问QK相乘为什么要scale，为什么除以根号下向量长度。然后问大模型处理的整个流程是什么。</p><p>最后手撕，先给题目，然后说完思路再做，这次是依次给了两道题。</p><p>第一道是有1，2，5三种硬币若干，求组成价值为21的组合有多少种，这是个背包问题，用动态规划做，然后面试官问了问初始化1什么意义，两层循环是否可以调换。</p><p>第二道题是实现一个开根号的函数，保留n位有效数字，这个题目我写了，不过好像有一点小问题。面试官问了我是否确认这个能实现这个功能</p><p>最后问我是否了解拼多多的工作强度，是否可以接受，可以。然后反问，我问了问部门具体做啥，他们具体根据商家和客户需求找到可能有问题的，然后及时给出平台的措施，也是结合多模态的信息处理，涉及推荐。然后就结束了。</p><p>总体来说感觉面试中答的比较一般，好多问题都准备的不太好，感觉这次面试也是G了。</p>]]></content>
    
    
    <summary type="html">秋招正式批拼多多技术面试分享。</summary>
    
    
    
    <category term="面试记录" scheme="http://example.com/categories/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="面试记录" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>秋招滴滴面试分享</title>
    <link href="http://example.com/2024/09/27/%E7%A7%8B%E6%8B%9B%E6%BB%B4%E6%BB%B4%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/"/>
    <id>http://example.com/2024/09/27/%E7%A7%8B%E6%8B%9B%E6%BB%B4%E6%BB%B4%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/</id>
    <published>2024-09-27T20:20:37.000Z</published>
    <updated>2024-11-29T17:06:27.577Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h2><p>这次面的滴滴，刚好赶上交大线下双选会，就在交大的楼里面了下，面完十分钟就过了。</p><p>过去自我介绍完之后，面试官就问了下我之前的实习主要做的内容，也问了不少细节，不过大体也答了上来。</p><p>然后问了特征工程是如何做的，具体这块我讲了下数据预处理和筛选相关这些，实际场景一般怎么做的。</p><p>问是否做过大规模的分布式的数据处理，我说实验室没有这个条件，这块估计问的可能是hadoop这种，理论估计还是要了解下。</p><p>然后问了一些八股，过拟合如何处理，需要如何调节。</p><p>LoRA微调是什么，需要调节什么参数，啥时候调节啥参数，为啥要这样调节。</p><p>最后是手撕一道算法题，这个是个场景题，题目还很长，已知n个员工每个员工的工资，钱币有100 50 20 10 5 1六种，每个员工的工资都是这六种钱币的组合，现在要找出这n个员工的工资的组合，使得这n个员工的工资的组合的钱币数量最少，然后手撕了出来。</p><p>面完三天写的复盘，面试的时候问的哪些已经忘得差不多了，看后面约二面的时间。</p><h2 id="二面"><a href="#二面" class="headerlink" title="二面"></a>二面</h2><p>10.17二面的还行吧，过去自我介绍完让我选一个印象最深的项目讲，我就没讲实习，讲了第一个项目，然后就问细节，这块问的也挺多的，比如路线是啥样，相比传统方法的优势，遇到了什么问题，怎么解决的，这些都问了。</p><p>然后是八股，问了几个问题</p><ol><li><p>YOLOv1到现在v11都有什么变化，大致说了说变化和大体的结构框架。</p></li><li><p>遇到过拟合欠拟合的时候如何做的，我讲了下小模型情况下从数据、预处理和增强方式、模型、训练方式这些展开讲了讲，还讲了大模型情况下LoRA调节遇到的如何解决这些问题。</p></li><li><p>优化器用的什么，如何调节的，我就从梯度衰减和优化器自动调节这些展开讲了讲。</p></li></ol><p>然后是手撕阶段，出了一个题，给定一个字符串s和一个字符串数组words，（串联字串是指words中所有字符串以任意顺序排列起来的，而不是words中所有元素随机排列），然后求串联字串在s中的起始位置，我就用滑动窗口解决了。</p><p>然后就反问，问部门有哪些需要和技术栈，面试官就讲了下部门情况，然后问我有没有其他offer，我说有几个在排序中，然后就结束了。</p>]]></content>
    
    
    <summary type="html">秋招正式批滴滴技术面试分享。</summary>
    
    
    
    <category term="面试记录" scheme="http://example.com/categories/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="面试记录" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>秋招理想面试分享</title>
    <link href="http://example.com/2024/09/25/%E7%A7%8B%E6%8B%9B%E7%90%86%E6%83%B3%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/"/>
    <id>http://example.com/2024/09/25/%E7%A7%8B%E6%8B%9B%E7%90%86%E6%83%B3%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/</id>
    <published>2024-09-25T19:00:37.000Z</published>
    <updated>2024-11-29T17:06:27.577Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h2><p>开始投的机器学习，最后被调到LLM了，本来以为会问很多大模型八股，实际也没有那么多，还行，面试了38分钟。</p><p>过去首先自我介绍，然后开始问算法八股，第一个是介绍一下特征工程，我就先从传统特征工程来说的，然以在面试官的提示下也说了数据预处理相关的内容。问RNN、LSTM、Transformer的区别，这块是经典八股了，差不多答了。</p><p>然后是问大模型的实习具体做了啥，这块我讲了好多，感觉后面面试官都不是很耐烦了，毕竟这块东西还挺多。然后是经典的问题，既然机器学习方法能做，为什么用大模型做，这块大致答了下。然后面试官问了解CoT不，我说了解一点，面试官说这个任务也是可以用CoT来做的，然后我也简单回答了具体做的相关性。</p><p>最后是手撕，给了个经典题，word1到word2最少的操作，插入、删除、替换，然后手撕了出来。</p><p>最后反问，问部门做啥，不同岗位之间的区别和调整，面试官说虽然这个岗是LLM，不过还是有很多机器学校方法等的内容，然后就结束了。</p><p>总体答的大差不差，不过感觉有一点KPI面，不过也可能是我自己感觉的，毕竟面试官也是很忙的。</p><h2 id="二面"><a href="#二面" class="headerlink" title="二面"></a>二面</h2><p>10.23二面，面了差不多40分钟吧，这次面的感觉还行，这次是主管面，没怎么问技术。</p><p>过去自我介绍完，然后面试官说视觉做的多，我说大模型这块也做了一些，就问目前主流都有哪些大语言模型和视觉大模型，大语言模型我大致介绍和点评了下，然后视觉大模型就不太了解了，多模态大模型简单说了一点。</p><p>然后问我更想做大语言模型还是视觉大模型，我这块犯了个忌讳，我说他们底层都差不多，其实CV和NLP差别还是过大了，直接说差不多还是不太合适，这块我又解释了下我都能做，这块回答的不太好。然后我说的目前技术栈偏向大语言模型，但是从长期发展更看好视觉大模型，视觉大模型的发展还处于比较早期。</p><p>然后是问关于大模型如何赚钱落地和商业模型这块如何看待，这个问题就比较宏观了，就不是技术，而是如何赚钱了。这块我首先谈了下RAG、Agent啥的，面试官说不是技术，而是盈利模式这块。我就大致谈了谈目前大模型各行各业的应用，然后说了下商业模式的一些看法，对于个人、开发者、以及做产品的角度如何看待，关于做产品我还是从交互方式的角度谈了下，大模型可能和新一代的硬件，改变交互方式有关。这块的回答应该还是很不错的，面试官说本来前面的回答让他很不满意想直接给我挂了，但是这个回答他还是很高兴的。然后就是谈了下这个关于这个领域和行业发展后面可能的一些方向之类的，这块感觉还是很不错的。</p><p>然后还是聊关于部门内部两个细分大语言模型和视觉大模型的组，面试官说视觉大模型这块都是博士和院士团队在做，我履历达不到，所以进去还是会给我安排大语言模型这块。</p><p>然后反问，我就问的我过去是否需要什么技术上的学习和准备，面试官说不用，反正进来还是会有相关培训，然后就结束了。</p><p>总体来说，面试前面面的不太行，中后期回答基本还算可以，感觉还是有希望的。</p><h2 id="HR面"><a href="#HR面" class="headerlink" title="HR面"></a>HR面</h2><p>11.27面直接过过了，然后问问题。</p><ol><li>是理想北京，是否接受</li><li>毕业时间</li><li>西电本硕否</li><li>是否都全日制</li><li>是否签三方</li><li>薪酬保密，给不错的薪酬，年终奖</li><li>六险一金</li><li>工作时间和加班情况</li><li>租房情况</li><li>有食堂需要自费</li><li>工作内容和晋升机制</li><li>是否有末位淘汰</li><li>家乡在哪，是否支持</li><li>加微信</li></ol>]]></content>
    
    
    <summary type="html">秋招正式批理想技术面试分享。</summary>
    
    
    
    <category term="面试记录" scheme="http://example.com/categories/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="面试记录" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>秋招蚂蚁面试分享</title>
    <link href="http://example.com/2024/09/24/%E7%A7%8B%E6%8B%9B%E8%9A%82%E8%9A%81%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/"/>
    <id>http://example.com/2024/09/24/%E7%A7%8B%E6%8B%9B%E8%9A%82%E8%9A%81%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/</id>
    <published>2024-09-24T20:40:37.000Z</published>
    <updated>2024-11-29T17:06:27.581Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h1><p>昨天有人加我，说是网商银行的智能引擎部门，主要基于蚂蚁集团大规模数据结合大模型，提升数据的感知和认知能力，帮助千万小商家的信用成长。部门包括多个NLP、大模型、时序和图方向，技术自由度高，且有业务价值。</p><p>然后约了今天上午的一面，今天上午到点是个电话面试，之前还没电话面过。面试首先自我介绍，然后主要讲实习的工作，他们这边应该是大模型比较相关的，所以实习相对契合一点。然后就开始非常细致的讨论实习做的内容，包括很多细节，文件如何处理的，如何表示的，如何训练的，任务是怎么样的，系统的架构，用了哪些机器学习方法，改进使用大模型的意义都有哪些方面，还有如何微调的，用了哪些方面，具体参数如何调整和设置的。然后问到LoRA，问为什么用，原理是什么，需要调整什么，啥时候怎么调整。总之这个问的细致程度基本是其他面试二面的强度，深挖一个项目，还是非常深入的。</p><p>然后面试官说看你简历里面有了解RAG相关内容，然后开始问相关的问题，原理是什么，为什么用RAG，解决了什么问题，还有相关的一些问题，最后问到向量表征都有哪些方法，如何做的，这个确实不是很懂，没怎么研究过。</p><p>然后反问，问了下后面有几面怎么安排，然后就结束了。后面看果然G了</p>]]></content>
    
    
    <summary type="html">秋招正式批蚂蚁技术面试分享。</summary>
    
    
    
    <category term="面试记录" scheme="http://example.com/categories/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="面试记录" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>秋招快手面试分享</title>
    <link href="http://example.com/2024/09/23/%E7%A7%8B%E6%8B%9B%E5%BF%AB%E6%89%8B%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/"/>
    <id>http://example.com/2024/09/23/%E7%A7%8B%E6%8B%9B%E5%BF%AB%E6%89%8B%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/</id>
    <published>2024-09-23T17:11:37.000Z</published>
    <updated>2024-11-29T17:06:27.577Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h1><p>这次面试的岗位是机器学习算法，面了一个小时，这次面试也算有质量。</p><p>过去先简单自我介绍，面试官说你这专业算计算机是吧，那计算机相关的理论你应该会，我说我专业属于计算机，不过学的还是偏向电子信息，然后让讲一下堆和栈的区别，这块没怎么讲清楚，只是简单讲了下定义，这块应该从内存中的开辟使用管理啥的开始说的。毕竟这块也是算基础吧，还是要准备下的，前面这块的都没背。</p><p>然后面试官说有论文，是不是人工智能领域的，我说是的。让讲一下论文，然后我翻出来自己的论文，从前到后讲了一遍，不过前面部分我用的时间太多，讲的有点乱，后面讲的就挺快了，讲完面试官说讲的有点乱，听的不是很清楚。</p><p>然后说去实习了就讲下实习的内容，然后我大致讲了讲，面试官简单问了两个小问题，比如效果不好的时候，如何判断是哪里的问题导致的，怎么改正。</p><p>之后面试官说给个数学题你想下：一个圆上取三点，构成锐角三角形的概率是多少，这个我尬住了，想了半天没思路，然后面试官说构成直角三角形的概率是多少，然后再到锐角，最后还是没回答出来。这块答的感觉不太行，没有体现出遇到未知问题解决问题的能力，这个思考过程不够清晰。</p><p>然后让手撕一道题，找无序数组中第K大的数，这个是一个很经典的题了，我用python堆来做的，写出来自然很简单，写完面试官说你用库实现的太简单，要不换个方法，然后说要不你自己用数组实现一个堆，然后我写不出来，又尬住了半天，然后面试官说让用快排的方法写，写了出来了。</p><p>然后反问环节，问他们部门具体做啥，然后哪方面的，说是搜广推的，还有一点具体的方向，然后刚好一个小时，就结束了。</p><p>然后晚上看，果然已经挂了。</p>]]></content>
    
    
    <summary type="html">秋招正式批快手技术面试分享。</summary>
    
    
    
    <category term="面试记录" scheme="http://example.com/categories/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="面试记录" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>秋招合肥安迅精密技术面试分享</title>
    <link href="http://example.com/2024/09/23/%E7%A7%8B%E6%8B%9B%E5%90%88%E8%82%A5%E5%AE%89%E8%BF%85%E7%B2%BE%E5%AF%86%E6%8A%80%E6%9C%AF%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/"/>
    <id>http://example.com/2024/09/23/%E7%A7%8B%E6%8B%9B%E5%90%88%E8%82%A5%E5%AE%89%E8%BF%85%E7%B2%BE%E5%AF%86%E6%8A%80%E6%9C%AF%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/</id>
    <published>2024-09-23T14:15:37.000Z</published>
    <updated>2024-11-29T17:06:27.577Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h1><p>这次面试的岗位是图像算法工程师，就面了15分钟7秒，特别短，面的不太行，应该也G了。</p><p>过去先自我介绍，介绍完之后面试官说看你简历里面有cpp，面试官说你会C++是吧，然后我说我只是在前面的一个项目中用到了一点，也是去年初了，后面几乎没怎么用到，所以也不是特别会。然后问CPP基础，第一个问题问值传递和引用有什么区别，第二个问题问虚函数定义是什么，这些都不会，毕竟cpp真很久不用了。</p><p>然后问其中一个项目，问是怎么做的，讲了讲，然后问做了什么创新点，当然是没有，把技术路线讲了讲，问这个项目的难点是什么。之后又问了一个项目，这个也问的不多，简单问问就够了。然后问训练模型都调节什么超参数，过拟合和欠拟合如何处理，注意力机制是什么。</p><p>然后反问，问他们这边是偏应用还是开发啥的，说开发的多一点，很多地方要用cpp，所以这块比较需要。</p><p>这个才是目前线上问的时间最短的，实习都没问，毕竟这边是图像算法。感觉不是很契合，第二天通知果然挂了。</p>]]></content>
    
    
    <summary type="html">秋招正式批合肥安迅精密技术面试分享。</summary>
    
    
    
    <category term="面试记录" scheme="http://example.com/categories/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="面试记录" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>秋招比亚迪面试分享</title>
    <link href="http://example.com/2024/09/22/%E7%A7%8B%E6%8B%9B%E6%AF%94%E4%BA%9A%E8%BF%AA%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/"/>
    <id>http://example.com/2024/09/22/%E7%A7%8B%E6%8B%9B%E6%AF%94%E4%BA%9A%E8%BF%AA%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB/</id>
    <published>2024-09-22T19:20:37.000Z</published>
    <updated>2024-11-29T17:06:27.577Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h1><p>这次是线下面，就在南校区C楼面了，过去也不用叫号啥的，就是随便看人自己排队，这个面试就是人事面，相当于填简历的面试。</p><p>过去先看证件，给简历，然后看本硕学历证明，成绩单，四六级，还要本科的成绩单，我没打印，就给记录上没本科成绩单，然后问有没有挂科，当然没有；然后挨个问，问完记录 ，就是纯粹当面填简历信息，问论文，然后把英文论文翻译成中文录进去，问简历号，然后是竞赛有啥，然后记录专利是啥名字；然后挨个问项目是做的啥，记完名字一句话描述做的啥，然后录系统，挨个问完之后问编程语言，然后是研究方向是啥，也是简历上有的信息。</p><p>然后问了问实习，她好像都没看简历，简历上写的有实习，他还问我有没有，我给他指出来她才看到然后对着把信息填系统。</p><p>问完这些然后问家是哪里的，父母是什么工作，将来想去哪里工作，将来想做啥方面的，我说人工智能这块都比较通，这块都可以做。</p><p>后面还是说本科成绩单的事，所以只好加上微信，后面发过去，然后反问，问他们后面有几面，是不是分配，说一面是人事面，二面技术面，然后也是根据人匹配岗位啥的，然后就结束了。</p><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/img/f0e470325b3d2276037b6d9878231f6.jpg" alt="f0e470325b3d2276037b6d9878231f6"></p><p>后面就发现挂了，进入人才库。</p><p>后面10.10被软开捞了，电话打过来问对开发有没有兴趣，我完全没有学过开发，前后端啥的完全不会，问cpp的也不太会，问了数据结构，还有堆栈、ArrayList、LinkedList这些就问了一二十分钟吧，然后就完了。</p><p>然后10.15就直接给offer了，但是13k，这个价在深圳只能说有点离谱，*1.36也没有太大意义。</p><p>offer是高级系统开发工程师。</p>]]></content>
    
    
    <summary type="html">秋招正式批比亚迪面试分享。</summary>
    
    
    
    <category term="面试记录" scheme="http://example.com/categories/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="面试记录" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
</feed>
