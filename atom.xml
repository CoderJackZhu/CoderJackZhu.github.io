<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>学习笔记记录感悟</title>
  
  <subtitle>不乱于心，不困于情，不念过往，不畏将来。</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2024-04-09T15:27:47.760Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Jack Zhu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hexo博客配置Github Actions和仓库分支存储实现自动化编译部署</title>
    <link href="http://example.com/2024/03/03/Hexo%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AEGithub%20Actions%E5%92%8C%E4%BB%93%E5%BA%93%E5%88%86%E6%94%AF%E5%AD%98%E5%82%A8%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%8A%A8%E5%8C%96%E7%BC%96%E8%AF%91%E9%83%A8%E7%BD%B2/"/>
    <id>http://example.com/2024/03/03/Hexo%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AEGithub%20Actions%E5%92%8C%E4%BB%93%E5%BA%93%E5%88%86%E6%94%AF%E5%AD%98%E5%82%A8%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%8A%A8%E5%8C%96%E7%BC%96%E8%AF%91%E9%83%A8%E7%BD%B2/</id>
    <published>2024-03-03T02:19:37.000Z</published>
    <updated>2024-04-09T15:27:47.760Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Hexo博客配置Github-Actions和仓库分支存储实现自动化编译部署"><a href="#Hexo博客配置Github-Actions和仓库分支存储实现自动化编译部署" class="headerlink" title="Hexo博客配置Github Actions和仓库分支存储实现自动化编译部署"></a>Hexo博客配置Github Actions和仓库分支存储实现自动化编译部署</h1><p>这次的这个自动化其实是解决了一个大的问题，之前不带自动化的处理太麻烦了，而且加上之前也没配置好图床，导致每次写博客不仅要准备很久的材料，还要一张一张的上传照片获取链接，然后源文件建了一个github仓库，然后一个仓库只用作github pages，这样的话，每次写博客都要手动编译，使用<code>hexo g</code>然后<code>hexo d</code>，部署，最后使用另外一个仓库提交更改，然后commit，push到github pages仓库，这样很麻烦，所以我就想到了使用github actions自动部署博客，然后使用仓库分支存储图片等资源。（虽然不怎么写博客）<br>相信以后写文章方便之后一定能经常写（大概）。<br>这块我参考了之前浪潮的一次技术讲座，不过那个稍微麻烦了一些，我这里就简化了一下，做了个升级版。</p><h2 id="1-把源文件和github-pages的文件分开"><a href="#1-把源文件和github-pages的文件分开" class="headerlink" title="1.把源文件和github pages的文件分开"></a>1.把源文件和github pages的文件分开</h2><p>source文件和在github上编译好的github pages还是要区分开，这里选择的还是原来github pages的仓库，clone到本地后</p><p>随后建立静态界面的分支，同一个Bash窗口，键入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> 你的Github用户名.github.io <span class="comment"># 进入博客仓库文件夹</span></span><br><span class="line">git branch html <span class="comment"># 新建静态页面分支，存放生成的博客页面</span></span><br></pre></td></tr></table></figure><h2 id="2-main分支文件修改"><a href="#2-main分支文件修改" class="headerlink" title="2. main分支文件修改"></a>2. main分支文件修改</h2><p>首先将你的仓库文件夹清空。</p><p>注：所有清空操作建议在Git Bash窗口中进行，键入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> -f * -r <span class="comment"># 强制递归清空仓库文件夹</span></span><br></pre></td></tr></table></figure><p>这样不会将.git&#x2F;文件夹中的仓库记录(这里此文件夹作为隐藏文件没有显示)删除，否则后续Git无法定位，也就无法继续操作<br>随后将之前博客的文件夹中的所有文件复制到这个仓库文件夹中，注意不要复制.git&#x2F;文件夹，因为这是仓库记录，复制后Git无法定位，也就无法继续操作；另外node_modules&#x2F;文件夹也不需要复制，因为这是node.js的依赖包，不需要上传到仓库中，不然可能会报错。</p><h2 id="3-推送main分支更改"><a href="#3-推送main分支更改" class="headerlink" title="3. 推送main分支更改"></a>3. 推送main分支更改</h2><p>回到仓库文件夹下的Git Bash窗口，输入:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add . <span class="comment"># 添加所有文件</span></span><br><span class="line">git commit -m <span class="string">&quot;update branch main&quot;</span> <span class="comment"># 提交更改</span></span><br><span class="line">git push <span class="comment"># 将修改推送到远程仓库</span></span><br></pre></td></tr></table></figure><h2 id="4-配置GiHub-Actions工作流文件"><a href="#4-配置GiHub-Actions工作流文件" class="headerlink" title="4. 配置GiHub Actions工作流文件"></a>4. 配置GiHub Actions工作流文件</h2><p>在仓库文件夹.github&#x2F;下新建一个目录workflows&#x2F;(注意有两层目录)，在里面新建一个hexo_build_deploy.yml文件，内容如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">Hexo</span> <span class="string">Build</span> <span class="string">&amp;</span> <span class="string">Deploy</span></span><br><span class="line"></span><br><span class="line"><span class="attr">on:</span></span><br><span class="line"><span class="comment"># 触发事件</span></span><br><span class="line">  <span class="attr">push:</span></span><br><span class="line">    <span class="comment"># 排除分支</span></span><br><span class="line">    <span class="attr">branches-ignore:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;html&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 工作流</span></span><br><span class="line"><span class="attr">jobs:</span></span><br><span class="line">  <span class="attr">build:</span></span><br><span class="line">    <span class="attr">runs-on:</span> <span class="string">ubuntu-latest</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Checkout</span> <span class="string">branch</span> <span class="string">main</span></span><br><span class="line">          <span class="attr">uses:</span> <span class="string">actions/checkout@v2</span></span><br><span class="line">          <span class="attr">with:</span></span><br><span class="line">            <span class="attr">ref:</span> <span class="string">main</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 工具安装</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Use</span> <span class="string">Node.js</span></span><br><span class="line">          <span class="attr">uses:</span> <span class="string">actions/setup-node@v3</span></span><br><span class="line">          <span class="attr">with:</span></span><br><span class="line">            <span class="attr">node-version:</span> <span class="string">&#x27;20&#x27;</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">dependencies</span></span><br><span class="line">          <span class="attr">run:</span> <span class="string">npm</span> <span class="string">install</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 构建</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Build</span></span><br><span class="line">          <span class="attr">run:</span> <span class="string">npm</span> <span class="string">run</span> <span class="string">build</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 部署</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Deploy</span></span><br><span class="line">          <span class="attr">uses:</span> <span class="string">JamesIves/github-pages-deploy-action@v4.5.0</span></span><br><span class="line">          <span class="attr">with:</span></span><br><span class="line">            <span class="attr">branch:</span> <span class="string">html</span></span><br><span class="line">            <span class="attr">folder:</span> <span class="string">public</span></span><br></pre></td></tr></table></figure><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/img/20240303020755.png" alt="20240303020755"></p><h2 id="5-修改GitHub仓库设置"><a href="#5-修改GitHub仓库设置" class="headerlink" title="5.修改GitHub仓库设置"></a>5.修改GitHub仓库设置</h2><p>先在博客仓库Settings的Pages中将Branch设置为html<br><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/img/20240303020837.png" alt="20240303020837"></p><p>然后将Actions下的General中的Workflow permissons设置为Read and write permissions<br><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/img/20240303020935.png" alt="20240303020935"></p><h2 id="6-推送更改"><a href="#6-推送更改" class="headerlink" title="6. 推送更改"></a>6. 推送更改</h2><p>然后将更改推送到远程仓库</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit -m <span class="string">&quot;update&quot;</span></span><br><span class="line">git push</span><br></pre></td></tr></table></figure><h2 id="7-等待部署完成"><a href="#7-等待部署完成" class="headerlink" title="7. 等待部署完成"></a>7. 等待部署完成</h2><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/img/20240303021139.png" alt="20240303021139"><br>没有报错的话就完成了<br><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/img/20240303021234.png" alt="20240303021234"><br>https最好也打开。</p><h2 id="一些其他问题"><a href="#一些其他问题" class="headerlink" title="一些其他问题"></a>一些其他问题</h2><p>我在配置过程中碰到了一些其他问题，腾讯云配置DNS我开始弄的有点问题，就重新配的DNS Pod 。</p><p>除此之外，在配置的过程中node_modules是不需要的，我开始这里加了，后面报错，去掉就好了。</p><p>另外一个问题是我把源文件复制过去之后，最后部署完成之后网页是空白，最后发现是theme文件下的butterfly主题文件夹是空的，我把这个文件夹删了，然后重新clone了一遍butterfly主题，再部署就好了。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://www.xdu-inspur.club/blog/site/%E6%8A%80%E6%9C%AF%E6%96%87%E6%A1%A3/get_a_blog.html#_7">https://www.xdu-inspur.club/blog/site/%E6%8A%80%E6%9C%AF%E6%96%87%E6%A1%A3/get_a_blog.html#_7</a></p>]]></content>
    
    
    <summary type="html">本文介绍如何使用Github Actions自动部署博客，并且使用仓库分支存储图片等资源。</summary>
    
    
    
    <category term="博客配置" scheme="http://example.com/categories/%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE/"/>
    
    
    <category term="博客配置" scheme="http://example.com/tags/%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>服务器常见技术问题与技巧</title>
    <link href="http://example.com/2023/09/03/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%B8%B8%E8%A7%81%E6%8A%80%E6%9C%AF%E9%97%AE%E9%A2%98%E4%B8%8E%E6%8A%80%E5%B7%A7/"/>
    <id>http://example.com/2023/09/03/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%B8%B8%E8%A7%81%E6%8A%80%E6%9C%AF%E9%97%AE%E9%A2%98%E4%B8%8E%E6%8A%80%E5%B7%A7/</id>
    <published>2023-09-03T12:29:37.000Z</published>
    <updated>2024-04-09T15:27:47.760Z</updated>
    
    <content type="html"><![CDATA[<h1 id="目前碰到的一些技术问题与知识"><a href="#目前碰到的一些技术问题与知识" class="headerlink" title="目前碰到的一些技术问题与知识"></a>目前碰到的一些技术问题与知识</h1><h2 id="ubuntu安装驱动时候出现的问题"><a href="#ubuntu安装驱动时候出现的问题" class="headerlink" title="ubuntu安装驱动时候出现的问题"></a>ubuntu安装驱动时候出现的问题</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">echo -e “blacklist nouveau\noptions nouveau modeset=0” &gt; /etc/modprobe.d/disable-nouveau.conf</span><br><span class="line">update-initramfs -u</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>修改启动参数:在GRUB菜单中选择Ubuntu启动选项，按下”e”键以编辑启动参数。尝试在命令行中添加”nomodeset”参数，然后按下F10键启动。</p><h2 id="ubuntu安装cuda驱动时候出现报错"><a href="#ubuntu安装cuda驱动时候出现报错" class="headerlink" title="ubuntu安装cuda驱动时候出现报错"></a>ubuntu安装cuda驱动时候出现报错</h2><ul><li>安装显卡驱动需要关闭图形界面，在命令行完成安装（提前下好安装包）<br>关闭图形界面</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl isolate multi-user.target</span><br></pre></td></tr></table></figure><p>开机可能出现黑屏，按<code>ctrl + shift + F2</code>即可进入命令行窗口，登录即可，随后安装驱动，安装完成之后，执行下边命令开机默认进入图形用户界面。  </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl isolate graphical.target</span><br></pre></td></tr></table></figure><p><a href="https://blog.csdn.net/xiaoyuxin1/article/details/124526430">给Ubuntu安装驱动（nvidia）保姆级教程（方法一）_X.等雨停的博客-CSDN博客</a></p><h2 id="ubuntu拨号上网以及各种方式上网设置"><a href="#ubuntu拨号上网以及各种方式上网设置" class="headerlink" title="ubuntu拨号上网以及各种方式上网设置"></a>ubuntu拨号上网以及各种方式上网设置</h2><p>命令行输入即可进入图形管理界面</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nm-connection-editor</span><br></pre></td></tr></table></figure><h2 id="ubuntu22-04-向日葵远程无法连接成功"><a href="#ubuntu22-04-向日葵远程无法连接成功" class="headerlink" title="ubuntu22.04 向日葵远程无法连接成功"></a>ubuntu22.04 向日葵远程无法连接成功</h2><p>需要切换桌面模式</p><h2 id="ubuntu机械盘挂载"><a href="#ubuntu机械盘挂载" class="headerlink" title="ubuntu机械盘挂载"></a>ubuntu机械盘挂载</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">创建挂载路径</span></span><br><span class="line">sudo mkdir /data</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">格式化硬盘</span></span><br><span class="line">sudo mkfs -t ext4 /dev/sda</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">挂载硬盘</span></span><br><span class="line">sudo mount -t ext4 /dev/sda /data</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">开机自动挂载</span></span><br><span class="line">sudo vim /etc/fstab</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">在最后一行加入</span></span><br><span class="line">/dev/sda /data ext4  defaults 0 0</span><br></pre></td></tr></table></figure><h2 id="使用yaml创建虚拟环境"><a href="#使用yaml创建虚拟环境" class="headerlink" title="使用yaml创建虚拟环境"></a>使用yaml创建虚拟环境</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda env create -f environment.yml</span><br></pre></td></tr></table></figure><p>例如：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">transformer</span></span><br><span class="line"><span class="attr">channels:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">pytorch</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">conda-forge</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">defaults</span></span><br><span class="line"><span class="attr">dependencies:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">_libgcc_mutex=0.1=main</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">_openmp_mutex=4.5=1_gnu</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">astor=0.8.1=py39h06a4308_0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">autograd=1.3=pyhd3eb1b0_1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">pip:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">argparse==1.4.0</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">einops==0.3.2</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">nystrom-attention==0.0.11</span></span><br><span class="line"><span class="attr">prefix:</span> <span class="string">/home/ps/anaconda3/envs/transformer</span></span><br></pre></td></tr></table></figure><p>最后的<code>prefix</code>指定环境位置</p><h2 id="使用-gitkeep文件保存空文件夹"><a href="#使用-gitkeep文件保存空文件夹" class="headerlink" title="使用.gitkeep文件保存空文件夹"></a>使用<code>.gitkeep</code>文件保存空文件夹</h2><h2 id="创建一个新的普通用户"><a href="#创建一个新的普通用户" class="headerlink" title="创建一个新的普通用户"></a>创建一个新的普通用户</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo useradd -m ai -s /bin/bash</span><br><span class="line">sudo passwd ai</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">sudo adduser ai sudo</span></span><br><span class="line">su ai</span><br></pre></td></tr></table></figure><ul><li>创建了可以登录的ai用户并使用&#x2F;bin&#x2F;bash作为shell。</li><li>设置密码。</li><li>为ai用户增加管理员权限。</li><li>切换登录用户为ai。</li></ul><h2 id="为普通用户添加sudo权限"><a href="#为普通用户添加sudo权限" class="headerlink" title="为普通用户添加sudo权限"></a>为普通用户添加sudo权限</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">为用户username添加sudo权限</span></span><br><span class="line">sudo usermod -a -G sudo username</span><br><span class="line"><span class="meta prompt_"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">去除用户username的sudo权限</span></span><br><span class="line">sudo usermod -G usergroup username</span><br></pre></td></tr></table></figure><p>给用户授权</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">groups ai</span><br><span class="line">usermod -aG sudo meow</span><br><span class="line">visudo</span><br></pre></td></tr></table></figure><p>删除用户</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo deluser --remove-home ai</span><br></pre></td></tr></table></figure><p>删除用户目录</p><p>查看所有用户</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep bash /etc/passwd</span><br></pre></td></tr></table></figure><h2 id="linux新建用户也使用原来conda环境"><a href="#linux新建用户也使用原来conda环境" class="headerlink" title="linux新建用户也使用原来conda环境"></a>linux新建用户也使用原来conda环境</h2><p>a用户下安装anaconda，默认地址不变，b用户直接不可用，在b用户登录的终端编辑b用户的<code>.bashrc</code>文件，在文档最后一行加入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export PATH=$PATH:/home/&lt;Username&gt;/anaconda3/bin</span><br></pre></td></tr></table></figure><p>保存退出，并<code>source .bashrc</code>，然后<code>conda init</code>就可以了</p><p>高级配置参考<a href="https://zhuanlan.zhihu.com/p/570747928?utm_id=0">Anaconda 多用户共享安装（Ubuntu） - 知乎 (zhihu.com)</a></p><h2 id="给用户授予docker使用权限"><a href="#给用户授予docker使用权限" class="headerlink" title="给用户授予docker使用权限"></a>给用户授予docker使用权限</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo gpasswd -a $USER docker </span><br><span class="line">newgrp docker</span><br></pre></td></tr></table></figure><p><code>$USER</code>可以更换为其他，不换就是默认的。第二步有可能需要输密码，然后输入会发现错误，其实是没有设置密码，需要先设置密码，然后这样更新组</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo chmod a+rw /var/run/docker.sock</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo usermod -aG docker $USER</span><br></pre></td></tr></table></figure><h2 id="neofetch"><a href="#neofetch" class="headerlink" title="neofetch"></a>neofetch</h2><p>方便的查看系统的工具</p><h2 id="卸载图形界面"><a href="#卸载图形界面" class="headerlink" title="卸载图形界面"></a>卸载图形界面</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get remove gnome-shell</span><br><span class="line">sudo apt-get remove gnome </span><br><span class="line">sudo apt-get autoremove</span><br><span class="line">sudo apt-get purge gnome</span><br><span class="line">sudo apt-get autoclean</span><br><span class="line">sudo apt-get clean</span><br><span class="line">reboot</span><br></pre></td></tr></table></figure><h2 id="ssh免密登录"><a href="#ssh免密登录" class="headerlink" title="ssh免密登录"></a>ssh免密登录</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id -i ~/.ssh/id_rsa.pub root@服务器IP</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lscpu</span><br></pre></td></tr></table></figure><h2 id="cudnn-source-problem"><a href="#cudnn-source-problem" class="headerlink" title="cudnn source problem"></a>cudnn source problem</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">W: GPG error: file:/var/cudnn-local-repo-ubuntu2004-8.6.0.163  InRelease: The following signatures couldn&#x27;t be verified because the public key is not available: NO_PUBKEY 323547C4B0FE0A41</span><br><span class="line">E: The repository &#x27;file:/var/cudnn-local-repo-ubuntu2004-8.6.0.163  InRelease&#x27; is not signed.</span><br><span class="line">N: Updating from such a repository can&#x27;t be done securely, and is therefore disabled by default.</span><br><span class="line">N: See apt-secure(8) manpage for repository creation and user configuration details.</span><br></pre></td></tr></table></figure><p>then input <code>sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 323547C4B0FE0A41</code> to solve the problem.</p><p>But it doesn’t work. You can follow the steps below to solve the problem.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cp /var/cudnn-local-repo-ubuntu2004-8.4.1.50/*.gpg /usr/share/keyrings/</span><br></pre></td></tr></table></figure><p>复制到&#x2F;usr&#x2F;share&#x2F;keyrings即可。</p><h2 id="两个盘软raid命令"><a href="#两个盘软raid命令" class="headerlink" title="两个盘软raid命令"></a>两个盘软raid命令</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install mdadm</span><br><span class="line">#格式化两块硬盘</span><br><span class="line">#sudo mkfs.ext4 -F /dev/sdb</span><br><span class="line">#sudo mkfs.ext4 -F /dev/sdc</span><br><span class="line">#mdadm管理 raid0</span><br><span class="line">sudo mdadm --create --verbose /dev/md0 --level=0 --raid-devices=2 /dev/sd&#123;b,c&#125;</span><br><span class="line">#格式化并挂载</span><br><span class="line">sudo mkfs.ext4 -F /dev/md0 sudo mkdir -p /home/md0 sudo mount /dev/md0 /home/md0</span><br></pre></td></tr></table></figure><h2 id="每隔时间杀程序"><a href="#每隔时间杀程序" class="headerlink" title="每隔时间杀程序"></a>每隔时间杀程序</h2><p>kill_python.py</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">while [ true ];do</span><br><span class="line">sleep 5</span><br><span class="line">ps -ef |grep -w  python |grep -v grep | awk &#x27;&#123;print $2&#125;&#x27; | xargs kill -9</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>然后再讲其添加到crontab中，执行crontab -e，添加如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/30 * * * * /usr/bin/sh /aa/bb/cleanFfmpegProcess.sh</span><br></pre></td></tr></table></figure><p>:wq即可。</p><h2 id="关闭服务器自动休眠"><a href="#关闭服务器自动休眠" class="headerlink" title="关闭服务器自动休眠"></a>关闭服务器自动休眠</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl mask sleep.target suspend.target hibernate.target hybrid-sleep.target</span><br></pre></td></tr></table></figure><p>查看系统休眠状态</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl status sleep.target</span><br></pre></td></tr></table></figure><h2 id="设置github的ssh连上github"><a href="#设置github的ssh连上github" class="headerlink" title="设置github的ssh连上github"></a>设置github的ssh连上github</h2><p>生成ssh key</p><p>读取公钥</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat ~/.ssh/id_rsa.pub</span><br></pre></td></tr></table></figure><p>复制粘贴到github。github配置ssh key的地方在<br><a href="https://github.com/settings/keys">https://github.com/settings/keys</a></p><p>测试ssh key是否配置成功，在linux开发机上输入<br>$ ssh -T <a href="mailto:git@github.com">git@github.com</a></p><p>如果出现Hi xxx! You’ve successfully authenticated, but GitHub does not provide shell access 。这就表示已成功连上github</p><p>3、配置git的用户名和邮箱</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git config --global user.name &quot;your name&quot;</span><br><span class="line">$ git config --global user.email &quot;your_email@youremail.com&quot;</span><br></pre></td></tr></table></figure><p>以后可以通过git config –global -l来查看全局设置，git config –global -e来编辑</p><h2 id="更新包导致cuda和驱动版本不对应，NVIDIA-SMI-has-failed-because-it-couldn‘t-communicate-with-the-NVIDIA-driver"><a href="#更新包导致cuda和驱动版本不对应，NVIDIA-SMI-has-failed-because-it-couldn‘t-communicate-with-the-NVIDIA-driver" class="headerlink" title="更新包导致cuda和驱动版本不对应，NVIDIA-SMI has failed because it couldn‘t communicate with the NVIDIA driver"></a>更新包导致cuda和驱动版本不对应，NVIDIA-SMI has failed because it couldn‘t communicate with the NVIDIA driver</h2><p>终端nvidia-smi出现这样，<strong>是内核版本更新的问题，导致新版本内核和原来显卡驱动不匹配</strong></p><p>查看已安装内核</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dpkg --get-selections |grep linux-image</span><br></pre></td></tr></table></figure><p>查看正在使用的内核</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uname -a</span><br></pre></td></tr></table></figure><p>利用命令 <code>ll /usr/src/</code> 可查看下面有一个nvidia-470.82.00文件夹，版本号因电脑而异。</p><p>只需执行两条命令就好：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install dkms</span><br><span class="line">sudo dkms install -m nvidia -v 470.82.00</span><br></pre></td></tr></table></figure><p>（470.82.00表示的是驱动版本号）</p><h3 id="禁止内核自动更新"><a href="#禁止内核自动更新" class="headerlink" title="禁止内核自动更新"></a>禁止内核自动更新</h3><p>1）命令行关闭系统自动更新，使用命令打开文件并编辑</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit /etc/apt/apt.conf.d/<span class="number">10</span>periodic</span><br></pre></td></tr></table></figure><p>将双引号中的“1”全部置“0”即可，修改后保存。</p><p>ubuntu默认启动了自动更新内核，为了避免出现重启系统后遇到错误进入不到系统中去，我们可以进一步关闭内核更新，使用当前内核。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-mark hold linux-image-generic linux-headers-generic </span><br><span class="line">linux-image-generic set on hold.</span><br><span class="line">linux-headers-generic set on hold.</span><br></pre></td></tr></table></figure><p>如果要重启启动内核更新：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-mark unhold linux-image-generic linux-headers-generic</span><br></pre></td></tr></table></figure><h2 id="文件格式问题"><a href="#文件格式问题" class="headerlink" title="文件格式问题"></a>文件格式问题</h2><p>qsub:script is written in DOS&#x2F;Windows text format</p><p>dos格式文件传输到unix系统时，会在每行的结尾多一个^M（&#x2F;r），当然也有可能看不到。但是在vim的时候，会在下面显示此文件的格式，比如 “dos.txt” [dos] 120L, 2532C 字样,表示是一个[dos]格式文件，如果是MAC系统的，会显示[MAC]。因为文件格式的原因有时会导致我们的unix程序，或者shell程序出现错误，那么需要把这些dos文件格式转换成unix格式，方法是</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim dos.txt</span><br><span class="line">:set fileformat=unix</span><br><span class="line">:w</span><br></pre></td></tr></table></figure><h2 id="centos7安装驱动"><a href="#centos7安装驱动" class="headerlink" title="centos7安装驱动"></a>centos7安装驱动</h2><p><a href="https://www.cnblogs.com/2012blog/p/9431432.html">https://www.cnblogs.com/2012blog/p/9431432.html</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --set show_channel_urls yes</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="彻底卸载wsl"><a href="#彻底卸载wsl" class="headerlink" title="彻底卸载wsl"></a>彻底卸载wsl</h2><p>在powerShell上<br>先看还有哪些子系统</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wsl --list --all</span><br></pre></td></tr></table></figure><p>注销子系统</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wsl --unregister Ubuntu</span><br></pre></td></tr></table></figure><h2 id="只读文件系统"><a href="#只读文件系统" class="headerlink" title="只读文件系统"></a>只读文件系统</h2><p>在linux硬盘挂载时候，部分情况磁盘变成ro只读而不是rw<br>一般df查看挂载设备</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">umount -i 挂载路径</span><br></pre></td></tr></table></figure><p>rm -rf 目录&#x2F;文件</p><p>在部分情况下，先使用windows系统，后使用linux，可能有系统挂载问题，即使chmod 777 也没用，出现错误：</p><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/img/image2.png" alt="image"><br>需要重新挂载</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">umount /dev/sda2</span><br></pre></td></tr></table></figure><p>报错target busy<br>杀死使用该目录的进程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fuser  -<span class="built_in">mv</span> -k /dev/sda2</span><br></pre></td></tr></table></figure><p> 再次卸载，卸载成功后重新挂载：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mount /dev/sda2 /data</span><br></pre></td></tr></table></figure><p>报错解决：<br>报错1：“The disk contains an unclean file system (0, 0). Metadata kept in Windows cache, refused to mount. Falling back to read-only mount because the NTFS partition is in an unsafe state. Please resume and shutdown Windows fully (no hibernation or fast restarting.)”。说明是NTFS分区格式错误<br>解决方法：ntfsfix修复，需要安装工具：<br>sudo apt-get install ntfs-3g<br>安装完成后进行ntfsfix修复：<br>sudo ntfsfix &#x2F;dev&#x2F;sda2<br>提示修复成功。                        </p><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/img/image3.png" alt="image3"></p><p>报错2：“没有那个文件或目录”。说明&#x2F;data目录不存在，需要创建。<br>解决方法：media根目录下创建新目录：<br>mkdir &#x2F;media&#x2F;jngk&#x2F;data<br>然后重新挂载，即可挂载成功。<br>mount &#x2F;dev&#x2F;sda2 &#x2F;media&#x2F;jngk&#x2F;data<br>现在该目录就不是只读文件系统了，在该目录下右键，新建文件夹选项也不再是灰色不可选状态了。</p><h1 id="无法将“XXX”项识别为-cmdlet、函数、脚本文件或可运行程序的名称。请检查名称的拼写，如果包括路径，请确保路径正确，然后再试一次"><a href="#无法将“XXX”项识别为-cmdlet、函数、脚本文件或可运行程序的名称。请检查名称的拼写，如果包括路径，请确保路径正确，然后再试一次" class="headerlink" title="无法将“XXX”项识别为 cmdlet、函数、脚本文件或可运行程序的名称。请检查名称的拼写，如果包括路径，请确保路径正确，然后再试一次"></a>无法将“XXX”项识别为 cmdlet、函数、脚本文件或可运行程序的名称。请检查名称的拼写，如果包括路径，请确保路径正确，然后再试一次</h1><p>进入PowerShell 模式<br>Get-ExecutionPolicy -List 查看当前所有作用域<br>1</p><p>上图显示就最后一个作用域有权限，其他作用域都没有权限，那么我们就需要去给它设置权限</p><p>设置权限<br>Set-ExecutionPolicy RemoteSigned -Scope &lt; scopeName &gt;,设置当前用户作用域具备权限，具体设置格</p><p>Set-ExecutionPolicy RemoteSigned -Scope CurrentUser<br>1</p><p>按照上面的格式，执行需要加权限的作用域，然后再去尝试之前的方法，发现就不会报错提示了。</p><h1 id="挖矿病毒处理"><a href="#挖矿病毒处理" class="headerlink" title="挖矿病毒处理"></a>挖矿病毒处理</h1><p>找到病毒文件：</p><p>方法一：由于入侵者对程序的名称做了伪装，无法直接通过其进行查找。因此使用PID入手，查找其在&#x2F;proc里的文件，进而发现了关键路径</p><p>将所有病毒文件展示出来，可以发现关键词miner</p><p>对里面的文件作进一步的查看，可以看到ETH（以太坊）、POOL、WALLET等关键词，实锤中了挖矿病毒</p><p>此外，查看run文件，可以发现这个病毒文件确实做了伪装</p><p>方法二：考虑到入侵者可能会用某些方式将病毒程序作一定的隐藏，这里通过查看用户的计划任务来定位病毒文件，因为病毒文件可能被kill掉而入侵者不会每次都自己手动启动的，肯定会设置自动启动。查看计划任务的命令为crontab -l<br>为了查看病毒文件在服务器上是否有多份，可以使用如下命令一次性查看所有用户的计划任务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> u <span class="keyword">in</span> $(<span class="built_in">cat</span> /etc/passwd | <span class="built_in">cut</span> -d<span class="string">&quot;:&quot;</span> -f1)</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$u</span>&gt;&gt;temp.txt</span><br><span class="line">    crontab -l -u <span class="variable">$u</span> &gt;&gt; temp.txt</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">cat</span> temp.txt</span><br><span class="line"><span class="built_in">rm</span> temp.txt</span><br></pre></td></tr></table></figure><p>方法三：尝试定位病毒文件中的特有关键词，比如“miner”<br>updatedb<br>locate miner</p><h1 id="由于locate命令不能查找-x2F-dev-x2F-shm之类的路径，以防万一可以使用find命令，不过会很慢"><a href="#由于locate命令不能查找-x2F-dev-x2F-shm之类的路径，以防万一可以使用find命令，不过会很慢" class="headerlink" title="由于locate命令不能查找&#x2F;dev&#x2F;shm之类的路径，以防万一可以使用find命令，不过会很慢"></a>由于locate命令不能查找&#x2F;dev&#x2F;shm之类的路径，以防万一可以使用find命令，不过会很慢</h1><h1 id="find-x2F-name-miner"><a href="#find-x2F-name-miner" class="headerlink" title="find &#x2F; -name miner"></a>find &#x2F; -name miner</h1><p>应对方法：</p><p>删除整个病毒文件夹（python），kill相关的PID，并删除相关定时任务（使用命令crontab -e，或者如果只有一个定时任务的话可以用命令crontab -r）</p><p>更改所有用户的密码，并设置一定的密码复杂度（可以使用cracklib）</p><p>移除所有除了管理员以外用户的sudo权限</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">admin=<span class="string">&quot;root,sudo,%sudo&quot;</span> <span class="comment"># 填入管理员账号（前三个不能删）</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> $(<span class="built_in">cat</span> /etc/sudoers|grep  <span class="string">&quot;ALL=(ALL:ALL) ALL&quot;</span>|<span class="built_in">cut</span> -f 1|<span class="built_in">cut</span> -f 1 -d <span class="string">&#x27; &#x27;</span>)</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$i</span></span><br><span class="line">    <span class="keyword">if</span> [ -z <span class="string">&quot;<span class="subst">$(echo $admin|grep $i)</span>&quot;</span> ]</span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;*** deluser <span class="variable">$i</span> sudo&quot;</span></span><br><span class="line">        deluser <span class="variable">$i</span> sudo</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> $(getent group sudo|<span class="built_in">cut</span> -f 4 -d :|<span class="built_in">tr</span> -s <span class="string">&#x27;,&#x27;</span> <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$i</span></span><br><span class="line">    <span class="keyword">if</span> [ -z <span class="string">&quot;<span class="subst">$(echo $admin|grep $i)</span>&quot;</span> ]</span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;*** deluser <span class="variable">$i</span> sudo&quot;</span></span><br><span class="line">        deluser <span class="variable">$i</span> sudo</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>删除现有的所有密钥&amp;授权</p><p>updatedb</p><h1 id="删除公钥-密钥"><a href="#删除公钥-密钥" class="headerlink" title="删除公钥+密钥"></a>删除公钥+密钥</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> pub <span class="keyword">in</span> $(locate .pub|grep .pub$)</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    u=$(ll <span class="variable">$pub</span>|awk <span class="string">&#x27;&#123;printf $3&#125;&#x27;</span>)</span><br><span class="line">    <span class="comment"># 根据UID判断所属用户是否为普通用户</span></span><br><span class="line">    <span class="keyword">if</span> [ 999 -lt $(<span class="built_in">id</span> -u <span class="variable">$u</span>) ]</span><br><span class="line">        <span class="keyword">then</span></span><br><span class="line">            pri=$(<span class="built_in">echo</span> <span class="variable">$&#123;pub%????&#125;</span>)</span><br><span class="line">            <span class="built_in">rm</span> <span class="variable">$pub</span></span><br><span class="line">            <span class="built_in">rm</span> <span class="variable">$pri</span></span><br><span class="line">            <span class="built_in">echo</span> del  <span class="variable">$u</span> <span class="variable">$pub</span> <span class="variable">$pri</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="built_in">echo</span> save <span class="variable">$u</span> <span class="variable">$pub</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="comment"># 删除knowN_hosts</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> $(locate known_hosts|grep known_hosts$)</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">rm</span> <span class="variable">$i</span></span><br><span class="line">    <span class="built_in">echo</span> del <span class="variable">$i</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="comment"># 删除authorized_keys</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> $(locate authorized_keys|grep authorized_keys$)</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">rm</span> <span class="variable">$i</span></span><br><span class="line">    <span class="built_in">echo</span> del <span class="variable">$i</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><h1 id="查看剩余"><a href="#查看剩余" class="headerlink" title="查看剩余"></a>查看剩余</h1><p>updatedb<br>locate .pub|grep .pub$<br>locate known_hosts<br>locate authorized_keys</p><p>可能会遇到某个文件用root权限也删除不了</p><p>如果使用命令lsattr发现该文件的隐藏属性中存在除了e以外的属性，则用命令chattr来移除这些属性</p><p>设置远程连接只能使用密钥，不能使用密码</p><p>禁止使用root账号进行远程连接</p><p>使用终端安全杀毒软件、内网安全监控产品、漏洞扫描设备等专业工具</p><h2 id="查杀病毒"><a href="#查杀病毒" class="headerlink" title="查杀病毒"></a>查杀病毒</h2><p>1、crontab -e 发现一条自启动任务，且为“python”程序，但不确定是否为挖矿程序，暂时保留<br>2、根据挖矿程序PID，进入&#x2F;proc&#x2F;PID目录下检查<br>进入&#x2F;tmp&#x2F;…&#x2F;Python目录<br><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/img/image4.png" alt="image4"><br>通过sudo vim config.ini检查config.ini文件，发现正是挖矿配置文件，从而自启动任务为挖矿任务<br><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/img/image5.png" alt="image5"><br>4、kill挖矿进程，删除挖矿文件及自启动任务，同时关闭挖矿病毒使用的端口<br>5、使用杀毒软件全盘查杀</p><h2 id="在cuda版本过高的情况nvidia官方bug，会出现内存泄露no-such-progress"><a href="#在cuda版本过高的情况nvidia官方bug，会出现内存泄露no-such-progress" class="headerlink" title="在cuda版本过高的情况nvidia官方bug，会出现内存泄露no such progress"></a>在cuda版本过高的情况nvidia官方bug，会出现内存泄露no such progress</h2><p>使用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pip install --upgrade nvidia-ml-py</span><br></pre></td></tr></table></figure><h2 id="fsl-安装"><a href="#fsl-安装" class="headerlink" title="fsl 安装"></a>fsl 安装</h2><p>使用本地安装包<br>解压缩到要安装的文件夹。推荐和我一样解压缩到&#x2F;usr&#x2F;local目录下<br>有可能会出现权限不足的问题无法解压缩，可以在usr目录中打开终端，输入<br>sudo chmod -R 777 local<br>输入密码后，打开权限<br>配置环境变量.bashrc</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export FSLDIR=/usr/local/fsl</span><br><span class="line">export PATH=$PATH:$FSLDIR/bin</span><br><span class="line">source $FSLDIR/etc/fslconf/fsl.sh</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="卸载cuda"><a href="#卸载cuda" class="headerlink" title="卸载cuda"></a>卸载cuda</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/cuda-xx.x/bin/</span><br><span class="line">sudo ./cuda-uninstaller</span><br><span class="line">sudo rm -rf /usr/local/cuda-xx.x</span><br></pre></td></tr></table></figure><h1 id="微星tpm"><a href="#微星tpm" class="headerlink" title="微星tpm"></a>微星tpm</h1><p>微星gl63有TPM的，下面教你如何操作：<br>首先进bios<br>然后按右边的CTRL+SHIFT+左边的ALT+F2开启超级模式。<br>之后在高级选项中找到PCH-FW Configuration<br>找到PTT Configuratio<br>把dTPM改为PTT（如果已经是PTT可以跳过此步）。<br>之后在高级选项中找到Trusted Computing<br>找到Security Device Support，将Disable改为Enable<br>按F10保存。</p>]]></content>
    
    
    <summary type="html">本文记录了一些常见的技术问题与技巧</summary>
    
    
    
    <category term="技术问题" scheme="http://example.com/categories/%E6%8A%80%E6%9C%AF%E9%97%AE%E9%A2%98/"/>
    
    
    <category term="技术问题" scheme="http://example.com/tags/%E6%8A%80%E6%9C%AF%E9%97%AE%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>浅谈《原神》游戏的理解</title>
    <link href="http://example.com/2023/02/07/%E6%B5%85%E8%B0%88%E3%80%8A%E5%8E%9F%E7%A5%9E%E3%80%8B%E6%B8%B8%E6%88%8F%E7%9A%84%E7%90%86%E8%A7%A3/"/>
    <id>http://example.com/2023/02/07/%E6%B5%85%E8%B0%88%E3%80%8A%E5%8E%9F%E7%A5%9E%E3%80%8B%E6%B8%B8%E6%88%8F%E7%9A%84%E7%90%86%E8%A7%A3/</id>
    <published>2023-02-07T00:00:00.000Z</published>
    <updated>2024-04-09T15:27:47.760Z</updated>
    
    <content type="html"><![CDATA[<h1 id="浅谈《原神》游戏的理解"><a href="#浅谈《原神》游戏的理解" class="headerlink" title="浅谈《原神》游戏的理解"></a>浅谈《原神》游戏的理解</h1><h2 id="关于游戏本身"><a href="#关于游戏本身" class="headerlink" title="关于游戏本身"></a>关于游戏本身</h2><p>游戏本身而言是全平台兼容的角色扮演（RPG）游戏，在更多的时候是划分在手游类别的，在手游中属于天花板的水平，但是相比于很多主机游戏以及部分买断制游戏如埃尔登法环、赛博朋克2077、荒野大镖客等游戏还是有不小的差距。作为一款国产二次元游戏，该游戏做的已经很不错了，自从游戏发布以来，月充值流水屡创新高，小部分的重度氪金用户支撑起了大部分的零氪玩家，不氪金也可以体验到游戏的所有内容和大部分游戏体验，氪金的点主要就在于角色和武器需要抽取，而抽取的成本不低，16元一抽，在非常特殊的情况下甚至需要两千多元才能抽取到一个角色，这也是游戏被诟病的主要一点。</p><h2 id="对于游戏受众"><a href="#对于游戏受众" class="headerlink" title="对于游戏受众"></a>对于游戏受众</h2><p>对于游戏受众而言，可以在游戏中体验到不同的国家，在扮演旅行者的过程中体验到多种多样的内容，很多人是冲着游戏角色来的，也有很多是体验高质量的画风等等。</p><p>游戏好的一点是游戏属于内容制作型，属于PVE即玩家对战环境，这样玩家与玩家之间不存在什么竞争关系，这样使得游戏的风气是非常和谐的，在这么长时间的游戏过程中和很多玩家交流，都是非常热心帮忙的，大佬后期长草经常会帮新玩家探索打boss等等；而很多游戏都是属于PVP，即玩家和玩家对战，这样的竞技性游戏很多时候几乎每次玩都会见到互相骂的情况。相比之下，原神游戏的环境还是好了太多。</p><p>相比于买断制游戏，这种无门槛体验所有内容的方式还是更适应实际的需要，很多人天天呼吁买断制如何好，然而叫好不叫座，动辄数百元的游戏，还没开始玩就要先花几百元，还不知道好不好以及能不能玩得来，成本还是太高了，所谓的外国人更喜欢3A大作也并没有，原神在海外的流水也非常高，也很受国外玩家喜爱。对于很多游戏玩家，不仅有很多买断游戏，也在原神中氪金了很多，很多游戏都玩，也有了不同的游戏体验。</p><p>除此之外，游戏制作中还花重金在音乐和画面上，在游戏中也能体验到各国传统的音乐，相关音乐很多时候都是各国的交响乐团演奏的，制作品质不低，高雅的艺术也变得易于接受和体验，对于玩家而言也是很不错的。游戏的制作过程中也发扬了部分中国传统文化，将很多传统傩舞戏剧等内容加入游戏，将非常晦涩难以接近体验的传统文化变得通俗易接受，也让外国人了解到这些内容，虽然不能完全成为文化输出，但是让外国人了解到这些，甚至进一步加深了解还是很好的，相比之前大价钱在各国建设孔子学院而收效甚微，这种潜移默化的方式还是更容易接受，也赚得了外国人的钱。虽然米哈游作为一个公司也是要盈利，但是在盈利的过程中确实对于中国文化的输出起到了一点的作用，这点也是值得肯定的。</p><h2 id="对于网络喷子"><a href="#对于网络喷子" class="headerlink" title="对于网络喷子"></a>对于网络喷子</h2><p>一部分网络喷子的关注点在于《原神》的全平台兼容性，全平台中很多玩家都是手游玩家，而很多玩家是PC玩家或者主机玩家，在游戏圈中存在着所谓的鄙视链，即主机&gt;PC&gt;手游，这种鄙视究其根本在于经济基础，一般家庭很少会有花几千元买游戏机；个人电脑适用性较广；手游成本最低，可以玩手游的人最为广泛。《原神》更多的时候是作为手游来比较，因此很多时候处于鄙视圈底层。这种鄙视深究可以发现，相比人种歧视，很多时候贫富差距的歧视以及地域歧视都不容忽略。</p><p>另一部分原因是由于游戏做的过于好，游戏质量之高远高于之前的其他很多游戏，游戏火出圈后就存在几种问题：</p><ol><li>很多人接触的游戏都是较少的，只有主流的《王者荣耀》、《和平精英》、《英雄联盟》或者吃鸡、守望、CF、csgo等等，部分游戏质量并不高，但是基于社交的游戏更符合大众推广，哪怕游戏质量一般，但是《原神》在手游上的天花板让很多人第一次接触到很好玩的游戏，日常痴迷甚至到处开喷说不如原神，在和《原神》毫无关系的地方刷游戏的相关内容或者引战。</li><li>游戏玩家数量过多导致的问题就是受众过于广泛，作为一款12+的游戏，游戏中可能有小中学生到高中大学生，再到不同年龄阶段和不同文化水平的人，俗话说林子大了什么鸟都有，存在部分不理智的玩家也很正常，这种就类似于一个地区的人有个别不文明就直接认为整个地区的人都有问题，这样的玩家毕竟是少数。很多游戏如英雄联盟等有时候玩家也会有不理智的行为，也不会有很多人认为这一群体就有问题了，同样也是受众广泛，表现很多时候并不同。</li><li>游戏质量高对于竞争对手的压力，相比之前的很多游戏，这都算是降维打击，演示的视频就是实际实机视频，这种就类似于吃了一碗红烧牛肉面，打开方便面发现包装和实物一样，这种在手游中从未遇到过，导致竞品难以望其项背，相比于投巨资做同等级别的游戏还可能竞争不过，抹黑反串引战已经是成本最低的最优解了，因此从两年半前游戏发布以及游戏刚出之前很多媒体都声称黑暗降临，至今很多都在抹黑并在各种无关的地方刷相关内容，或者取相关的名字换头像，然后发引战言论，这也就是最初所谓op的由来。</li><li>很多玩家的跟风心理，部分玩家也没玩过很多游戏，也没体验过《原神》，但是经常在很多地方刷到相关的反对言论就认为游戏如何不好，低人一等并鄙视玩游戏的人，很多这种人都是心智不成熟，玩游戏还能玩出优越感，也有的这些人后来也开始玩原神，也是出于跟风心理，不过这也正常，毕竟很多人都是这样的。</li><li>部分玩家的崇洋媚外心理，认为外国人做的东西就是好的，中国人做的就是不好的，就要抹黑，然而在国外，现在已经过去了两年半，《原神》游戏的流水还是很高，热度也不断，移动端2022年就超过了190亿，实际而言，身边玩原神的很多，大部分都不是手游玩家，实际流水要高很多，游戏质量得到了肯定。在国外都很受欢迎证明外国人也肯定，那么很多时候在国内黑的更多可能会有点奇怪。</li></ol><h2 id="对玩家潜在的风险"><a href="#对玩家潜在的风险" class="headerlink" title="对玩家潜在的风险"></a>对玩家潜在的风险</h2><p>游戏制作较为精美，而且属于角色扮演类型的游戏可能会导致的问题有以下几点：</p><ol><li>游戏较为精美而容易沉溺于虚拟世界，一玩就会花去很多时间，导致用于平时生活的时间减少，相比于很多游戏而言，《原神》用于每日基本任务等内容的时间约为半小时，加上活动抽时间做，实际而言消耗的时间并不是很严重的问题。</li><li>游戏中角色可以见到多样的世界，扮演能力强大的旅行者，而这种体验是在现实生活中不可能体验到的，出于人类的本能，这种落差是肯定会面对的，很多时候游戏玩家每天会花更多的精力在游戏中，进而影响现实生活。</li><li>游戏虽然可以联机，但是主要玩法和内容都是单机游戏，这种在互联网时代普遍存在的问题更严重了：缺乏和人的交流，更多的和游戏内探索互动，可能导致和人交往的能力下降，性格内向以及部分性格障碍，这种潜在的问题对于部分人而言是有影响的。</li><li>游戏的一大卖点在于人物角色，人物的塑造，声音以及服装的设计是非常优秀的。实事求是的来说，一定程度的软色情，很多时候经常“老婆”的这样叫着，很多时候是出于图一乐的心理，但是有时候也会有不小的问题。游戏中的角色很多时候都有一定的人设和意义，代表着一定的特点，很多时候都是较为完美的，让人非常喜爱，但是过于沉迷于虚拟的人往往会提高人的阈值，这样在现实生活中见到正常人都是不完美的时候产生的巨大落差有可能会使得不能很好的面对现实生活中的人。</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>写这些更多的是为了树立一个正确的思想，《原神》也不可能非常完美，但是为了黑而黑或者跟风输出可能并没有什么意义，游戏作为日常生活的一个调剂，适度游戏放松也是很好的，过于沉迷游戏而忽略现实生活则会带来问题，游戏只是个工具，想玩什么就玩什么，但是借此非要打个标签就没必要了，愿读者也有正确的价值观。</p>]]></content>
    
    
    <summary type="html">一点点的理解</summary>
    
    
    
    <category term="生活" scheme="http://example.com/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
    <category term="随笔" scheme="http://example.com/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>ActionFormer论文分享</title>
    <link href="http://example.com/2022/11/09/%E5%AD%A6%E6%9C%AF%E4%BA%A4%E6%B5%81%E5%88%86%E4%BA%ABActionFormer/"/>
    <id>http://example.com/2022/11/09/%E5%AD%A6%E6%9C%AF%E4%BA%A4%E6%B5%81%E5%88%86%E4%BA%ABActionFormer/</id>
    <published>2022-11-09T18:01:37.000Z</published>
    <updated>2024-04-09T15:27:47.760Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ActionFormer论文分享"><a href="#ActionFormer论文分享" class="headerlink" title="ActionFormer论文分享"></a>ActionFormer论文分享</h1><p>由于水平有限，讲的内容也可能会出现不是很正确的地方，欢迎大家批评指正，沟通交流。今天给大家分享的是之前做过的项目中使用到的一个模型，这个模型在时序定位中取得了非常好的效果，这是Papers with Code上在THUMOS14数据集上的结果，当后面几名还是相差一个点的时候，已经比第二名领先了十多个点，因此我拿来分享一下这个模型，讲一下关于模型的结构以及使用感受。</p><h2 id="ActionFormer在THUMOS‘14效果"><a href="#ActionFormer在THUMOS‘14效果" class="headerlink" title="ActionFormer在THUMOS‘14效果"></a>ActionFormer在THUMOS‘14效果</h2><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/img/tal_pwc.png" alt="image-20221106153056010"></p><h2 id="视频领域常用的数据集"><a href="#视频领域常用的数据集" class="headerlink" title="视频领域常用的数据集"></a>视频领域常用的数据集</h2><p><strong>THUMOS14：</strong>数据集包含大量的人类动作在真实环境中开源视频。 动作包括日常生活动作。THUMOS14的主要挑战是动作实例持续时间的巨大变化。具体来说，短动作实例只能持续十分之一秒，而长动作实例可以持续数百秒。</p><p><strong>ActivityNet ：</strong>是目前视频动作分析方向最大的数据集，包含分类和检测两个任务。目前的1.3版本有200个类别，涵盖了200种不同的日常活动。</p><p><strong>EPIC Kitchens 100：</strong>记录了多个多角度、无脚本、本地环境中的厨房场景。它们均来自拍摄者真实的日常饮食生活，并且使用了一种新颖的实时音频评论方法来收集注释。</p><h2 id="时序定位任务"><a href="#时序定位任务" class="headerlink" title="时序定位任务"></a>时序定位任务</h2><p>动作识别可以看作是一个纯分类问题，其中要识别的视频基本上已经过剪辑，即每个视频包含一段明确的动作，视频时长较短，且有唯一确定的动作类别。而在时序动作定位领域，视频通常没有被剪辑，视频时长较长，动作通常只发生在视频中的一小段时间内，视频可能包含多个动作，也可能不包含动作，即为背景。找到视频中动作的起始和结束，很多时候还需要找出其中动作属于哪一类。这一任务类似于时间上的目标检测，因此很多目标检测中的方法也常常拿来应用在这一领域，比如Faster-RCNN中两阶段的思想，先找到候选区域，再筛选，回归修正。有基于滑窗的方法，基于候选区域的方法。而本次讲的ActionFormer则是单阶段无锚框的方法，如图中所示，直接通过Transformer模型预测出每一刻的动作类别和他们这一时间点到动作开始和结束的距离。</p><h2 id="ActionFormer模型结构"><a href="#ActionFormer模型结构" class="headerlink" title="ActionFormer模型结构"></a>ActionFormer模型结构</h2><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/img/base_ActionFormer.png" alt="image-20221106155642020"></p><p>这一模型使用分类分数以及回归分数来计算出动作的情况，分类的分数用于对动作进行分类，回归的分数用于回归出动作的开始和结束的时间点，这个过程就有点像目标检测，事实上，时序定位的很多方法都是从目标检测中借鉴过来的，这里的分类和回归也就像目标检测中找到锚框中目标的类别和对锚框体的回归，不过时序定位的这个任务是在时间上一维的。</p><h3 id="总体结构、输入输出"><a href="#总体结构、输入输出" class="headerlink" title="总体结构、输入输出"></a>总体结构、输入输出</h3><p>模型的输入是首先对视频经过特征提取，根据视频的长度处理成很多个向量，随后把特征向量送入网络，网络的开始是使用卷积进行映射，随后是一个Transformer结构作为编码器，经过这个结构之后，使用了一个轻量级的卷积进行解码，最后使用分类和回归头得到每个时刻的预测类别，开始和结束，最后通过转化变成预测的结果。</p><p>在送入模型训练的时候，只有特征向量是不行的，还是需要一些信息的，比如训练的时候就需要标注信息，片段的起始和末尾，所属的类型，划分为训练还是测试，视频的持续时间和fps帧率信息，在测试的时候不需要标注信息，但是关于视频的帧率和持续时间这些信息还是需要的。</p><p>对于模型的输出，我们需要的是一段时间的开始时刻，结束时刻以及对应的分类，因此问题可以转化为</p><p>对于时间上的每一个时刻，预测出$p(a_t),d^s_t,d^e_t$，其中$p(a_t)$包含C个值，随后使用以下的公式来求出该时刻预测的结果</p><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/img/tal_input.png" alt="image-20221106155554231"></p><p>具体的结构可以划分为以下几个部分：</p><ul><li><p><strong>特征提取</strong></p></li><li><p><strong>使用卷积进行映射</strong></p></li><li><p><strong>Transformer编码器</strong></p></li><li><p><strong>卷积网络解码</strong></p></li><li><p><strong>分类和回归头</strong></p></li><li><p><strong>损失计算</strong></p></li></ul><p>接下来我讲详细讲这几个部分。</p><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/img/action_structure.png" alt="image-20221106160221382"></p><h3 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h3><p>特征提取是视频领域常用的操作，因为视频相比图片来说信息量更大，而且视频中存在着非常多的信息冗余，如果直接把视频放入网络，计算量也会很高，因此很多任务会使用特征提取后的特征进行处理。</p><p>使用预训练好的模型进行特征提取，一般常用双流I3D进行特征提取，双流I3D模型是视频领域中经典的模型，一路使用RGB信息建模空间信息，一路采用光流信息建模时间变化信息。预训练一般使用Kinetics-400这样的大型数据集，提取出1024*帧数的矩阵，向量和视频的帧具有时间上的对应关系，不过经过实验，其他模型如R(2+1)D、TSN等模型也可以，效果差不多。这里提取特征的时候，一般是采用一个特征向量对应16帧，然后每次向后移动1帧的这种形式，具体参数根据需要进行更改，这种得到的特征向量个数其实是总帧数-16，不过这点差别是不影响结果的。</p><h3 id="用卷积进行映射"><a href="#用卷积进行映射" class="headerlink" title="用卷积进行映射"></a>用卷积进行映射</h3><p>使用这一操作，论文中说有助于更好地结合时间序列数据的本地上下文，对于这一点，我的理解是卷积操作使得可以更好的捕捉到相邻时间前后的信息。</p><p>另一点是稳定视觉Transformer的训练，这一点怎么体现的具体论文也没说，我也不是很清楚。</p><h3 id="多尺度Transformer进行编码"><a href="#多尺度Transformer进行编码" class="headerlink" title="多尺度Transformer进行编码"></a>多尺度Transformer进行编码</h3><p>把$Z_0$进行特征表示，乘以一个W<br>$$<br>Q&#x3D;Z^0W_Q, K&#x3D;Z^0W_K, V&#x3D;Z^0W_V<br>$$<br>自注意力输出，这里就是一般Transformer的这种方式，计算一个余弦相似度，然后进行缩放，进行softmax操作，最后和Value相乘得到结果。<br>$$<br>S&#x3D;softmax(QK^T&#x2F;\sqrt(D_q))V<br>$$<br>使用Transfomer的时候这里是通过使用可选的下采样构建特征池化金字塔，从而更好的关注到时间上不同距离的影响。</p><p>作者在后续的消融实验中证明了使用Transformer结构是取得好的效果最重要的原因。</p><p>在编码的时候作者也考虑使用位置编码，但是发现加上之后效果会更差，因此默认是没有使用的</p><h3 id="使用卷积网络进行解码"><a href="#使用卷积网络进行解码" class="headerlink" title="使用卷积网络进行解码"></a>使用卷积网络进行解码</h3><p>对于使用卷积网络进行解码这一步骤中，这里使用的是带有分类和回归头的轻量级卷积网络。分类头检查特征金字塔上所有 L 层的每个时刻 t，并预测每个时刻 t 的动作概率 p(at)。分类网络是使用 3 层 1D 卷积实现的。回归头也检查金字塔上所有 L 级的每一时刻 t。不同之处在于，仅当当前时间步 t 位于某个动作中时，回归头才预测到动作开始和偏移的距离。除此之外，在后处理环节还使用了非极大值抑制（nms）操作，把多余的预测消除掉。</p><h3 id="损失计算"><a href="#损失计算" class="headerlink" title="损失计算"></a>损失计算</h3><p>在损失计算这部分，使用了分类损失和回归损失，仅当预测的分类不是背景的情况下计算回归损失，相应的还设置了权重。</p><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/img/loss_actionformer.png" alt="image-20221106194551616"></p><h2 id="模型缺点与改进方向"><a href="#模型缺点与改进方向" class="headerlink" title="模型缺点与改进方向"></a>模型缺点与改进方向</h2><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul><li><p>最大的问题应该还是在于使用预提取的视频特征，不是端到端的模型，从实际使用来说，特征提取花的时间远大于实际的代码训练与推理，在项目应用中，一个几秒的视频特征提取在1060上需要6秒左右，而模型推理只需要0.02秒，这一问题在应用时感知非常明显。</p></li><li><p>另一问题应该还是使用了大量有标注的信息，而这一信息不易获取而且成本很高。</p></li><li><p>文中还提到了一个问题在于存在预定义动作词汇的约束。</p></li></ul><h3 id="改进方向"><a href="#改进方向" class="headerlink" title="改进方向"></a>改进方向</h3><ul><li><p>我觉得一个问题在于可以通过可学习的前处理操作替代特征提取的操作，特征提取这一步骤使用的预训练好的模型，在使用的时候是不计算梯度，更新参数的。最近我读了一篇视频领域标注的论文SWINBERT，感觉其中的思想可以参考一些，该模型的前面使用了Video Swin Transformer模型，后面使用了稀疏注意力，而且模型对于帧率是自适应的，不需要再指定视频的帧率信息，这一思路或许可以应用在这一领域。</p></li><li><p>另一个问题在于这种方法还是有监督学习，需要使用大量人工标记的视频样本进行学习还有预定义的动作词汇的约束，未来可以从预训练方面还有半监督无监督学习等方向改进，在没有人工标签的情况下从视频和文本语料库中学习。</p></li><li><p>还有一点作者认为目前还缺乏时序动作定位领域的预训练。目前在很多领域都有很大的数据集预训练，随后微调都能取得不错的效果，而在这一领域目前还缺乏。</p></li></ul><h2 id="使用感受"><a href="#使用感受" class="headerlink" title="使用感受"></a>使用感受</h2><ul><li><p>该模型不仅可以预测有开始和结束帧的情况，还可以把开始帧设为0，仅预测结束帧作为关键帧，经过实验发现这样的方法使用起来也没问题，也能取得很好的效果。</p></li><li><p>在项目中，使用该模型效果确实非常好，而且足够轻量级就可以完成一定要求的任务，训练推理都很快。</p></li><li><p>在不调参的情况下，使用其他数据集的参数配置效果就很好。</p></li><li><p>经过实验，在小规模数据集上表现良好。</p></li><li><p>额外增加了特征提取的操作，增加了使用的复杂度，使用起来需要组合，考虑更多的问题。</p></li></ul><p>总而言之，这一模型在时序动作定位领域这一较为小众的方向中取得了不错的成绩，如果是相关方向的值得一看。</p>]]></content>
    
    
    <summary type="html">之前读的论文</summary>
    
    
    
    <category term="时序定位" scheme="http://example.com/categories/%E6%97%B6%E5%BA%8F%E5%AE%9A%E4%BD%8D/"/>
    
    
    <category term="ActionFormer" scheme="http://example.com/tags/ActionFormer/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu的基本使用</title>
    <link href="http://example.com/2022/11/01/ubuntu%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <id>http://example.com/2022/11/01/ubuntu%E7%9A%84%E4%BD%BF%E7%94%A8/</id>
    <published>2022-11-01T23:17:37.000Z</published>
    <updated>2024-04-09T15:27:47.760Z</updated>
    
    <content type="html"><![CDATA[<p>实验室的服务器到了，今天给组里的同学们分享了一下Ubuntu的基本使用，匆忙写了一点相关的东西，顺便发上来，虽然也挺基础的，但反正博客也没多少东西，就记录一下好了。</p><h1 id="文件组织结构"><a href="#文件组织结构" class="headerlink" title="文件组织结构"></a>文件组织结构</h1><p><code>/</code>为根目录，为系统最基本的目录</p><p><code>/home</code>下有用户名的文件夹，该文件夹就是<code>~</code>为主目录，为日常使用的目录</p><p>命令在终端中输入，需要注意当前所在的文件夹</p><h1 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h1><p>创建文件夹</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir xx</span><br></pre></td></tr></table></figure><p>进入文件夹</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd xxx</span><br></pre></td></tr></table></figure><p>可以使用相对路劲和绝对路径</p><p>使用相对目录回到上一级目录</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd ..</span><br></pre></td></tr></table></figure><p>进入根目录</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /</span><br></pre></td></tr></table></figure><p>根目录下的文件非常重要，不要轻易动。</p><p>显示当前文件夹下有哪些文件和文件夹</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls</span><br></pre></td></tr></table></figure><p>后面可以接参数</p><p>如果是接-a则是查看隐藏文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -a</span><br></pre></td></tr></table></figure><p>如果后接-l则是查看详细信息，包括权限</p><p>vim的使用</p><p>vim是一个非常经典的文件编辑工具</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim hello.py</span><br></pre></td></tr></table></figure><p>即可进入编辑</p><p>进入模式之后可以点击键盘的<code>i</code>或者<code>a</code>插入，即可输入，方向键可以控制，详细的命令很多，可以自行查询</p><p>编辑完成之后，需要点击<code>esc</code>退出编辑模式</p><p>随后点击<code>shift + :</code>，就是输入:，然后输入w表示保存，随后输入q表示退出</p><p>即输入<code>:wq</code>完成保存退出，后面有时候需要加上<code>!</code>表示强制</p><h1 id="权限"><a href="#权限" class="headerlink" title="权限"></a>权限</h1><p>root是最高权限，在此状态下不要轻易动一些东西，危险</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo -i</span><br></pre></td></tr></table></figure><p>进入root模式</p><p>或者</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo su</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exit</span><br></pre></td></tr></table></figure><p>退出root模式</p><p>发现文件上有锁或者x说明当前是不能使用的，需要授权</p><p>权限包括三个部分，用户user、组group、其他人other</p><p>权限内容也包括方面，读r、写w、执行x，对应的编码是4、2、1</p><p>如向日葵远程传文件，无法执行，常用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo chmod 777 xxx</span><br></pre></td></tr></table></figure><p>xxx为文件名，包括扩展名</p><p>给文件夹和文件夹下的所有都授权</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo chmod -R 777 xxx</span><br></pre></td></tr></table></figure><p>常用*</p><p>如</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo chmod 777 *</span><br></pre></td></tr></table></figure><p>*一般是指全部，这里就是指当前文件夹下的所有文件（不包含下一级目录）</p><p>很多命令执行没有权限的时候都需要前面加<code>sudo</code></p><p>删除</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo rm xx</span><br></pre></td></tr></table></figure><p>有时候后面会跟-rf，表示不询问，把子目录也都删除，<strong>慎用，非常危险</strong></p><h1 id="日常使用文件"><a href="#日常使用文件" class="headerlink" title="日常使用文件"></a>日常使用文件</h1><p>下载的<code>.deb</code>文件可以直接点击安装，或者使用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo dpkg -i xxx</span><br></pre></td></tr></table></figure><p>也可以安装</p><p><code>.sh</code>文件可以直接输入<code>./xxx.sh</code>执行，或者<code>sh xxx.sh</code>，没有权限的时候先授权</p><p>常用命令，查看有哪些包可以升级</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br></pre></td></tr></table></figure><p>随后执行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt upgrade</span><br></pre></td></tr></table></figure><p>将这些包升级，这是经常需要做的</p><p>apt为一种包管理的工具，有很多时候可以直接</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install xx</span><br></pre></td></tr></table></figure><p>直接下载安装</p><p>snap是ubuntu近些年大力推广的一种包管理的工具</p><h1 id="anaconda的基本使用"><a href="#anaconda的基本使用" class="headerlink" title="anaconda的基本使用"></a>anaconda的基本使用</h1><p>创建虚拟环境可以使用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n &lt;name&gt; python=3.x</span><br></pre></td></tr></table></figure><p>这种方式，随后可以根据<code>requirements.txt</code>的信息执行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><p>安装所需的包</p><p>也可以通过</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda env create -f environment.yaml</span><br></pre></td></tr></table></figure><p>从yaml文件中创建环境并安装包。</p><p>在linux下使用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source activate &lt;name&gt;</span><br></pre></td></tr></table></figure><p>在windows下执行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate &lt;name&gt;</span><br></pre></td></tr></table></figure><p>激活指定的虚拟环境</p><p>使用以下命令可以删除环境</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda remove -n &lt;name&gt; --all</span><br></pre></td></tr></table></figure><h1 id="ssh"><a href="#ssh" class="headerlink" title="ssh"></a>ssh</h1><p>这是一种非常方便的远程控制的方法，广泛使用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh ps@10.120.16.12</span><br></pre></td></tr></table></figure><p>输入密码即可远程命令行控制，ps为用户名，后面的为当前局域网下的ip地址，目前在有线校园网的情况下可以直接这样连接</p><p>pycharm（专业版）、vscode等软件都可以直接使用远程ssh的解释器，本地写代码，然后远程直接跑。</p>]]></content>
    
    
    <summary type="html">一点小记录</summary>
    
    
    
    <category term="Ubuntu" scheme="http://example.com/categories/Ubuntu/"/>
    
    
    <category term="Ubuntu" scheme="http://example.com/tags/Ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读】 Deep High-Resolution Representation Learning for Visual Recognition</title>
    <link href="http://example.com/2022/09/20/HRNet/"/>
    <id>http://example.com/2022/09/20/HRNet/</id>
    <published>2022-09-20T19:57:37.000Z</published>
    <updated>2024-04-09T15:27:47.760Z</updated>
    
    <content type="html"><![CDATA[<h1 id="【论文阅读】-Deep-High-Resolution-Representation-Learning-for-Visual-Recognition"><a href="#【论文阅读】-Deep-High-Resolution-Representation-Learning-for-Visual-Recognition" class="headerlink" title="【论文阅读】 Deep High-Resolution Representation Learning for Visual Recognition"></a>【论文阅读】 Deep High-Resolution Representation Learning for Visual Recognition</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>在计算机视觉中高分辨的表示是非常重要的，HRNet是用于识别的高分辨网络，广泛的用于姿态检测以及语义分割中，也可用于目标检测。</p><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>相比一般的网络，HRNet具有特殊的结构，一般的卷积神经网络往往是随着网络的深入，特征图的分辨率逐渐由高到低，这样的网络结构设计适合一般的视觉问题，视觉空间信息都是冗余的，对信息的精准度要求不高，但是这种结构在面对关键点检测以及语义分割问题的时候就不能很好的完成任务，精准度不够。因此就有了HRNet的结构设计如下图所示：<br><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/img/HRnet1.png" alt="HRnet1"><br>HRNet网络在模型的整个过程中都能保持高分辨率，采用并行的网络，不同的流的分辨率不同，在网络的第n个阶段有n流个网络，从前往后每次下采样一个流，同时在阶段的连接出对信息进行交汇，从高分辨率使用卷积到低分辨率，从低分辨率的流上采样到高分辨率的流，最终得到模型。<br>模型的特色有两点：</p><ul><li>使用并行连接从高到低分辨率的卷积流</li><li>跨分辨率反复交换信息</li></ul><p>使用并行连接使得在整个过程中都保持了高分辨率的表示，使用了跨分辨率的反复融合信息使得模型对于位置具有很强的敏感性，可以较好的完成相关的工作。</p><h2 id="模型的变体"><a href="#模型的变体" class="headerlink" title="模型的变体"></a>模型的变体</h2><p>在HRNet模型中共提出了三种模型的结构，HRNetV1 HRNetV2以及HRNetV2p这三种结构<br><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/img/HRnet2.png" alt="HRnet2"><br>其中V1只使用了融合最后的高分辨率流，这种结构相比V2运算量更小，而在关键点检测任务中和V2版本性能基本没有差别。而V2版本对最后的信息都进行了融合，在语义分割任务中表现较好。V2p则是在V2的基础上形成特征金字塔，更适合目标检测任务。</p><h2 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h2><p>消融实验证明分辨率确实会影响关键的检测的质量，这一点与一般的感觉相符。对多分辨率融合的实验也证明了融合会带来好的性能提升。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>对该模型的研究中可以得到一个结论，针对特定的问题来设计网络架构可能是有用的。此外，一个可能的误解在于分辨率越高，HRNet的内存消耗越大，但是实际是在姿态估计、语义分割以及目标检测中，内存成本并未很高。</p>]]></content>
    
    
    <summary type="html">读论文的记录</summary>
    
    
    
    <category term="姿态估计" scheme="http://example.com/categories/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>今日随笔</title>
    <link href="http://example.com/2022/05/10/%E4%BB%8A%E6%97%A5%E9%9A%8F%E7%AC%94/"/>
    <id>http://example.com/2022/05/10/%E4%BB%8A%E6%97%A5%E9%9A%8F%E7%AC%94/</id>
    <published>2022-05-10T00:00:00.000Z</published>
    <updated>2024-04-09T15:27:47.760Z</updated>
    
    <content type="html"><![CDATA[<h1 id="我终于把图床修好了"><a href="#我终于把图床修好了" class="headerlink" title="我终于把图床修好了"></a>我终于把图床修好了</h1><p>之前gitee的图床用不了，因此这段时间博客都一片404（其实本来也影响不大，毕竟也没几篇博客），今天总算抽出时间修一下，虽然不是什么特别麻烦的事，就是懒。之前的图还真是手动一个一个传的，效率太低，现在用了typora+picgo+github，总算是能用了，方便了不少，希望以后会多更新下吧。之前说的要把大作业都传上去，也能方便后面的学弟学妹，但是后面要么懒，要么就做毕设，最近毕设做的差不多了，又要开始准备做研究生的项目了（虽然确实不多）。</p><p>不过前段时间做的一个有意义的事是联系了两个小伙伴，把自己的考研经历分享到了<a href="https://github.com/CoderJackZhu/XD-AI-graduate_entrance_exam">GitHub</a>，三人成绩还行（平均380+），也上岸了，下一篇就分享一下经历。</p><p>最近在做毕设论文的修改，同时也学习一下深度学习相关领域的知识，毕竟准研究生了，要学的很多东西可以先准备着了。</p>]]></content>
    
    
    <summary type="html">进步了</summary>
    
    
    
    <category term="生活" scheme="http://example.com/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
    <category term="记录生活" scheme="http://example.com/tags/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu 20.04下Pytorch深度学习环境搭建以及常用工具配置</title>
    <link href="http://example.com/2022/04/10/Ubuntu%2020.04%E4%B8%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E4%BB%A5%E5%8F%8A%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E9%85%8D%E7%BD%AE/"/>
    <id>http://example.com/2022/04/10/Ubuntu%2020.04%E4%B8%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E4%BB%A5%E5%8F%8A%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E9%85%8D%E7%BD%AE/</id>
    <published>2022-04-10T00:08:37.000Z</published>
    <updated>2024-04-09T15:27:47.760Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Ubuntu-20-04下Pytorch深度学习环境搭建以及常用工具配置"><a href="#Ubuntu-20-04下Pytorch深度学习环境搭建以及常用工具配置" class="headerlink" title="Ubuntu 20.04下Pytorch深度学习环境搭建以及常用工具配置"></a>Ubuntu 20.04下Pytorch深度学习环境搭建以及常用工具配置</h1><p>作者：CoderJackZhu</p><p>从事计算机相关行业的在今后学习工作过程中总会接触到Linux系统，而且在很多情况下，Windows下可能会出现一些奇奇怪怪的bug，这些问题部分是系统的问题导致的，比如常见的路径中不能带中文。深度学习环境有时候为了更好的管理机器，取得更好的效率也常常采用Linux系统，这里选择Ubuntu是对于个人的萌新而言，应该选择尽量大众些的系统，出问题也容易找到解决办法，比如由于各种误操作，linux系统我至少已经重装过不下二十次了，为了更好的学习相关知识，这样一个系统的搭建也是需要的，这里写出这个博客为了方便使用，也让我之后重装系统的时候不用再找好几个博客了。</p><h2 id="“双系统”中Ubuntu安装"><a href="#“双系统”中Ubuntu安装" class="headerlink" title="“双系统”中Ubuntu安装"></a>“双系统”中Ubuntu安装</h2><p>这里的所说的双系统并不是真正的单个硬盘上多个挂载点的双系统，而是把第二个系统装在移动硬盘里面，这样正常开机默认还是Windows系统，需要选择系统就在进入系统时长按<code>F11</code>（不同品牌电脑不同），选择相应的系统就可以进入了，这样的安装相比一个硬盘上多个挂载点简易不少，配置难度低，而且不易出问题，不然一不小心两个系统都不能用了，这样Linux出了问题只需要直接覆盖重装就可以了，下面是具体步骤：</p><h3 id="准备需要的工具"><a href="#准备需要的工具" class="headerlink" title="准备需要的工具"></a>准备需要的工具</h3><p>这里软件方面需要准备的是，从官方网站上下载Ubuntu的镜像，以及刻录软件。刻录软件使用UltraIso或者balentEtcher都是可以的，balentEtcher相对操作更简易些。</p><p>硬件需要准备的是一个U盘用于制作启动盘，尽量大于等于16G，一个移动硬盘用于安装系统，尽量大于128G，毕竟实际使用过程中数据集也比较大，还是需要给后续留足空间。</p><h3 id="制作启动盘"><a href="#制作启动盘" class="headerlink" title="制作启动盘"></a>制作启动盘</h3><p>安装好Format后选择文件为之前下的系统镜像，选择硬件为U盘，然后点击Flash就可以了，等几分钟安装校验完就可以了。</p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>然后重启并选择使用刚才的U盘启动，就可以进入安装Ubuntu的界面了，正常使用的话选择中文汉语，正常安装，勾选安装第三方软件。这个时候可以插上移动硬盘了，然后输入自己的用户名密码什么的，之后就进入选择安装位置了，这里点击清理磁盘安装就可以了，不然挂载点就很不太好理解，然后下一步点击你插入的那个硬盘，<strong>这里注意别选错</strong>，根据你的硬盘大小就能判断出了，选错其他盘的话可能你的数据就凉了，然后下一步。然后选择地图上的位置为shanghai就可以了，之后就进入安装了，等一会安装完然后点击重新启动，然后根据提示拔掉U盘，然后开机的时候选择那个硬盘启动，这个时候硬盘的名字就已经是Ubuntu了，然后两次回车就可以进入系统了，到这里，系统的安装就算完成了。</p><h2 id="深度学习Pytorch环境配置"><a href="#深度学习Pytorch环境配置" class="headerlink" title="深度学习Pytorch环境配置"></a>深度学习Pytorch环境配置</h2><p>正常使用深度学习环境跑代码，GPU是必不可少，这里只演示GPU版本的pytorch的安装，所需要的工具为Anaconda、CUDA、cuDNN、Pytorch。Anaconda可以用来管理不同版本的环境，CUDA和cuDNN是使用GPU计算所需要的工具这里需要注意相互之间的匹配关系，首先去<a href="https://pytorch.org/">pytorch官网</a>可以看到</p><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/PicGo/202205102136735.png" alt="6"></p><p>因此这里选择CUDA11.3，然后根据CUDA的版本，选择cuDNN的版本，具体在下载cuDNN的时候可以看到。</p><h3 id="安装驱动"><a href="#安装驱动" class="headerlink" title="安装驱动"></a>安装驱动</h3><p>安装NVIDIA驱动有多种方式，比如可以去官网下载最新版，这里介绍最简单的一种，首先打开软件与更新，然后点附加驱动这里，系统默认用的是开源的的驱动，这里选最上面的几个版本高的就可以，这里安装的cuda11.3驱动至少要470以上，然后点击应用更改等一会就可以了。</p><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/PicGo/202205102136053.png" alt="1"></p><p>安装完成之后在命令行输入<code>nvidia-smi</code>就可以看到下图GPU情况，这就说明驱动基本没问题了。</p><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/PicGo/202205102136894.png" alt="4"></p><h3 id="下载安装cuda"><a href="#下载安装cuda" class="headerlink" title="下载安装cuda"></a>下载安装cuda</h3><p>这里找<a href="https://developer.nvidia.com/cuda-downloads">官方网站</a></p><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/PicGo/202205102136125.png" alt="2"></p><p>可以看到这里默认是11.6版本的，这里点击下方中的<code>Archive of Previous CUDA Releases</code>并选择对于的11.3版本，都是11.3的情况下选最后一位高的，之后进入以下界面，选择对应版本，然后先后输入下方的两行，第一行输入命令行，就开始下载了，下载完之后在对应的目录打开终端命令行，然后输入第二行，就开始安装了。</p><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/PicGo/202205102137818.png" alt="3"></p><p>安装过程中看到勾选多个项目的时候，把第一项的X勾选框点下回车取消掉，由于之前已经安装了驱动，所有这里不需要安装里面附带的驱动，然后切换Install并点击回车，等待就可以安装好了。</p><p>然后添加路径，修改<code>.bashrc</code>文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit ~/.bashrc</span><br></pre></td></tr></table></figure><p>#在末尾添加：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export PATH=/usr/local/cuda/bin$&#123;PATH:+:$&#123;PATH&#125;&#125; </span><br><span class="line">export LD_LIBRARY_PATH=/usr/local/cuda/lib64$&#123;LD_LIBRARY_PATH:+:$&#123;LD_LIBRARY_PATH&#125;&#125; </span><br></pre></td></tr></table></figure><p>更新刚才输入的内容，在命令行输入： <code>source ~/.bashrc</code></p><p>安装成功输入<code>nvcc -V</code></p><h3 id="cuDNN的安装"><a href="#cuDNN的安装" class="headerlink" title="cuDNN的安装"></a>cuDNN的安装</h3><p>到<a href="https://developer.nvidia.com/cudnn">官网</a>下载文件：点击如图<code>Download cuDNN</code>按钮。下载需要NVIDIA的账号，没有的需要先注册一个。</p><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/PicGo/202205102137133.png" alt="5"></p><p>然后进入<a href="https://developer.nvidia.com/rdp/cudnn-archive#a-collapse742-10">下载界面</a>并选择Previous Archive</p><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/PicGo/202205102137217.png" alt="7"></p><p>选择CUDA11.x对于的cuDNNv8.2 选择Runtime Library版的deb文件进行下载：</p><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/PicGo/202205102137992.png" alt="8"></p><p>安装cuDNN过程与CUDA类似：<br>在下载的文件的文件夹里面打开终端，执行命令<code>sudo dpkg -i &lt;name&gt;</code>，其中<code>&lt;name&gt;</code>为刚才下载的deb文件名<br>执行命令<code>sudo apt install &lt;name&gt;</code>,其中<code>&lt;name&gt;</code>要和自己下载的cudnn版本匹配，比如这里是libcudnn8</p><h2 id="安装Anaconda"><a href="#安装Anaconda" class="headerlink" title="安装Anaconda"></a>安装Anaconda</h2><p>Anaconda用于控制版本管理，直接在系统的python里装不太方便，库的控制也不那么直观，使用Anaconda之后会方便很多。</p><p>这里直接从<a href="https://www.anaconda.com/products/individual">官网</a>下载就可以，速度也不错，下载完之后在下载的文件夹打开终端，这里重点，命令行不要输入<code>sudo</code>，直接<code>sh &lt;name&gt;</code> <code>name</code>为刚才下的文件名然后可以了，一路回车过完协议书，然后yes同意，然后要么回车要么yes就可以了。千万别在命令行前面加<code>sudo</code>，这样anaconda3的文件夹就安装在<code>root</code>下了，这样感觉有时候不方便；直接<code>sh</code>就可以安装在你的主目录下，装好退出命令行就可以用了。</p><p>安装过程先一路回车，然后按要求都yes就好。</p><p>安装后退出命令行，然后重新进入命令行，然后输入<code>conda</code>，若出现如下则证明安装成功，若出现command not found则重启系统，若还不行则需要添加环境变量。</p><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/PicGo/202205102137141.png" alt="10"></p><h2 id="添加环境变量"><a href="#添加环境变量" class="headerlink" title="添加环境变量"></a>添加环境变量</h2><p>输入</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure><p>再执行conda，若好则安装结束，否则手动添加环境变量</p><p>输入命令</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim ~/.bashrc</span><br></pre></td></tr></table></figure><p>若vim未安装，先安装，可以使用<code>sudo apt install vim</code>安装（或者使用<code>sudo gedit ~/.bashrc</code>也可打开文件），然后执行上述命令，然后在文件的最后添加，这里的内容不要直接复制，根据自己的用户名来定</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export</span><br><span class="line">PATH=/home/&lt;自己的用户名&gt;/anaconda3/bin:$PATH</span><br></pre></td></tr></table></figure><p>输入完成后点击<code>ESC</code>, 然后输入<code>:wq</code>保存退出.</p><p>然后更新环境变量:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure><p>输入conda,检查是否配置成功。</p><h2 id="创建环境并安装PyTorch"><a href="#创建环境并安装PyTorch" class="headerlink" title="创建环境并安装PyTorch"></a>创建环境并安装PyTorch</h2><p>安装后一般应用栏里是没有这个软件的，需要在命令行中输入<code>anaconda-navigator</code>等待进入就可以了，然后点左方的environment然后点下方的加号创建环境，想个环境的名字，选择需要的python版本，这里也可以使用命令来创建</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n &lt;环境名&gt; python=3.8</span><br></pre></td></tr></table></figure><p>等待创建完成后在命令行中输入<code>conda info -e</code>即可查看现有哪些环境</p><p>然后进入相应的环境输入下面命令，其中这里使用的环境名为<code>env1</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source activate env1</span><br></pre></td></tr></table></figure><p>即可激活，若为windows下则为<code>conda activate env1</code>。</p><p>这样就进入环境了，随后输入pytorch官网上的命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch</span><br></pre></td></tr></table></figure><p>如果速度慢，则需要换源，一般默认使用清华源为以下命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line"></span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge</span><br><span class="line"></span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/</span><br><span class="line"></span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br><span class="line"></span><br><span class="line">conda config --set show_channel_urls yes</span><br></pre></td></tr></table></figure><p><strong>或者</strong>打开主目录下的隐藏文件<code>.condarc</code>，将其内容整体更换为以下内容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ssl_verify: true</span><br><span class="line">show_channel_urls: true</span><br><span class="line"></span><br><span class="line">channels:</span><br><span class="line">  - http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/win-64/</span><br><span class="line">  - http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/win-64/</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>然后运行 <code>conda clean -i</code> 清除索引缓存。</p><p>这时候安装命令就要把最后的<code>-c pytorch</code>去掉，变成</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch torchvision torchaudio cudatoolkit=11.3</span><br></pre></td></tr></table></figure><p>就可以很快的下载了，也可以使用<a href="https://download.pytorch.org/whl/torch_stable.html">pytorch离线安装下载</a>直接下载whl文件，然后在命令行中进入下载的文件夹，然后输入</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch-<span class="number">1.9</span><span class="number">.0</span>+cu111-cp38-cp38-win_amd64.whl</span><br></pre></td></tr></table></figure><p>这样就可以安装了，若为linux则将<code>win_amd64</code>改为<code>linux_x86_64</code>即可。</p><p>若为单次换下载换源则命令为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple/  </span><br></pre></td></tr></table></figure><p>在后面加上需要安装的库名字即可。</p><h2 id="验证安装成功"><a href="#验证安装成功" class="headerlink" title="验证安装成功"></a>验证安装成功</h2><p>若全部安装完成，则新建一个python脚本hello.py，内容如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line">print(torch)</span><br><span class="line">print(torchvision)</span><br><span class="line">print(torch.cuda.is_available())</span><br><span class="line">x=torch.randn(5, 3)</span><br><span class="line">print(x)</span><br><span class="line">print(torch.cuda.device)</span><br><span class="line">print(torch.__version__)</span><br><span class="line">print(torchvision.__version__)</span><br><span class="line">print(torch.version)</span><br><span class="line">print(torch.version.cuda) # Corresponding CUDA version</span><br><span class="line">print(torch.backends.cudnn.version()) # Corresponding cuDNN version</span><br><span class="line">print(torch.cuda.get_device_name(0)) # GPU type</span><br></pre></td></tr></table></figure><p>即可查看详细情况，若cuda可用这里显示true就说明安装成功。</p><h2 id="常用软件"><a href="#常用软件" class="headerlink" title="常用软件"></a>常用软件</h2><p>深度学习环境其他非常常用的软件一般还有VScode和Pychram，一般这两个都安装比较好。</p><p>BT下载以及磁力链下载很多时候是需要的，因此需要下载工具</p><p>下载工具可以用Free Download Manger，还是非常好用的，还有qbittorrent和Motrix作为备用下载软件，这两个软件下载后不用安装，需要用的时候打开，也非常不错。</p><p>其他比如截屏剪切板等功能用utools也挺好，不过高级功能后来收费了。</p><h2 id="windows下安装的差异"><a href="#windows下安装的差异" class="headerlink" title="windows下安装的差异"></a>windows下安装的差异</h2><h3 id="更新驱动"><a href="#更新驱动" class="headerlink" title="更新驱动"></a>更新驱动</h3><p>正常使用的话，下载GeForce Experience然后把驱动更新到最新版即可，或者手动下载驱动，没有特殊需要的话默认最新版就好。</p><h3 id="安装cuda和cudnn"><a href="#安装cuda和cudnn" class="headerlink" title="安装cuda和cudnn"></a>安装cuda和cudnn</h3><p>主体部分和linux下大同小异，按要求下载安装对应版本即可，安装cuda后打开命令行输入</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc -V</span><br></pre></td></tr></table></figure><p>返回版本号说明安装cuda成功。</p><p>不过cudnn这里下载完后是复制到cuda对应的bin目录里面，一般是C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA。</p><p>安装后有时候不能使用则需要添加环境变量，在系统环境变量里的Path项下添加几个路径</p><p>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1</p><p> 　　C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\lib\x64</p><p>安装完成后进入路径然后运行测试，成功则为以下界面。</p><p><img src="https://gcore.jsdelivr.net/gh/CoderJackZhu/bloggallery/PicGo/202205102138180.png" alt="11"></p><p>然后运行测试的代码即可。</p>]]></content>
    
    
    <summary type="html">一点小记录</summary>
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>考研后的思考</title>
    <link href="http://example.com/2021/12/29/%E6%88%91%E7%9A%84%E7%94%9F%E6%B4%BB/"/>
    <id>http://example.com/2021/12/29/%E6%88%91%E7%9A%84%E7%94%9F%E6%B4%BB/</id>
    <published>2021-12-29T00:08:37.000Z</published>
    <updated>2024-04-09T15:27:47.760Z</updated>
    
    <content type="html"><![CDATA[<h1 id="考研后的感想"><a href="#考研后的感想" class="headerlink" title="考研后的感想"></a>考研后的感想</h1><h1 id="想法"><a href="#想法" class="headerlink" title="想法"></a>想法</h1><p>今天是考研后的第二天晚上，考研生活算是过去了，然后就是之后的新生活了，对于之后的安排，目前来看，主线是做毕业设计，在期间可以学习一些东西。我计划近期将之前做过的大作业再复习一遍，然后整理出来，发到博客里，这不是什么大的任务，我打算先从这样的小事做起，慢慢学知识。毕竟，在有目标的情况下很多时候还不一定能一直坚持做事，现在时间比较闲了，能做多少事就比较随缘了。</p>]]></content>
    
    
    <summary type="html">反内卷而不躺平</summary>
    
    
    
    <category term="生活" scheme="http://example.com/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
    <category term="生活" scheme="http://example.com/tags/%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title>机器学习课程报告——波士顿房价预测</title>
    <link href="http://example.com/2021/06/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E6%8A%A5%E5%91%8A%E2%80%94%E2%80%94%E6%B3%A2%E5%A3%AB%E9%A1%BF%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B/"/>
    <id>http://example.com/2021/06/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E6%8A%A5%E5%91%8A%E2%80%94%E2%80%94%E6%B3%A2%E5%A3%AB%E9%A1%BF%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B/</id>
    <published>2021-06-18T12:29:37.000Z</published>
    <updated>2024-04-09T15:27:47.760Z</updated>
    
    <content type="html"><![CDATA[<h2 id="摘-要"><a href="#摘-要" class="headerlink" title="摘 要"></a>摘 要</h2><p>在这次大作业中我完成了波士顿房价预测模型的实现, 波士顿房价预测是一个经典的回归模型。<br>在本次实验中, 首先对数据的分布情况以及特征信息, 相关性信息都进行了查看, 并分别对每个特征的相关性信息进行了分析, 并筛选掉无用的特征, 更好的对结果进行预测。<br>然后根据特征的信息与房价存在线性和非线性相关的关系, 这里依次选择了神经网络预测模型以及线性模型对房价的结果进行了预测, 并检验其效果。这里采用了 sklearn 中的库函数来进行训练集和测试集的划分,将 (30%) 的部分划分为测试集。<br>对于神经网络模型, 采用的是一个三层的全连接网络, 通过均方损失函数和 Adam 优化器对网络的参数进行更新, 最终使得网络可以更好的进行预测。对于线性模型, 采用了 sklearn 中的线性回归函数进行预测。<br>对于两者都进行了与实际值的对比, 并计算方差和相关系数, 从<br>而更好的对比了两者的效果差别。<br>关键词: 特征选择 神经网络 线性模型</p><h2 id="目-录"><a href="#目-录" class="headerlink" title="目 录"></a>目 录</h2><p>1 背景介绍 1<br>1.1 问题描述 1<br>2 方法 1<br>3 代码实现 1<br>3.1 读取数据及预处理 1<br>3.2 神经网络预测模型实现 3<br>3.3 线性模型 6<br>4 试验结果 6<br>4.1 实验分析 6<br>4.2 对比 13<br>5 结论 16<br>6 总结 16<br>A 程序代码 17</p><h2 id="1-背景介绍"><a href="#1-背景介绍" class="headerlink" title="1 背景介绍"></a>1 背景介绍</h2><h2 id="1-1-问题描述"><a href="#1-1-问题描述" class="headerlink" title="1.1 问题描述"></a>1.1 问题描述</h2><p>在本次的机器学习课程设计中需要选择一个项目, 应用机器学习算法到真实世界的任<br>务中去, 这里我选择了机器学习的经典案例: 波士顿房价预测任务。<br>波士顿房价数据说明: 此数据源于美国某经济学杂志上, 分析研究波士顿房价 (Boston HousePrice) 的数据集。数据集中的每一行数据都是对波士顿周边或城镇房价的情况描述, 下面对数据集变量说明, 数据集包含了 506 组数据, 一共 14 个属性, 为以下内容:<br>CRIM: 城镇人均犯罪率 ZN: 住宅用地所占比例<br>INDUS: 城镇中非住宅用地所占比例 CHAS: 虚拟变量, 用于回归分析 NOX: 环保指数<br>RM: 每栋住宅的房间数<br>AGE: 1940 年以前建成的自住单位的比例 DIS: 距离 5 个波士顿的就业中心的加权距离 RAD: 距离高速公路的便利指数 TAX: 每一万美元的不动产税率 PTRATIO: 城镇中的教师学生比例 B: 城镇中的黑人比例<br>LSTAT: 地区中有多少房东属于低收入人群 MEDV: 自住房屋房价中位数 (也就是均价)</p><h2 id="2-方法"><a href="#2-方法" class="headerlink" title="2 方法"></a>2 方法</h2><p>波士顿房价预测为一个回归模型, 回归模型的研究范围可以包括线性回归, 以及神经网络预测模型等多种, 这里实现了线性回归以及神经网络回归 [1]。</p><h2 id="3-代码实现"><a href="#3-代码实现" class="headerlink" title="3 代码实现"></a>3 代码实现</h2><h2 id="3-1-读取数据及预处理"><a href="#3-1-读取数据及预处理" class="headerlink" title="3.1 读取数据及预处理"></a>3.1 读取数据及预处理</h2><p>首先进行读取数据, 然后对数据预处理, 首先要清楚数据的分布信息, 这里使用了直方图以及箱图来观察, 然后依次查看数据的 13 个特征与房价之间的关系, 便于进行后续处理, 具体代码如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">column_names = [<span class="string">&#x27;CRIM&#x27;</span>, <span class="string">&#x27;ZN&#x27;</span>, <span class="string">&#x27;INDUS&#x27;</span>, <span class="string">&#x27;CHAS&#x27;</span>, <span class="string">&#x27;NOX&#x27;</span>, <span class="string">&#x27;RM&#x27;</span>, <span class="string">&#x27;AGE&#x27;</span>, <span class="string">&#x27;DIS&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;RAD&#x27;</span>, <span class="string">&#x27;TAX&#x27;</span>, <span class="string">&#x27;PTRATIO&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;LSTAT&#x27;</span>, <span class="string">&#x27;PRICE&#x27;</span>]</span><br><span class="line">all_data = pd.read_csv(<span class="string">&#x27;./housing.csv&#x27;</span>, header=<span class="literal">None</span>,delimiter=<span class="string">r&quot;\\&amp;+&quot;</span>,</span><br><span class="line">names=column_names)</span><br><span class="line">all_data.hist()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">all_data.describe()</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">10</span>)) plt.boxplot(all_data) plt.show()</span><br><span class="line">corr \( = \) all_data.corr()</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">sns.heatmap(corr,annot=<span class="literal">True</span>, \(&#123;\text&#123;cmap=<span class="string">&#x27;twilight_r&#x27;</span>)&#125;&#125;^&#123;&#123;\prime&#125;&#125;\) data=all_data.iloc[:,:-<span class="number">1</span>] label=all_data.iloc[:,-<span class="number">1</span>]</span><br><span class="line">data=np.array(data,dtype=<span class="built_in">float</span>) label=np.array(label, dtype=<span class="built_in">float</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">13</span>):</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">7</span>)) plt.grid()</span><br><span class="line">plt.scatter(data[:,i],label,s=<span class="number">5</span>) \<span class="comment"># 横纵坐标和点的大小 plt.title(column_names[i]) plt.show()</span></span><br><span class="line">uns \(F = \lbrack\rbrack\<span class="comment">#\) 次要特征下标</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(data.shape[<span class="number">1</span>]): <span class="keyword">if</span> column_names [i] == <span class="string">&#x27;CHAS&#x27;</span>: unsF.append(i)</span><br><span class="line">data \( = \) np.delete(data,unsF,axis=<span class="number">1</span>) \<span class="comment"># 删除次要特征 uns \(T = \lbrack\rbrack\#\) 房价异常值下标</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(data.shape[<span class="number">1</span>]): <span class="keyword">if</span> label[i] &gt; <span class="number">46</span>: unsT.append(i)</span><br><span class="line">data \( = \) np.delete(data,unsT,axis=<span class="number">0</span>) \<span class="comment"># 删除样本异常值数据</span></span><br><span class="line">label \( = \) np.delete(label,unsT,axis=<span class="number">0</span>) \<span class="comment"># 删除异常房价</span></span><br></pre></td></tr></table></figure><p>在查看完每个特征的信息后, 可以根据实际情况对数据无关部分以及异常的结果进行删改操作, 从而使得结果更加接近实际, 代码实现这里对于和结果相关性不大的特征进行了删除, 也去掉了部分异常高的房价。<br>在查看数据的分布信息后可以看到只有少部分数据的分布和房价是线性相关的, 大部分都不是明显的线性关系, 因此只采用线性模型进行预测可能会结果与实际差别较大, 因此这里对线性模型以及神经网络模型都进行了是实现, 并对比其结果的差别, 从而更好的进行结果分析。</p><h2 id="3-2-神经网络预测模型实现"><a href="#3-2-神经网络预测模型实现" class="headerlink" title="3.2 神经网络预测模型实现"></a>3.2 神经网络预测模型实现</h2><p>对于神经网络的模型, 这里使用的是简单的全连接方式, 用三层的网络来进行预测, 损失函数为均方损失, 优化器为 Adam, 使用 gpu 进行计算, 迭代次数为 1000 次, 训练过程的损失变化也记录下来, 然后将预测的房价与实际的房价进行对比, 即可得出预测的效果, 具体代码如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">data=torch.tensor(data, dtype=torch.<span class="built_in">float</span>) label=torch.tensor(label, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(data,label, test_size</span><br><span class="line">\( = <span class="number">0.3</span>\) ,random_state \( = <span class="number">4</span>\) )</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model, device, train_loader, optimizer, epoch, criterion</span>): model.train() loss \( = <span class="number">0.0</span>\)</span><br><span class="line"><span class="keyword">for</span> i, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader): data, target = data.to(device), target.to(device) optimizer.zero_grad() output \( = \) model (data)</span><br><span class="line">loss = criterion(output, target.view_as(output)) loss.backward() optimizer.step() <span class="keyword">if</span> i \% \(<span class="number">100</span> = = <span class="number">0</span>\) :</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Train Epoch: &#123;&#125; Loss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>( epoch, loss.item()/<span class="built_in">len</span>(train_loader)))</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">model, device, test_loader, criterion</span>):</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">test_loss \( = <span class="number">0</span>\)</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line"><span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">data, target = data.to(device), target.to(device) output \( = \) model (data)</span><br><span class="line">test_loss += criterion(output, target.view_as(output)).item() \<span class="comment">#</span></span><br><span class="line"><span class="built_in">sum</span> up batch loss</span><br><span class="line">test_loss /= <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Test set: Average loss: &#123;:.4f&#125;\\n&#x27;</span>.<span class="built_in">format</span>( test_loss)) <span class="keyword">return</span> test_loss <span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module): <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line"><span class="built_in">super</span> (Net, self).__init__() self.fc1 = nn.Linear \((<span class="number">12</span>,<span class="number">128</span>)\) self.fc2 = nn.Linear \((<span class="number">128</span>,<span class="number">1</span>)\) <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>): \(x = \operatorname&#123;self&#125;fc1(x)\) \(\mathrm&#123;x&#125; = \mathrm&#123;F&#125; &#123;\cdot&#125; \mathrm&#123;relu&#125;\left( \mathrm&#123;x&#125; \right)\) \(x = \operatorname&#123;self&#125;fc2(x)\) <span class="keyword">return</span> \(x\)</span><br><span class="line">device \( = \) torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>) model=Net().to(device)</span><br><span class="line">optimizer-torch.optim. Adam (params=model.parameters()) criterion=nn.MSELoss()</span><br><span class="line">trainset=TensorDataset(X_train, y_train)</span><br><span class="line">trainloader=DataLoader(trainset,batch_size=<span class="number">64</span>,shuffle=<span class="literal">True</span>,num_workers=<span class="number">0</span>) testset=TensorDataset(X_test, y_test)</span><br><span class="line">testloader=DataLoader (testset,batch_size=<span class="number">64</span>,shuffle=<span class="literal">False</span>,num_workers=<span class="number">0</span>) epoch_list,loss_list \( = \lbrack\rbrack\) ,[] <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span> \((<span class="number">1</span>,<span class="number">1000</span>)\) :</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">train(model, device, trainloader, optimizer, epoch, criterion)</span><br><span class="line">test_loss=test(model, device, testloader, criterion)</span><br><span class="line">epoch_list.append(epoch)</span><br><span class="line">loss_list.append(test_loss)</span><br><span class="line">fig \( = \) plt.figure(figsize=(<span class="number">20</span>,<span class="number">10</span>))</span><br><span class="line">plt.plot(epoch_list, loss_list)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;error&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read</span>(<span class="params">test_loader</span>):</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">output_list, target_list=[], []</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line"><span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">model.to(<span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">output \( = \) model (data).detach().cpu().numpy()</span><br><span class="line">output_list.extend(output)</span><br><span class="line">target_list.extend(target.cpu().numpy())</span><br><span class="line">p=pd.DataFrame(output_list, columns=[<span class="string">&#x27;predict&#x27;</span>])</span><br><span class="line">p[<span class="string">&#x27;real&#x27;</span>]=target_list</span><br><span class="line"><span class="built_in">print</span>(p.head())</span><br><span class="line"><span class="keyword">return</span> \(p\)</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">p=read(testloader)</span><br><span class="line">error1 = mean_squared_error(p.iloc[:,<span class="number">1</span>], p.iloc[:,<span class="number">0</span>]).<span class="built_in">round</span>(<span class="number">5</span>) \<span class="comment"># 平方差 score1 = r2_score(p.iloc[:,1],p.iloc[:,0]).round(5) \# 相关系数 plt.rcParams[&#x27;font.family&#x27;] = &quot;sans-serif&quot; plt.rcParams [&#x27;font.sans-serif&#x27;] = &quot;SimHei&quot; plt.rcParams [&#x27;axes.unicode_minus&#x27;] = False fig1 = plt.figure(figsize=(20, 10))</span></span><br><span class="line">plt.plot (<span class="built_in">range</span> (p. shape[<span class="number">0</span>]),p. iloc[:,<span class="number">1</span>], color=<span class="string">&#x27;red&#x27;</span>, linewidth=<span class="number">1</span>, linestyle=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">plt.plot (<span class="built_in">range</span> (p. shape[<span class="number">0</span>]), p. iloc[:,<span class="number">0</span>], color=<span class="string">&#x27;blue&#x27;</span>, linewidth=<span class="number">1</span>,</span><br><span class="line">linestyle=<span class="string">&#x27;dashdot&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;真实值&#x27;</span>, <span class="string">&#x27;预测值&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;神经网络预测值与准确率对比图&#x27;</span>)</span><br><span class="line">error1 = <span class="string">&quot;标准差d=&quot;</span> + <span class="built_in">str</span>(error1)+<span class="string">&quot;\\n&quot;</span>+<span class="string">&quot;相关指数R^2=&quot;</span>+<span class="built_in">str</span>(score1) plt.xlabel(error1, size=<span class="number">18</span>, color=<span class="string">&quot;green&quot;</span>) plt.grid() plt.show()</span><br></pre></td></tr></table></figure><h2 id="3-3-线性模型"><a href="#3-3-线性模型" class="headerlink" title="3.3 线性模型"></a>3.3 线性模型</h2><p>这里使用了传统的方法线性模型与神经网络的模型进行对比, 从而反映出效果, 这里的线性模型直接 sklearn 中的库函数来实现, 预测出房价后同样与实际进行对比, 并比较结果, 其代码实现较为简单, 代码如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">1f = LinearRegression()</span><br><span class="line">If.fit(X_train, y_train) \<span class="comment"># 训练数据, 学习模型参数</span></span><br><span class="line">y_predict = 1f.predict(X_test)</span><br><span class="line">error \(<span class="number">2</span> = \) mean_squared_error (y_test.numpy(),y_predict).<span class="built_in">round</span>(<span class="number">5</span>) \<span class="comment">#平方差</span></span><br><span class="line">score \(<span class="number">2</span> = r2\) _score(y_test,y_predict).<span class="built_in">round</span>(<span class="number">5</span>)</span><br><span class="line">fig2 = plt.figure(figsize=(<span class="number">20</span>,<span class="number">10</span>))</span><br><span class="line">plt.plot (<span class="built_in">range</span>(y_test.shape[<span class="number">0</span>]), y_test, color=<span class="string">&#x27;red&#x27;</span>, linewidth=<span class="number">1</span>,</span><br><span class="line">linestyle=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">plt.plot (<span class="built_in">range</span> (y_test.shape [<span class="number">0</span>]), y_predict, color=<span class="string">&#x27;blue&#x27;</span>, linewidth=<span class="number">1</span>,</span><br><span class="line">linestyle=<span class="string">&#x27;dashdot&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;真实值&#x27;</span>, <span class="string">&#x27;预测值&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;线性模型预测值与准确率对比图&#x27;</span>)</span><br><span class="line">error \(<span class="number">2</span> = \) <span class="string">&quot;标准差d=&quot;</span> + <span class="built_in">str</span>(error2)+<span class="string">&quot;\\n&quot;</span>+<span class="string">&quot;相关指数R^2=&quot;</span>+<span class="built_in">str</span>(score2)</span><br><span class="line">plt.xlabel(error2, size=<span class="number">18</span>, color=<span class="string">&quot;green&quot;</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="4-试验结果"><a href="#4-试验结果" class="headerlink" title="4 试验结果"></a>4 试验结果</h2><h2 id="4-1-实验分析"><a href="#4-1-实验分析" class="headerlink" title="4.1 实验分析"></a>4.1 实验分析</h2><p>实验过程中首先得到的直方图以及箱图, 以及相关系数矩阵的热力图如下图所示: 由不同特征与房价的直方图可以大致观察到不同特征的基本影响。<br>由盒图可以看到不同特征下, 数据的分布情况基本较好, 几乎没有异常值和离群点的<br>存在。<br>由热力图可以大致看出, 第四列和第四行, 即 CHAS 的颜色较深, 这说明其与其他特征的相关性较低, 这里将此特征作为重点排查对象, 此时并不能完全判断该特征是否合适,<br><img src="https://cdn.noedgeai.com/373f4192-7bc0-4d1c-9d14-e9c31dcc7467_9.jpg?x=192&y=76&w=457&h=320 "/></p><p>图 1: 特征直方图</p><img src="https://cdn.noedgeai.com/373f4192-7bc0-4d1c-9d14-e9c31dcc7467_9.jpg?x=187&y=467&w=466&h=238 "/><p>图 2: 盒图</p><img src="https://cdn.noedgeai.com/373f4192-7bc0-4d1c-9d14-e9c31dcc7467_9.jpg?x=188&y=768&w=465&h=253 "/><p>图 3: 特征相关性热力图<br>还有看后续的信息。随后为了准确了解每个特征的信息, 这里分布对每个特征与房价的关系进行了可视化, 结果如下:<br>犯罪率: 高房价的房屋大都集中在低犯罪率地区, 有对预测结果有一定的参考价值</p><img src="https://cdn.noedgeai.com/373f4192-7bc0-4d1c-9d14-e9c31dcc7467_10.jpg?x=188&y=142&w=461&h=332 "/><p>图 4: 犯罪率相关图</p><p>住宅用地比例: 与房价无明显的线性关系, 有一定相关性, 可以保留。</p><img src="https://cdn.noedgeai.com/373f4192-7bc0-4d1c-9d14-e9c31dcc7467_10.jpg?x=187&y=566&w=462&h=333 "/><p>图 5: 住宅用地比例图</p><p>城镇中非商业用地的所占比例: 与房价无明显的线性关系, 只能说在某一区间内房价<br>呈现一定特征, 保留。<br>是否处于查尔斯河边 (1 表示在河边, 0 表示不在河边): 是否在查尔斯河边影响房价也<br>不明显, 因此考虑把此特征去除, 防止无关特征影响效果。<br>一氧化氮浓度: 一氧化氮浓度与房价的关系呈现极其微弱的线性关系, 一氧化氮低于<br><img src="https://cdn.noedgeai.com/373f4192-7bc0-4d1c-9d14-e9c31dcc7467_11.jpg?x=186&y=126&w=464&h=333 "/></p><p>图 6: 城镇非商业用地比例图</p><img src="https://cdn.noedgeai.com/373f4192-7bc0-4d1c-9d14-e9c31dcc7467_11.jpg?x=186&y=635&w=464&h=334 "/><p>图 7: 是否处于查尔斯河边图<br>0.5 的情况下, 房价绝大部分高于 15 。</p><img src="https://cdn.noedgeai.com/373f4192-7bc0-4d1c-9d14-e9c31dcc7467_12.jpg?x=187&y=95&w=462&h=332 "/><p>图 8: 一氧化氮浓度相关图</p><p>每栋住宅的房间数: 与房价之间具有较强的线性关系, 保留。</p><img src="https://cdn.noedgeai.com/373f4192-7bc0-4d1c-9d14-e9c31dcc7467_12.jpg?x=186&y=522&w=462&h=331 "/><p>图 9: 每栋住宅房间数图</p><p>1940 年以前建成的业主自住单位的占比: 对房价的影响较小, 但也可保留。<br>距离 5 个波士顿就业中心的平均距离: 平均距离较小的情况下, 房价对应也较低。距离高速公路的便利指数: 房价高于 30 的房产, 近乎都集中在距离高速公路的便利指<br>数低的地区, 有一定的相关性, 可以保留。<br>每一万美元的不动产税率: 与房价的线性相关度较小, 也可保留。城镇中学生教师比例: 对房价的影响较小, 呈微弱的线性关系。<br>黑人比例: 黑人比例对波士顿房价的影响尤其是往后的影响越趋于更小, 对结果预测<br><img src="https://cdn.noedgeai.com/373f4192-7bc0-4d1c-9d14-e9c31dcc7467_13.jpg?x=186&y=126&w=464&h=334 "/></p><p>图 10: 1940 年前建成业主自住比例图</p><img src="https://cdn.noedgeai.com/373f4192-7bc0-4d1c-9d14-e9c31dcc7467_13.jpg?x=186&y=635&w=463&h=333 "/><p>图 11: 距离 5 个波士顿就业中心的距离图<br><img src="https://cdn.noedgeai.com/373f4192-7bc0-4d1c-9d14-e9c31dcc7467_14.jpg?x=186&y=126&w=463&h=333 "/></p><p>图 12: 距离高速公路的便利指数图</p><img src="https://cdn.noedgeai.com/373f4192-7bc0-4d1c-9d14-e9c31dcc7467_14.jpg?x=187&y=635&w=463&h=332 "/><p>图 13: 每一万美元的不动产税率图<br><img src="https://cdn.noedgeai.com/373f4192-7bc0-4d1c-9d14-e9c31dcc7467_15.jpg?x=185&y=63&w=466&h=333 "/></p><p>图 14: 城镇中学教师比例图</p><p>有一定的影响。</p><img src="https://cdn.noedgeai.com/373f4192-7bc0-4d1c-9d14-e9c31dcc7467_15.jpg?x=187&y=493&w=463&h=333 "/><p>图 15: 黑人比例图</p><p>低收入阶层占比: 与房价具有较强的线性关系, 是影响房价的重要因素。<br>从以上对每个特征的分析, 我们可以得出, CHAS 特征与房价的关系非常小, 可以忽<br>略掉, 因此这里的特征仅去掉这一项。</p><h2 id="4-2-对比"><a href="#4-2-对比" class="headerlink" title="4.2 对比"></a>4.2 对比</h2><p>在数据处理完成后, 就是两个模型对于结果的预测。对于神经网络的模型, 其迭代过<br>程的损失变化如下图所示<br><img src="https://cdn.noedgeai.com/373f4192-7bc0-4d1c-9d14-e9c31dcc7467_16.jpg?x=186&y=126&w=464&h=334 "/></p><p>图 16: 低收入阶层占比图</p><img src="https://cdn.noedgeai.com/373f4192-7bc0-4d1c-9d14-e9c31dcc7467_16.jpg?x=189&y=640&w=459&h=324 "/><p>图 17: 迭代过程损失变化图<br>由图中可以看出, 损失在初期迅速下降, 随后缓慢下降, 最后达到了一个很低的水平,<br>说明模型在训练过程中性能越来越好。<br>随后是神经网络模型的预测值与实际值进行的对比图:</p><img src="https://cdn.noedgeai.com/373f4192-7bc0-4d1c-9d14-e9c31dcc7467_17.jpg?x=187&y=165&w=469&h=258 "/><p>图 18: 神经网络预测值与准确率对比图</p><p>由图中可以看出, 绝大部分情况预测的准确度还是很高的, 在房价的峰值与谷值这里<br>出现了一定的误差。<br>线性模型的预测值和实际值对比图如下:</p><img src="https://cdn.noedgeai.com/373f4192-7bc0-4d1c-9d14-e9c31dcc7467_17.jpg?x=187&y=591&w=468&h=258 "/><p>图 19: 线性模型预测值与准确率对比图</p><p>由图中可以看出, 预测效果也还不错, 但是预测的误差相对于神经网络还是高一些, 数据也反映出了这一点, 神经网络的标准差是 19.86254, 线性模型的标准差是 28.35625, 这说明了神经网络预测的的误差小,也更加稳定: 神经网络的相关系数 (R^{2}) 为 0.80978,线性模型的相关系数数 (R^{2}) 为 0.72844,神经网络的相关性要比线性模型的更好,与实际更加符合。</p><h2 id="5-结论"><a href="#5-结论" class="headerlink" title="5 结论"></a>5 结论</h2><p>线性模型和神经网络模型都能够较好的对房价进行预测, 神经网络预测的准确性相对<br>较好。</p><h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6 总结"></a>6 总结</h2><p>由于期末时间问题, 课程复习相对较紧张, 而且还有很多事, 机器学习的大作业这里选取的是经典的题目来做, 并未进行创新性质的探索。但是在这次大作业中我也有很多收获, 代码能力得到了提升, 熟练度增加, 也提升了自己的综合能力。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] 欧阳光. 正交回归最小二乘估计 [J]. 湘南学院学报,2021,42(2):1-5. DOI:10.3969&#x2F;j.issn.1672-8173.2021.02.001.</p><h2 id="A-程序代码"><a href="#A-程序代码" class="headerlink" title="A 程序代码"></a>A 程序代码</h2><p>房价预测模型 - price_predict.py </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> TensorDataset</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> skimage.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">column_names = [<span class="string">&#x27;CRIM&#x27;</span>, <span class="string">&#x27;ZN&#x27;</span>, <span class="string">&#x27;INDUS&#x27;</span>, <span class="string">&#x27;CHAS&#x27;</span>, <span class="string">&#x27;NOX&#x27;</span>, <span class="string">&#x27;RM&#x27;</span>, <span class="string">&#x27;AGE&#x27;</span>, <span class="string">&#x27;DIS&#x27;</span>, <span class="string">&#x27;RAD&#x27;</span>, <span class="string">&#x27;TAX&#x27;</span>, <span class="string">&#x27;PTRATIO&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;LSTAT&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;PRICE&#x27;</span>]</span><br><span class="line">all_data = pd.read_csv(<span class="string">&#x27;./housing.csv&#x27;</span>, header=<span class="literal">None</span>, delimiter=<span class="string">r&quot;\s+&quot;</span>, names=column_names)</span><br><span class="line"></span><br><span class="line">all_data.hist()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">all_data.describe()</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">plt.boxplot(all_data)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">corr = all_data.corr()</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">sns.heatmap(corr, annot=<span class="literal">True</span>, cmap=<span class="string">&#x27;twilight_r&#x27;</span>)</span><br><span class="line"></span><br><span class="line">data = all_data.iloc[:, :-<span class="number">1</span>]</span><br><span class="line">label = all_data.iloc[:, -<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">data = np.array(data, dtype=<span class="built_in">float</span>)</span><br><span class="line">label = np.array(label, dtype=<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">13</span>):</span><br><span class="line">    plt.figure(figsize=(<span class="number">10</span>, <span class="number">7</span>))</span><br><span class="line">    plt.grid()</span><br><span class="line">    plt.scatter(data[:, i], label, s=<span class="number">5</span>)  <span class="comment"># 横纵坐标和点的大小</span></span><br><span class="line">    plt.title(column_names[i])</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">unsF = []  <span class="comment"># 次要特征下标</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(data.shape[<span class="number">1</span>]):</span><br><span class="line">    <span class="keyword">if</span> column_names[i] == <span class="string">&#x27;CHAS&#x27;</span>:</span><br><span class="line">        unsF.append(i)</span><br><span class="line">data = np.delete(data, unsF, axis=<span class="number">1</span>)  <span class="comment"># 删除次要特征</span></span><br><span class="line"></span><br><span class="line">unsT = []  <span class="comment"># 房价异常值下标</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(data.shape[<span class="number">1</span>]):</span><br><span class="line">    <span class="keyword">if</span> label[i] &gt; <span class="number">46</span>:</span><br><span class="line">        unsT.append(i)</span><br><span class="line">data = np.delete(data, unsT, axis=<span class="number">0</span>)  <span class="comment"># 删除样本异常值数据</span></span><br><span class="line">label = np.delete(label, unsT, axis=<span class="number">0</span>)  <span class="comment"># 删除异常房价</span></span><br><span class="line"></span><br><span class="line">data = torch.tensor(data, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">label = torch.tensor(label, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=<span class="number">0.3</span>, random_state=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model, device, train_loader, optimizer, epoch, criterion</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        data, target = data.to(device), target.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(data)</span><br><span class="line">        loss = criterion(output, target.view_as(output))</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Train Epoch: &#123;&#125; Loss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                epoch, loss.item() / <span class="built_in">len</span>(train_loader)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">model, device, test_loader, criterion</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">            data, target = data.to(device), target.to(device)</span><br><span class="line">            output = model(data)</span><br><span class="line"></span><br><span class="line">            test_loss += criterion(output, target.view_as(output)).item()  <span class="comment"># sum up batch loss</span></span><br><span class="line"></span><br><span class="line">    test_loss /= <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Test set: Average loss: &#123;:.4f&#125;\n&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        test_loss))</span><br><span class="line">    <span class="keyword">return</span> test_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">12</span>, <span class="number">128</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">128</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">model = Net().to(device)</span><br><span class="line">optimizer = torch.optim.Adam(params=model.parameters())</span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line"></span><br><span class="line">trainset = TensorDataset(X_train, y_train)</span><br><span class="line">trainloader = DataLoader(trainset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line">testset = TensorDataset(X_test, y_test)</span><br><span class="line">testloader = DataLoader(testset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">epoch_list, loss_list = [], []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">1000</span>):</span><br><span class="line">    train(model, device, trainloader, optimizer, epoch, criterion)</span><br><span class="line">    test_loss = test(model, device, testloader, criterion)</span><br><span class="line">    epoch_list.append(epoch)</span><br><span class="line">    loss_list.append(test_loss)</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">plt.plot(epoch_list, loss_list)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;error&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read</span>(<span class="params">test_loader</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    output_list, target_list = [], []</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">            model.to(<span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">            output = model(data).detach().cpu().numpy()</span><br><span class="line">            output_list.extend(output)</span><br><span class="line">            target_list.extend(target.cpu().numpy())</span><br><span class="line">    p = pd.DataFrame(output_list, columns=[<span class="string">&#x27;predict&#x27;</span>])</span><br><span class="line">    p[<span class="string">&#x27;real&#x27;</span>] = target_list</span><br><span class="line">    <span class="built_in">print</span>(p.head())</span><br><span class="line">    <span class="keyword">return</span> p</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">p = read(testloader)</span><br><span class="line"></span><br><span class="line">error1 = mean_squared_error(p.iloc[:, <span class="number">1</span>], p.iloc[:, <span class="number">0</span>]).<span class="built_in">round</span>(<span class="number">5</span>)  <span class="comment"># 平方差</span></span><br><span class="line">score1 = r2_score(p.iloc[:, <span class="number">1</span>], p.iloc[:, <span class="number">0</span>]).<span class="built_in">round</span>(<span class="number">5</span>)  <span class="comment"># 相关系数</span></span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = <span class="string">&quot;sans-serif&quot;</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = <span class="string">&quot;SimHei&quot;</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">fig1 = plt.figure(figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">plt.plot(<span class="built_in">range</span>(p.shape[<span class="number">0</span>]), p.iloc[:, <span class="number">1</span>], color=<span class="string">&#x27;red&#x27;</span>, linewidth=<span class="number">1</span>, linestyle=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(p.shape[<span class="number">0</span>]), p.iloc[:, <span class="number">0</span>], color=<span class="string">&#x27;blue&#x27;</span>, linewidth=<span class="number">1</span>, linestyle=<span class="string">&#x27;dashdot&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;真实值&#x27;</span>, <span class="string">&#x27;预测值&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;神经网络预测值与准确率对比图&#x27;</span>)</span><br><span class="line">error1 = <span class="string">&quot;标准差d=&quot;</span> + <span class="built_in">str</span>(error1) + <span class="string">&quot;\n&quot;</span> + <span class="string">&quot;相关指数R^2=&quot;</span> + <span class="built_in">str</span>(score1)</span><br><span class="line">plt.xlabel(error1, size=<span class="number">18</span>, color=<span class="string">&quot;green&quot;</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">lf = LinearRegression()</span><br><span class="line">lf.fit(X_train, y_train)  <span class="comment"># 训练数据,学习模型参数</span></span><br><span class="line">y_predict = lf.predict(X_test)</span><br><span class="line"></span><br><span class="line">error2 = mean_squared_error(y_test.numpy(), y_predict).<span class="built_in">round</span>(<span class="number">5</span>)  <span class="comment"># 平方差</span></span><br><span class="line">score2 = r2_score(y_test, y_predict).<span class="built_in">round</span>(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">fig2 = plt.figure(figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">plt.plot(<span class="built_in">range</span>(y_test.shape[<span class="number">0</span>]), y_test, color=<span class="string">&#x27;red&#x27;</span>, linewidth=<span class="number">1</span>, linestyle=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(y_test.shape[<span class="number">0</span>]), y_predict, color=<span class="string">&#x27;blue&#x27;</span>, linewidth=<span class="number">1</span>, linestyle=<span class="string">&#x27;dashdot&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;真实值&#x27;</span>, <span class="string">&#x27;预测值&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;线性模型预测值与准确率对比图&#x27;</span>)</span><br><span class="line">error2 = <span class="string">&quot;标准差d=&quot;</span> + <span class="built_in">str</span>(error2) + <span class="string">&quot;\n&quot;</span> + <span class="string">&quot;相关指数R^2=&quot;</span> + <span class="built_in">str</span>(score2)</span><br><span class="line">plt.xlabel(error2, size=<span class="number">18</span>, color=<span class="string">&quot;green&quot;</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;摘-要&quot;&gt;&lt;a href=&quot;#摘-要&quot; class=&quot;headerlink&quot; title=&quot;摘 要&quot;&gt;&lt;/a&gt;摘 要&lt;/h2&gt;&lt;p&gt;在这次大作业中我完成了波士顿房价预测模型的实现, 波士顿房价预测是一个经典的回归模型。&lt;br&gt;在本次实验中, 首先对数据的分布情况以</summary>
      
    
    
    
    <category term="机器学习" scheme="http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>计算智能导论作业——感知器实现二分类</title>
    <link href="http://example.com/2021/05/30/%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA%E4%BD%9C%E4%B8%9A%E2%80%94%E2%80%94%E6%84%9F%E7%9F%A5%E5%99%A8%E5%AE%9E%E7%8E%B0%E4%BA%8C%E5%88%86%E7%B1%BB/"/>
    <id>http://example.com/2021/05/30/%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA%E4%BD%9C%E4%B8%9A%E2%80%94%E2%80%94%E6%84%9F%E7%9F%A5%E5%99%A8%E5%AE%9E%E7%8E%B0%E4%BA%8C%E5%88%86%E7%B1%BB/</id>
    <published>2021-05-30T11:29:37.000Z</published>
    <updated>2024-04-09T15:27:47.760Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目-录"><a href="#目-录" class="headerlink" title="目 录"></a>目 录</h2><p>1 背景知识 1<br>1.1 基本定义 1<br>1.2 感知器的损失函数 1<br>1.3 感知器的训练 1<br>2 数据集 2<br>3 代码实现 2<br>4 结果展示与分析 4<br>4.1 数据集一 4<br>4.2 数据集二 5<br>4.3 数据集三 5<br>5 探究 6<br>6 总结 7<br>A 程序代码 8</p><h2 id="1-背景知识"><a href="#1-背景知识" class="headerlink" title="1 背景知识"></a>1 背景知识</h2><h2 id="1-1-基本定义"><a href="#1-1-基本定义" class="headerlink" title="1.1 基本定义"></a>1.1 基本定义</h2><p>感知器可以实现简单的布尔运算, 可以拟合任何的线性函数, 任何线性分类或线性问题都可以用感知器来解决, 布尔运算就可以看作是一个二分类问题, 用一条直线将两类分开。感知器无法实现异或运算, 因为异或运算不是线性的, 无法用一条直线将两类分开。<br>与逻辑斯蒂回归从概率的角度判别不同, 感知机可以理解为从几何的角度上做判断, 即<br>求得一个分离超平面, 可以将对应输入空间中的实例划分为正负两类。<br>一个感知器有如下组成部分:</p><ul><li><p>输入权值: 一个感知器可以接收多个输入 $(x_{1},x_{2},\ldots,x_{n} | x_{i} \in \mathbb{R})$, 每个输入上有一个权值 $\omega_{i} \in \mathbb{R}$, 此外还有一个偏置项 $b \in \mathbb{R}$, 就是上图中的 $\omega_{0}$。</p></li><li><p>激活函数: 感知器的激活函数可以有很多选择, 比如我们可以选择下面这个阶跃函数 $f$ 来作为激活函数:<br>$$<br>f(z) &#x3D; \begin{cases}<br>1 &amp; \text{if } z &gt; 0 \<br>0 &amp; \text{otherwise}<br>\end{cases}<br>$$</p></li><li><p>输出: 感知器的输出由下面这个公式来计算<br>$$<br>y &#x3D; f(\mathbf{w} \cdot \mathbf{x} + b)<br>$$</p></li></ul><h2 id="1-2-感知器的损失函数"><a href="#1-2-感知器的损失函数" class="headerlink" title="1.2 感知器的损失函数"></a>1.2 感知器的损失函数</h2><p>为了求得感知器的权重参数, 需要确定一个学习策略, 即定义损失函数并将损失函数<br>极小化。有这样几种选择:</p><ol><li><p>误分类点的总数: 损失函数不是 $w,b$ 的连续可导函数, 不易优化。</p></li><li><p>误分类点到超平面的总距离: 感知器所采用的损失函数。感知器的损失函数是:</p></li></ol>$${-} \frac{1}{{\| w \|}} \sum_{x_{i} \in M} y_{i}(w x_{i} + b)$$<p>感知器学习问题转化为上式损失函数的最优化问题, 最优化的方法是随机梯度下降法。<br>当训练数据集线性可分时, 感知器学习算法原始形式是收玫的。</p><h2 id="1-3-感知器的训练"><a href="#1-3-感知器的训练" class="headerlink" title="1.3 感知器的训练"></a>1.3 感知器的训练</h2><p>感知器的权值和偏置项是利用感知器训练算法得出的, 首先将权重项和偏置项初始化为 0, 然后, 利用下面的感知器规则迭代地修改 $w_{i}$ 和 $b$, 直到训练完成。</p><p>$$<br>w_{i} \leftarrow w_{i} + \Delta w_{i}<br>$$</p><p>$$<br>b \leftarrow b + \Delta b<br>$$</p><p>其中:</p><p>$$<br>\Delta w_{i} &#x3D; \eta(t - y)x_{i}<br>$$</p><p>$$<br>\Delta b &#x3D; \eta(t - y)<br>$$</p><p>$w_{i}$ 是与输入对应的权重项, $b$ 是偏置项。事实上, 可以把 $b$ 看作是值永远为 1 的输入所对应的权重。$t$ 是训练样本的实际值，一般称之为 label。而 $y$ 是感知器的输出值, 它是根据上面的公式计算得出的。$\eta$ 是一个称为学习速率的常数, 其作用是控制每一步调整权的幅度。</p><p>每次从训练数据中取出一个样本的输入向量 $x$, 使用感知器计算其输出 $y$, 再根据上面的规则来调整权重。每处理一个样本就调整一次权重。经过多轮迭代后（即全部的训练数据被反复处理多轮），就可以训练出感知器的权重，使之实现目标函数。</p><h2 id="2-数据集"><a href="#2-数据集" class="headerlink" title="2 数据集"></a>2 数据集</h2><p>在本次实验中, 选择了三组数据, 第一组是自己生成的 200 个二维的数据, 一共两组, 每组 100 个数据,一组是以 (({-}2, {-} 2)) 为均值,标准差为 1.5 的数据,另一组是以 ((2,2)) 为均值, 标准差为 1.5 的数据, 这两类数据中有一点交叉, 使得数据不能完全线性可分。<br>第二组数据是读取的自定义的数据, 一共两类, 这两类数据之间有一定的间隔, 是完全<br>线性可分的。<br>第三组数据是著名的数据集 Sonar, Sonar 数据集是一个声纳信号分类数据集, 声纳信号从一个金属圆柱体上反弹, 或者从一个大致呈圆柱形的岩石上反弹。每个样本是一个 60 维向量。每个数字表示特定频带内的能量, 范围从 0 到 1 。如果是从一块岩石上反弹, 则样本标签为 “R”, 如果是从一个金属圆柱体上反弹则为 “M”。</p><h2 id="3-代码实现"><a href="#3-代码实现" class="headerlink" title="3 代码实现"></a>3 代码实现</h2><p>在代码实现中, 这里首先创建了一个感知器类, 首先根据输入数据的维度初始化权重向量以及偏置的值。然后定义类的内置函数, 包括计算以及权值更新函数, 利用权值以及偏置的更新公式进行更新。随后这里定义了一个作图函数, 将数据展示出, 并画出分界面。随后是分别对三个数据集进行读取, 然后定义激活函数为阶跃函数。最后是主函数, 完成感知器的全过程, 并计算出分类后的准确率。具体代码如下:<br>感知器类的定义函数:</p><hr><p>class Perceptron():<br>def init__(self,input_num,f):<br>self.input_num&#x3D;input_num<br>self.weights&#x3D;np.ones(input_num)<br>self.bias&#x3D;2.0<br>self.activation&#x3D;f<br>def_str__(self):<br>return f’weight&#x3D;{self.weights},bias&#x3D;{self.bias}’<br>def predict(self,inputs):<br>return self.activation(np.dot(inputs, self.weights)+self.bias)<br>def train(self,inputs,labels,rate&#x3D;0.1):<br>for (j) in range (inputs. shape [0]):<br>output&#x3D;self.predict(inputs[j])<br>self.weights&#x3D;self.weights+rate*(labels[j]-output)<em>inputs[j]<br>self.bias&#x3D;self.bias+rate</em>(labels[j]-output)</p><hr><p>前两个数据集的作图函数:<br>def plot_result(perceptron, result):<br>knew ( &#x3D; ) -perceptron.weights (\lbrack 0\rbrack&#x2F;) perceptron.weights [1] bnew ( &#x3D; ) -perceptron.bias &#x2F; perceptron.weights [1] (\mathrm{x} &#x3D; \mathrm{np}) . linspace (({-}5,5))<br>(y &#x3D; 1) ambda (x : knew * x + bnew) plt.xlim(-8,8) plt.ylim(-8,8)<br>plt.plot(x, y(x), ‘b–’)<br>plt.scatter(data[:, 0], data[:, 1], c&#x3D;result) plt.title(‘Binary Classification’) plt.show()<br>对高维度数据集的作图函数:</p><hr><p>def imshow(data,result):<br>tsne ( &#x3D; ) TSNE(n_components ( &#x3D; 2) ,learning_rate ( &#x3D; 100) ). fit_transform(data)<br>pca ( &#x3D; PCA()) . fit_transform(data)<br>plt.figure(figsize&#x3D;(12, 6))<br>plt.subplot(121)<br>plt.scatter(tsne[:, 0], tsne[:, 1], c&#x3D;result)<br>plt.title(‘t-SNE’)<br>plt.subplot(122)<br>plt.scatter(pca[:, 0], pca[:, 1], c&#x3D;result)<br>plt.title(‘PCA’)<br>plt.colorbar()<br>plt.show()</p><hr><p>对于高维度数据, 主函数中代码适当进行了改动, 只显示了最终的结果图。主函数部分代码如下:</p><hr><p>if _<em>name</em>&#x3D;&#x3D;’<strong>main</strong>‘:<br>epochs ( &#x3D; 1000)<br>data,target&#x3D;get_data()<br>perceptron&#x3D;Perceptron(data.shape[1],f)<br>print(perceptron)<br>plot_result(perceptron,target)<br>for i in range(epochs):<br>perceptron.train(data, target)<br>if (i%400 &#x3D; &#x3D; 0) :<br>plot_result(perceptron, target)<br>print(perceptron)<br>acc ( &#x3D; 0)</p><hr><p>result&#x3D;np.zeros_like(target) for i in range(data.shape[0]):<br>result[i]&#x3D;perceptron.predict(data[i]) acc+&#x3D;(result[i]&#x3D;&#x3D;target[i]) plot_result(perceptron,target)<br>print(’acc&#x3D;{}’.format(acc &#x2F; len(target)))</p><h2 id="4-结果展示与分析"><a href="#4-结果展示与分析" class="headerlink" title="4 结果展示与分析"></a>4 结果展示与分析</h2><h2 id="4-1-数据集一"><a href="#4-1-数据集一" class="headerlink" title="4.1 数据集一"></a>4.1 数据集一</h2><p>首先使用第一个数据集进行展示, 在展示中, 为了更好的体现迭代过程中线性分界面的变化, 这里每隔 400 次展示一次结果, 效果如下图所示, 第一张为初始图, 分解面为初始化的值。</p><img src="https://cdn.noedgeai.com/e61111d4-9579-4d1a-b6be-0d3a5e039cb8_5.jpg?x=152&y=415&w=246&h=196 "/><p>图 1: 初始</p><img src="https://cdn.noedgeai.com/e61111d4-9579-4d1a-b6be-0d3a5e039cb8_5.jpg?x=437&y=414&w=248&h=196 "/><p>图 2: 迭代 400 次</p><p>可以看到迭代中分界面一直在进行变化来使得全部样本被正确划分, 但本数据集是线<br>性不可分的, 无法找到一条直线可以将所有样本都能正确被划分。</p><img src="https://cdn.noedgeai.com/e61111d4-9579-4d1a-b6be-0d3a5e039cb8_5.jpg?x=438&y=744&w=247&h=195 "/><p>图 4: 最终结果</p><img src="https://cdn.noedgeai.com/e61111d4-9579-4d1a-b6be-0d3a5e039cb8_5.jpg?x=153&y=744&w=243&h=196 "/><p>图 3: 迭代 800 次</p><p>经过了 1000 次的迭代后, 可以看到分界面几乎可以将绝大部分样本正确划分, 说明感知器模型较好的完成了线性分类的任务, 计算得到分类准确率为 0.965 , 印证了从图像中得到的结果。<br>在迭代的过程中,初始权值为 (\lbrack 1,1\rbrack) ,偏置为 2,经过 1000 次迭代后,weight ( &#x3D; \lbrack {-} 0.10703409 {-} )<br>(0.05266879\rbrack,bias &#x3D; 0.09999999999999931) 。</p><h2 id="4-2-数据集二"><a href="#4-2-数据集二" class="headerlink" title="4.2 数据集二"></a>4.2 数据集二</h2><p>与数据集一不同, 该数据集是线性可分的, 其他初始化参数部分基本与数据集一设置<br>相同。</p><img src="https://cdn.noedgeai.com/e61111d4-9579-4d1a-b6be-0d3a5e039cb8_6.jpg?x=430&y=227&w=256&h=197 "/><p>图 6: 迭代 400 次</p><img src="https://cdn.noedgeai.com/e61111d4-9579-4d1a-b6be-0d3a5e039cb8_6.jpg?x=142&y=228&w=257&h=194 "/><p>图 5: 初始</p><p>可以看到, 经过 400 次迭代后, 数据集已经可以完全正确的划分。</p><img src="https://cdn.noedgeai.com/e61111d4-9579-4d1a-b6be-0d3a5e039cb8_6.jpg?x=142&y=531&w=256&h=197 "/><p>图 7: 迭代 800 次</p><img src="https://cdn.noedgeai.com/e61111d4-9579-4d1a-b6be-0d3a5e039cb8_6.jpg?x=430&y=531&w=254&h=196 "/><p>图 8: 最终结果</p><p>在迭代 400 次时, 就已经实现了正确的分类, 因此可以看到后来的迭代中, 线性分界<br>面并未发生改变, 因为在参数更新中, 无错误分类的样本, 因此权重并未被更新。<br>最后可以得到分类的准确率为 1.0, 效果很好, 初始化时, 参数为 weight ( &#x3D; \left\lbrack 1.1\text{.} \right\rbrack,bias &#x3D; )<br>2.0, 经过迭代后, weight ( &#x3D; \lbrack{-}0.095474010.96129867\rbrack) ,bias ( &#x3D; {-} 0.500000000000000000) 。<br>在这里, 我们可以发现一个现象, 线性分界面在完全将数据划分开后就不再改变, 因此分界面相对来说是有些 “偏” 的, 而不是像支持向量机那样, 达到距离最小化的效果, 这也反映了感知器的缺陷, 只是完成简单的分类, 并未考虑到样本整体的情况, 这样对于未知样本, 效果就会相对差一些。</p><h2 id="4-3-数据集三"><a href="#4-3-数据集三" class="headerlink" title="4.3 数据集三"></a>4.3 数据集三</h2><p>为了更好的展示迭代过程中准确率以及损失的变化, 确定足够迭代次数得到较好的结<br>果, 这里对这两项指标进行了记录, 结果如下图所示:<br><img src="https://cdn.noedgeai.com/e61111d4-9579-4d1a-b6be-0d3a5e039cb8_7.jpg?x=183&y=79&w=473&h=203 "/></p><p>图 9: 损失准确率结果图</p><p>从上图可以看出, 随着迭代次数的增加, 损失不断减小, 因为是负数, 所以图中是不断<br>上升,一定次数后达到稳定,准确率不断上升,并达到约 (80%) 。<br>与前两个数据集不同, 第三个数据集维度较高, 无法用之前的方法进行可视化, 因此这里使用了两种方法 t-SNE 降维以及 PCA 降维, 从而对结果进行可视化, 结果如下图所示:</p><img src="https://cdn.noedgeai.com/e61111d4-9579-4d1a-b6be-0d3a5e039cb8_7.jpg?x=178&y=475&w=474&h=254 "/><p>图 10: 降维结果图</p><p>降维效果不理想, 因此下文对其进行了探究。<br>在实验中发现, 由于数据维度过高, 1000 次迭代后, 数据仍未达到稳定的状态, 因此这里设置迭代次数为 50000 次, 由于数据维度过高, 不方便展示, 这里不再进行权重展示, 结果的准确率为 0.7836538461538461 , 也得到了较好的效果。</p><h2 id="5-探究"><a href="#5-探究" class="headerlink" title="5 探究"></a>5 探究</h2><p>降维效果并不理想, 这里存在疑问, 分类准确率较高的情况下, 降维效果不理想, 因此<br>这里又对 Sonar 数据集使用 K-means 聚类后降维展示, 结果如下:<br>从图中可以看出, 降维效果较好, 因此并不是数据集的问题。由于 kmeans 对此高维数据处理后, 降维效果很好, 可以说明并不是因为从维度高降到二维特征减少太多而无法表现良好的效果, 这里推测应该是对于感知器的分类结果并不能很好的降维<br><img src="https://cdn.noedgeai.com/e61111d4-9579-4d1a-b6be-0d3a5e039cb8_8.jpg?x=180&y=83&w=473&h=255 "/></p><p>图 11: Sonar 使用 kmeans 降维结果图</p><h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6 总结"></a>6 总结</h2><p>在本次实验中遇到了一些问题, 在此感谢尚荣华老师以及博士生的指导, 在感知器分<br>类的时候遇到了两个问题。<br>第一,对于数据高维度的 Sonar 数据集,为了可视化效果,这里使用了 (\mathrm{t} {-} \mathrm{SNE}) 以及 PCA 降维可视化, 但分类准确率高的同时, 降维效果并不好, 这里又对 Sonar 数据使用了聚类方法, 随后降维可视化, 其效果较好, 也对问题原因进行了推测。<br>第二, 对于高维数据的损失记录, 开始的记录为损失先迅速降低, 随后慢慢升高, 经过发现后发现记录损失的方式不对, 开始使用了每个样本标签与输出的插值的绝对值作为损失, 并求和, 这样是一中类似于均方误差的计算方式, 在高维超平面移动的过程, 这样的方式计算的并不是实际的损失, 因此查阅资料后使用了正确的损失函数计算, 结果较好。<br>本次实验中对感知器进行了实现, 并利用多种数据集进行展示, 得到了很好的效果, 在这次实验中, 开始在理解题意方面遇到了很多问题, 后来经过多方询问才明白。这次实验中我通过广泛查询资料了解到了相关的知识, 也认真写代码来完成任务, 这份作业的完成确实比较艰巨, 一份顶多份, 但是我还是有很大的收获, 能力也得到了提升。</p><h2 id="A-程序代码"><a href="#A-程序代码" class="headerlink" title="A 程序代码"></a>A 程序代码</h2><p>感知器实现程序 - 感知器.py </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># Author : JackZhu</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Data : 2021/5/20 18:21</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> scio</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Perceptron</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_num,f</span>):</span><br><span class="line">        self.input_num=input_num</span><br><span class="line">        self.weights=np.ones(input_num)</span><br><span class="line">        self.bias=<span class="number">2.0</span></span><br><span class="line">        self.activation=f</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&#x27;weight=<span class="subst">&#123;self.weights&#125;</span>,bias=<span class="subst">&#123;self.bias&#125;</span>&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,inputs</span>):</span><br><span class="line">        <span class="keyword">return</span> self.activation(np.dot(inputs,self.weights)+self.bias)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self,inputs,labels,rate=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(inputs.shape[<span class="number">0</span>]):</span><br><span class="line">            output=self.predict(inputs[j])</span><br><span class="line">            self.weights=self.weights+rate*(labels[j]-output)*inputs[j]</span><br><span class="line">            self.bias=self.bias+rate*(labels[j]-output)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> <span class="keyword">if</span> x&gt;<span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># def get_data():</span></span><br><span class="line"><span class="comment">#     path = &#x27;./sonar.csv&#x27;</span></span><br><span class="line"><span class="comment">#     file = pd.read_csv(path, header=None)</span></span><br><span class="line"><span class="comment">#     data = file.iloc[:, :-1]</span></span><br><span class="line"><span class="comment">#     target = file.iloc[:, -1]</span></span><br><span class="line"><span class="comment">#     target = pd.get_dummies(target).iloc[:, -1]</span></span><br><span class="line"><span class="comment">#     data = np.array(data)</span></span><br><span class="line"><span class="comment">#     target = np.array(target)</span></span><br><span class="line"><span class="comment">#     return data,target</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_data</span>():</span><br><span class="line">    data=torch.ones(<span class="number">100</span>,<span class="number">2</span>)</span><br><span class="line">    x0=torch.normal(<span class="number">2</span>*data,<span class="number">1.5</span>)</span><br><span class="line">    x1=torch.normal(-<span class="number">2</span>*data,<span class="number">1.5</span>)</span><br><span class="line">    x=torch.cat((x0,x1),<span class="number">0</span>)</span><br><span class="line">    y0=torch.zeros(<span class="number">100</span>)</span><br><span class="line">    y1=torch.ones(<span class="number">100</span>)</span><br><span class="line">    y=torch.cat((y0,y1))</span><br><span class="line">    data=np.array(x)</span><br><span class="line">    target=np.array(y)</span><br><span class="line">    <span class="keyword">return</span> data,target</span><br><span class="line"></span><br><span class="line"><span class="comment"># def get_data():</span></span><br><span class="line"><span class="comment">#     path = &#x27;./long.mat&#x27;</span></span><br><span class="line"><span class="comment">#     file = scio.loadmat(path)[&#x27;long1&#x27;]</span></span><br><span class="line"><span class="comment">#     data = file[:, 0:2]</span></span><br><span class="line"><span class="comment">#     target = file[:, 2]</span></span><br><span class="line"><span class="comment">#     return data,target</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_result</span>(<span class="params">perceptron,result</span>):</span><br><span class="line">    knew = -perceptron.weights[<span class="number">0</span>] / perceptron.weights[<span class="number">1</span>]</span><br><span class="line">    bnew = -perceptron.bias / perceptron.weights[<span class="number">1</span>]</span><br><span class="line">    x = np.linspace(-<span class="number">5</span>, <span class="number">5</span>)</span><br><span class="line">    y = <span class="keyword">lambda</span> x: knew * x + bnew</span><br><span class="line">    plt.xlim(-<span class="number">8</span>,<span class="number">8</span>)</span><br><span class="line">    plt.ylim(-<span class="number">8</span>,<span class="number">8</span>)</span><br><span class="line">    plt.plot(x, y(x), <span class="string">&#x27;b--&#x27;</span>)</span><br><span class="line">    plt.scatter(data[:, <span class="number">0</span>], data[:, <span class="number">1</span>], c=result)</span><br><span class="line">    plt.title(<span class="string">&#x27;Binary Classification&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    epochs = <span class="number">1000</span></span><br><span class="line">    data,target=get_data()</span><br><span class="line">    perceptron=Perceptron(data.shape[<span class="number">1</span>],f)</span><br><span class="line">    <span class="built_in">print</span>(perceptron)</span><br><span class="line">    plot_result(perceptron,target)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        perceptron.train(data,target)</span><br><span class="line">        <span class="keyword">if</span> i%<span class="number">400</span>==<span class="number">0</span>:</span><br><span class="line">            plot_result(perceptron,target)</span><br><span class="line">    <span class="built_in">print</span>(perceptron)</span><br><span class="line">    acc=<span class="number">0</span></span><br><span class="line">    result=np.zeros_like(target)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(data.shape[<span class="number">0</span>]):</span><br><span class="line">        result[i]=perceptron.predict(data[i])</span><br><span class="line">        acc+=(result[i]==target[i])</span><br><span class="line">    plot_result(perceptron,target)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;acc=&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(acc / <span class="built_in">len</span>(target)))</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>感知器实现 SONAR. 数据程序 - perceptron2.py </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># Author : JackZhu</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Data : 2021/5/20 18:21</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> scio</span><br><span class="line"><span class="keyword">from</span> sklearn.manifold <span class="keyword">import</span> TSNE</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Perceptron</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_num,f</span>):</span><br><span class="line">        self.input_num=input_num</span><br><span class="line">        self.weights=np.ones(input_num)</span><br><span class="line">        self.bias=<span class="number">2.0</span></span><br><span class="line">        self.activation=f</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&#x27;weight=<span class="subst">&#123;self.weights&#125;</span>,bias=<span class="subst">&#123;self.bias&#125;</span>&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,inputs</span>):</span><br><span class="line">        <span class="keyword">return</span> self.activation(np.dot(inputs,self.weights)+self.bias)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self,inputs,labels,rate=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(inputs.shape[<span class="number">0</span>]):</span><br><span class="line">            output=self.predict(inputs[j])</span><br><span class="line">            self.weights=self.weights+rate*(labels[j]-output)*inputs[j]</span><br><span class="line">            self.bias=self.bias+rate*(labels[j]-output)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> <span class="keyword">if</span> x&gt;<span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_data</span>():</span><br><span class="line">    path = <span class="string">&#x27;./sonar.csv&#x27;</span></span><br><span class="line">    file = pd.read_csv(path, header=<span class="literal">None</span>)</span><br><span class="line">    data = file.iloc[:, :-<span class="number">1</span>]</span><br><span class="line">    target = file.iloc[:, -<span class="number">1</span>]</span><br><span class="line">    target = pd.get_dummies(target).iloc[:, -<span class="number">1</span>]</span><br><span class="line">    data = np.array(data)</span><br><span class="line">    target = np.array(target)</span><br><span class="line">    <span class="keyword">return</span> data,target</span><br><span class="line"></span><br><span class="line"><span class="comment"># def get_data():</span></span><br><span class="line"><span class="comment">#     data=torch.ones(100,2)</span></span><br><span class="line"><span class="comment">#     x0=torch.normal(2*data,1.5)</span></span><br><span class="line"><span class="comment">#     x1=torch.normal(-2*data,1.5)</span></span><br><span class="line"><span class="comment">#     x=torch.cat((x0,x1),0)</span></span><br><span class="line"><span class="comment">#     y0=torch.zeros(100)</span></span><br><span class="line"><span class="comment">#     y1=torch.ones(100)</span></span><br><span class="line"><span class="comment">#     y=torch.cat((y0,y1))</span></span><br><span class="line"><span class="comment">#     data=np.array(x)</span></span><br><span class="line"><span class="comment">#     target=np.array(y)</span></span><br><span class="line"><span class="comment">#     return data,target</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># def get_data():</span></span><br><span class="line"><span class="comment">#     path = &#x27;./long.mat&#x27;</span></span><br><span class="line"><span class="comment">#     file = scio.loadmat(path)[&#x27;long1&#x27;]</span></span><br><span class="line"><span class="comment">#     data = file[:, 0:2]</span></span><br><span class="line"><span class="comment">#     target = file[:, 2]</span></span><br><span class="line"><span class="comment">#     return data,target</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_result</span>(<span class="params">perceptron,result</span>):</span><br><span class="line">    knew = -perceptron.weights[<span class="number">0</span>] / perceptron.weights[<span class="number">1</span>]</span><br><span class="line">    bnew = -perceptron.bias / perceptron.weights[<span class="number">1</span>]</span><br><span class="line">    x = np.linspace(-<span class="number">5</span>, <span class="number">5</span>)</span><br><span class="line">    y = <span class="keyword">lambda</span> x: knew * x + bnew</span><br><span class="line">    plt.xlim(-<span class="number">5</span>,<span class="number">5</span>)</span><br><span class="line">    plt.ylim(-<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">    plt.plot(x, y(x), <span class="string">&#x27;b--&#x27;</span>)</span><br><span class="line">    plt.scatter(data[:, <span class="number">0</span>], data[:, <span class="number">1</span>], c=result)</span><br><span class="line">    plt.title(<span class="string">&#x27;Binary Classification&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">imshow</span>(<span class="params">data,result</span>):</span><br><span class="line">    tsne = TSNE(n_components=<span class="number">2</span>, learning_rate=<span class="number">100</span>).fit_transform(data)</span><br><span class="line">    pca = PCA().fit_transform(data)</span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">    plt.subplot(<span class="number">121</span>)</span><br><span class="line">    plt.scatter(tsne[:, <span class="number">0</span>], tsne[:, <span class="number">1</span>], c=result)</span><br><span class="line">    plt.title(<span class="string">&#x27;t-SNE&#x27;</span>)</span><br><span class="line">    plt.subplot(<span class="number">122</span>)</span><br><span class="line">    plt.scatter(pca[:, <span class="number">0</span>], pca[:, <span class="number">1</span>], c=result)</span><br><span class="line">    plt.title(<span class="string">&#x27;PCA&#x27;</span>)</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    epochs = <span class="number">50000</span></span><br><span class="line">    data,target=get_data()</span><br><span class="line">    perceptron=Perceptron(data.shape[<span class="number">1</span>],f)</span><br><span class="line">    <span class="built_in">print</span>(perceptron)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        perceptron.train(data,target)</span><br><span class="line">    <span class="built_in">print</span>(perceptron)</span><br><span class="line">    acc=<span class="number">0</span></span><br><span class="line">    result=np.zeros_like(target)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(data.shape[<span class="number">0</span>]):</span><br><span class="line">        result[i]=perceptron.predict(data[i])</span><br><span class="line">        acc+=(result[i]==target[i])</span><br><span class="line">    imshow(data,target)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;acc=&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(acc / <span class="built_in">len</span>(target)))</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;目-录&quot;&gt;&lt;a href=&quot;#目-录&quot; class=&quot;headerlink&quot; title=&quot;目 录&quot;&gt;&lt;/a&gt;目 录&lt;/h2&gt;&lt;p&gt;1 背景知识 1&lt;br&gt;1.1 基本定义 1&lt;br&gt;1.2 感知器的损失函数 1&lt;br&gt;1.3 感知器的训练 1&lt;br&gt;2 数据集 </summary>
      
    
    
    
    <category term="计算智能" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD/"/>
    
    
    <category term="计算智能" scheme="http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>计算智能导论作业——FCM 聚类的实现</title>
    <link href="http://example.com/2021/05/30/%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA%E4%BD%9C%E4%B8%9A%E2%80%94%E2%80%94FCM%20%E8%81%9A%E7%B1%BB%E7%9A%84%E5%AE%9E%E7%8E%B0/"/>
    <id>http://example.com/2021/05/30/%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA%E4%BD%9C%E4%B8%9A%E2%80%94%E2%80%94FCM%20%E8%81%9A%E7%B1%BB%E7%9A%84%E5%AE%9E%E7%8E%B0/</id>
    <published>2021-05-30T10:29:37.000Z</published>
    <updated>2024-04-09T15:27:47.760Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目-录"><a href="#目-录" class="headerlink" title="目 录"></a>目 录</h2><p>1 背景知识 1<br>1.1 FCM 算法原理 1<br>2 数据集简介 1<br>2.1 Iris 数据集 1<br>3 实验环境 1<br>4 代码实现 2<br>5 结果分析 4<br>6 总结 4<br>A Iris FCM 程序代码 5</p><h2 id="1-背景知识"><a href="#1-背景知识" class="headerlink" title="1 背景知识"></a>1 背景知识</h2><h2 id="1-1-FCM-算法原理"><a href="#1-1-FCM-算法原理" class="headerlink" title="1.1 FCM 算法原理"></a>1.1 FCM 算法原理</h2><p>FCM 算法 (Fuzzy c-Means) 也称为模糊 $C$ 均值算法,是一种基于划分的聚类算法,他的思想就是使得被划分到同一簇的对象之间相似度最大, 而不同簇之间的相似度最小。模糊 $C$ 均值算法是普通 $C$ 均值算法的改进,普通 $C$ 均值算法对于数据的划分是硬性的,而 FCM 则是一种柔性的模糊划分。通过隶属度函数来描述样本属于某个集合的程度, 其自变量范围是所有样本点的所有值,值域范围是 $[0,1]$ ,即 $0 \leq \mu_A(x) \leq 1$。</p><p>有了模糊集合的概念, 一个元素属于某个类就不是硬性的, 而是属于某个聚类的隶属度是区间 $[0,1]$ 之间的值,样本属于所有类的隶属度之和应该等于 1,可以表示为</p><p>$$<br>J(U,z_{1},z_{2},\ldots,z_{c}) &#x3D; \sum_{j &#x3D; 1}^c J_j &#x3D; \sum_{j &#x3D; 1}^c \sum_{i &#x3D; 1}^m u_{ij}^{\alpha} d_{ij}^2<br>$$</p><p>对输入参量进行求导, 使得目标函数达到最小值的条件: 聚类中心:</p><p>$$<br>z_{i} &#x3D; \frac{\sum_{i &#x3D; 1}^m u_{ij}^{\alpha} x_{i}}{\sum_{i &#x3D; 1}^m u_{ij}^{\alpha}}<br>$$</p><p>隶属度矩阵中的值:</p><p>$$<br>u_{ij} &#x3D; \frac{1}{\sum_{k &#x3D; 1}^c \left( \frac{d_{ij}}{d_{ik}} \right)^{\frac{2}{\alpha - 1}}}<br>$$</p><p>该算法的思路即为如下:</p><p>Step1: 初始化隶属度矩阵 </p><p>Step2: 计算聚类中心 </p><p>Step3: 计算代价函数</p><p>Step4: 计算新的隶属度矩阵, 并返回 Step2</p><h2 id="2-数据集简介"><a href="#2-数据集简介" class="headerlink" title="2 数据集简介"></a>2 数据集简介</h2><h2 id="2-1-Iris-数据集"><a href="#2-1-Iris-数据集" class="headerlink" title="2.1 Iris 数据集"></a>2.1 Iris 数据集</h2><p>Iris 数据集是模式识别中最著名的数据集之一。Iris 数据集包含 3 个类, 每个类有 50 个实例, 其中每一类都是指一种鸢尾属植物。有一类是与另外两类是线性可分的, 而另外两类之间是线性不可分的。</p><h2 id="3-实验环境"><a href="#3-实验环境" class="headerlink" title="3 实验环境"></a>3 实验环境</h2><ul><li>系统: Windows 10</li><li>程序运行环境: Python 3.8</li><li>Python 库: numpy、pandas、matplotlib、sklearn、random</li><li>开发工具: Spyder、Pycharm</li></ul><h2 id="4-代码实现"><a href="#4-代码实现" class="headerlink" title="4 代码实现"></a>4 代码实现</h2><p>在代码实现这里, 这里首先创建了一个 FCM 聚类的类, 这个类的初始化部分用于初始化参数, 初始化的参数包括聚类中心与隶属度矩阵, 隶属度矩阵每行之和为 1 , 数据随机设置。随后创建了一个 fit 的函数用于计算聚类中心, 创建了一个 cost 函数计算代价函数, 创建 cal_u 函数更新隶属度矩阵, 随后创建了一个 cal_label 函数计算聚类后的标签, 创建 imshow 函数用于降维可视化, 具体代码如下:</p><hr><p>class FuzzyCMeans():<br>def init__(self, data, c, alpha&#x3D;2):<br>self.alpha ( &#x3D; ) alpha<br>self.data ( &#x3D; ) data<br>self.c ( &#x3D; c)<br>self.row, self.col &#x3D; data.shape<br>self.matrix ( &#x3D; ) np.zeros((self.row,self.c))<br>for i in range(self.row):<br>for (j) in range(self.c-1):<br>if np.sum(self.matrix[i, :]) &lt; 1 :<br>self.matrix[i, j] &#x3D; random.uniform(0, 1 -<br>np.sum(self.matrix[i, :]))<br>self.matrix[i,self.c - 1] &#x3D; 1 - np.sum(self.matrix[i, :])<br>self.centers ( &#x3D; ) np.zeros((self.c,self.col))<br>def fit(self):<br>for (j) in range(self.c):<br>up1 ( &#x3D; 0)<br>down1 ( &#x3D; 0)<br>for i in range(self.row):<br>up1 +&#x3D; (self.matrix[i, j] ** self.alpha) * self.data[i]<br>down1 +&#x3D; self.matrix[i, j] ** self.alpha<br>self.centers[j] &#x3D; up1 &#x2F; down1<br>def cost(self):<br>sum ( &#x3D; 0)<br>for (j) in range(self.c):<br>for i in range(self.row):<br>sum +&#x3D; (self.matrix[i, j] ** self.alpha) *<br>(np.linalg.norm(self.data[i] - self.centers[j]) ** 2)<br>return sum<br>def cal_u(self):<br>for i in range(self.row):<br>for (j) in range(self.c):<br>down2 ( &#x3D; 0)</p><hr><hr><p>for (\mathrm{k}) in range (self.c):<br>down2 +&#x3D; (np.linalg.norm(self.data[i] - self.centers[j])<br>&#x2F; np.linalg.norm(<br>self.data[i] - self.centers[k])) ** (2 &#x2F; (self.alpha<br>( {-} 1)))<br>self.matrix (\lbrack i,j\rbrack &#x3D; 1&#x2F;\left( \operatorname{down}2 \right))<br>def cal_label(self):<br>lab ( &#x3D; ) np.argmax(self.matrix,axis&#x3D;1)<br>return lab<br>def calcute(self, epochs):<br>for epoch in range(epochs):<br>self.fit()<br>result ( &#x3D; \operatorname{self} {\cdot} \operatorname{cost}())<br>print (result)<br>self.cal_u()<br>label &#x3D; self.cal_label()<br>return label<br>def imshow(self, label):<br>tsne ( &#x3D; TSNE(n_) components ( &#x3D; 2) ,<br>learning_rate&#x3D;100).fit_transform(self.data)<br>pca ( &#x3D; ) PCA().fit_transform(self.data)<br>plt.figure(figsize&#x3D;(12, 6))<br>plt.subplot(121)<br>plt.scatter(tsne[:,0],tsne[:,1], c&#x3D;label)<br>plt.title(‘t-SNE’)<br>plt.subplot(122)<br>plt.scatter(pca[:,0],pca[:,1], c&#x3D;label)<br>plt.title(‘PCA’)<br>plt.colorbar()<br>plt.show()</p><hr><p>然后是主函数部分, 此部分是关于创建出的类的使用, 首先读取数据并创建类的对象, 设置迭代次数为 50 , 然后使用 fcm 聚类方法进行计算得到结果, 然后进行可视化并计算聚类的标准轮廓系数, 代码如下:</p><hr><p>if _<em>name</em> &#x3D;&#x3D; ‘<strong>main</strong>‘:<br>(c &#x3D; 3)<br>iris ( &#x3D; ) load_iris()<br>data ( &#x3D; ) iris.data<br># target &#x3D; iris.target<br>(f\mathrm{\ cm} &#x3D; ) FuzzyCMeans(data, (c &#x3D; c) )</p><hr><p>label ( &#x3D; f\mathrm{\ cm}) . calcute (epochs ( &#x3D; 50) ) print(label)<br>fcm.imshow(label)<br>(s &#x3D; ) metrics.silhouette_score(data,label,metric&#x3D;’euclidean’) print(‘轮廓系数为 ({: .4f}) ‘.format(s))</p><h2 id="5-结果分析"><a href="#5-结果分析" class="headerlink" title="5 结果分析"></a>5 结果分析</h2><p>经过实验, 可以得到最终结果如下图所示, 其中代价函数最后为 60.5057, 计算得到的<br>轮廓系数为 0.5495 , 由下图可以看出, 聚类效果很好, 完成了聚类的任务。</p><img src="https://cdn.noedgeai.com/13b8aff7-d660-486b-8d4a-83244a4fc29c_5.jpg?x=181&y=341&w=479&h=254 "/><p>图 1: 结果图</p><h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6 总结"></a>6 总结</h2><p>本次作业算法相当一部分都已经给出, 因此写的过程中问题不大, 在这次实验中遇到的一个问题是在开始初始化隶属度矩阵的时候, 我将矩阵的所有值都统一为聚类数分之一, 这样导致的后果是随着迭代进行, 聚类中心以及隶属度矩阵都没有发生变化, 后来经过仔细检查才发现问题并进行解决。<br>在这次实验中, 开始在理解题意方面遇到了很多问题, 后来经过多方询问才明白。这次实验中我通过广泛查询资料了解到了相关的知识, 也认真写代码来完成任务, 这份作业的完成确实比较艰巨, 一份顶多份, 但是我还是有很大的收获, 能力也得到了提升。</p><h2 id="A-Iris-FCM-程序代码"><a href="#A-Iris-FCM-程序代码" class="headerlink" title="A Iris FCM 程序代码"></a>A Iris FCM 程序代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.manifold <span class="keyword">import</span> TSNE</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FuzzyCMeans</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data, c, alpha=<span class="number">2</span></span>):</span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        self.data = data</span><br><span class="line">        self.c = c</span><br><span class="line">        self.row, self.col = data.shape</span><br><span class="line">        self.matrix = np.zeros((self.row, self.c))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.row):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.c-<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> np.<span class="built_in">sum</span>(self.matrix[i, :]) &lt; <span class="number">1</span> :</span><br><span class="line">                    self.matrix[i, j] = random.uniform(<span class="number">0</span>, <span class="number">1</span> - np.<span class="built_in">sum</span>(self.matrix[i, :]))</span><br><span class="line">            self.matrix[i, self.c - <span class="number">1</span>] = <span class="number">1</span> - np.<span class="built_in">sum</span>(self.matrix[i, :])</span><br><span class="line">        self.centers = np.zeros((self.c, self.col))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.c):</span><br><span class="line">            up1 = <span class="number">0</span></span><br><span class="line">            down1 = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.row):</span><br><span class="line">                up1 += (self.matrix[i, j] ** self.alpha) * self.data[i]</span><br><span class="line">                down1 += self.matrix[i, j] ** self.alpha</span><br><span class="line">            self.centers[j] = up1 / down1</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cost</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.c):</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.row):</span><br><span class="line">                <span class="built_in">sum</span> += (self.matrix[i, j] ** self.alpha) * (np.linalg.norm(self.data[i] - self.centers[j]) ** <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cal_u</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.row):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.c):</span><br><span class="line">                down2 = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(self.c):</span><br><span class="line">                    down2 += (np.linalg.norm(self.data[i] - self.centers[j]) / np.linalg.norm(</span><br><span class="line">                        self.data[i] - self.centers[k])) ** (<span class="number">2</span> / (self.alpha - <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">                self.matrix[i, j] = <span class="number">1</span> / (down2)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cal_label</span>(<span class="params">self</span>):</span><br><span class="line">        lab = np.argmax(self.matrix, axis=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> lab</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">calcute</span>(<span class="params">self, epochs</span>):</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">            self.fit()</span><br><span class="line">            result = self.cost()</span><br><span class="line">            <span class="built_in">print</span>(result)</span><br><span class="line">            self.cal_u()</span><br><span class="line">        label = self.cal_label()</span><br><span class="line">        <span class="keyword">return</span> label</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">imshow</span>(<span class="params">self, label</span>):</span><br><span class="line">        tsne = TSNE(n_components=<span class="number">2</span>, learning_rate=<span class="number">100</span>).fit_transform(self.data)</span><br><span class="line">        pca = PCA().fit_transform(self.data)</span><br><span class="line">        plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">        plt.subplot(<span class="number">121</span>)</span><br><span class="line">        plt.scatter(tsne[:, <span class="number">0</span>], tsne[:, <span class="number">1</span>], c=label)</span><br><span class="line">        plt.title(<span class="string">&#x27;t-SNE&#x27;</span>)</span><br><span class="line">        plt.subplot(<span class="number">122</span>)</span><br><span class="line">        plt.scatter(pca[:, <span class="number">0</span>], pca[:, <span class="number">1</span>], c=label)</span><br><span class="line">        plt.title(<span class="string">&#x27;PCA&#x27;</span>)</span><br><span class="line">        plt.colorbar()</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    c = <span class="number">3</span></span><br><span class="line">    iris = load_iris()</span><br><span class="line">    data = iris.data</span><br><span class="line">    <span class="comment"># target = iris.target</span></span><br><span class="line">    fcm = FuzzyCMeans(data, c=c)</span><br><span class="line">    label = fcm.calcute(epochs=<span class="number">50</span>)</span><br><span class="line">    <span class="built_in">print</span>(label)</span><br><span class="line">    fcm.imshow(label)</span><br><span class="line">    s = metrics.silhouette_score(data, label, metric=<span class="string">&#x27;euclidean&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;轮廓系数为&#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(s))</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;目-录&quot;&gt;&lt;a href=&quot;#目-录&quot; class=&quot;headerlink&quot; title=&quot;目 录&quot;&gt;&lt;/a&gt;目 录&lt;/h2&gt;&lt;p&gt;1 背景知识 1&lt;br&gt;1.1 FCM 算法原理 1&lt;br&gt;2 数据集简介 1&lt;br&gt;2.1 Iris 数据集 1&lt;br&gt;3 实验环</summary>
      
    
    
    
    <category term="计算智能" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD/"/>
    
    
    <category term="计算智能" scheme="http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>机器学习上机报告——聚类分析</title>
    <link href="http://example.com/2021/05/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8A%E6%9C%BA%E6%8A%A5%E5%91%8A%E2%80%94%E2%80%94%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/"/>
    <id>http://example.com/2021/05/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8A%E6%9C%BA%E6%8A%A5%E5%91%8A%E2%80%94%E2%80%94%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/</id>
    <published>2021-05-23T12:29:37.000Z</published>
    <updated>2024-04-09T15:27:47.760Z</updated>
    
    <content type="html"><![CDATA[<h1 id="摘-要"><a href="#摘-要" class="headerlink" title="摘 要"></a>摘 要</h1><p>本文使用了 K-means 和 DBSCAN 两种聚类方法, 较好的完成了聚类任务, 并将得到的结果使用了 t-SNE 和 PCA 两种方法进行降维可视化,从而更好的得到聚类的效果,并计算了轮廓系数、 (\mathrm{CH}) score、 DBI 这些聚类指标, 对于 K-means 方法还使用了图片进行聚类, 使得效果更加直观, 实验效果非常好。<br>在这次实验中, 使用的两种聚类方法, K-means 是基于原型的方法, 而 DBSCAN 是基于密度的聚类方法。本文首先介绍了两种聚类方法的背景知识以及相关指标的知识, 随后简单介绍了 Iris 数据集, 然后展示出实验环境。<br>在代码实现部分, 本文分别对两种聚类方法列出了重点的代码, 并<br>进行简要的介绍, 说明这些部分是如何通过代码实现的。<br>在实验结果部分, 本文展示了两种聚类方法的结果, 对于 K-means 方法, 使用 Iris 数据集进行了降维可视化, 并算出 Iris 的轮廓系数为 0.4976 , 对图片进行聚类, 得到着色后的效果图, 并进行降维可视化。对于 DBSCAN 方法, 这里使用了八组数据进行展示, 分别对八组数据求出其轮廓系数、 (\mathrm{CH}) score、 (\mathrm{DBI}) 这些聚类指标,并得到了较好的实验效果, 数据较多, 具体数据以及聚类效果图见正文部分。<br>最后对本次实验进行了总结, 分析实验得出了收获以及思考。关键字: K-means DBSCAN 轮廓系数 PCA t-SNE</p><h2 id="目-录"><a href="#目-录" class="headerlink" title="目 录"></a>目 录</h2><p>1 背景知识 1<br>1.1 基于原型的方法 1<br>1.2 基于密度的方法论 1<br>1.2.1 基本知识 1<br>1.2 .2 基本概念 1<br>1.3 轮廓系数 2<br>2 Iris 数据集简介 2<br>3 实验环境 2<br>4 代码实现 2<br>(4.1\mathrm{kmeans}) 代码实现 2<br>4.2 DBSCAN 代码实现 4<br>5 结果与分析 7<br>(5.1\mathrm{kmeans}) 聚类 7<br>5.2 DBSCAN 聚类 9<br>6 总结 11<br>A K-means 程序代码 12<br>B DBSCAN 程序代码 15</p><h2 id="1-背景知识"><a href="#1-背景知识" class="headerlink" title="1 背景知识"></a>1 背景知识</h2><h2 id="1-1-基于原型的方法"><a href="#1-1-基于原型的方法" class="headerlink" title="1.1 基于原型的方法"></a>1.1 基于原型的方法</h2><p>本作业使用的基于原型的方法即 K-means 聚类算法，其原理如下:<br>K-均值 (K-means) 聚类算法是应用最广泛的基于划分的聚类算法之一，适用于处理大样本数据。其基础是最小误差平方和准则，若 $N_{i}$ 是第 $i$ 聚类 $\Gamma$ 中的样本数目，$m_{i}$ 是这些样本的均值，即</p><p>$$<br>m_{i} &#x3D; \frac{1}{N_{i}} \sum_{y \in \Gamma} y<br>$$</p><p>把其中的各样本 $y$ 与均值 $m_{i}$ 间的误差平方和对所有类相加后即得目标函数为:</p><p>$$<br>J_{e} &#x3D; \sum_{i &#x3D; 1}^c \sum_{y \in \Gamma_{i}} \left| y - m_{i} \right|^2<br>$$</p><p>即需进行优化使上式的值取得最小。<br>该算法的的步骤如下:</p><ol><li>Step1: 选取 $K$ 个初始聚类中心。</li><li>Step2: 根据最小距离标准将要分类的模式样本划分到某个簇中心。</li><li>Step3: 计算各个聚类中心的新的向量值及计算各聚类簇中样本数据的均值向量。</li><li>Step4: 若聚类中心与上一次的相同，则返回 Step2，否则计算结束。</li></ol><h2 id="1-2-基于密度的方法论"><a href="#1-2-基于密度的方法论" class="headerlink" title="1.2 基于密度的方法论"></a>1.2 基于密度的方法论</h2><h2 id="1-2-1-基本知识"><a href="#1-2-1-基本知识" class="headerlink" title="1.2.1 基本知识"></a>1.2.1 基本知识</h2><p>基于密度的聚类中著名的是 DBSCAN, DBSCAN (Density-Based Spatial Clustering of Applications with Noise, 具有噪声的基于密度的聚类方法) 是一种基于密度的空间聚类算法。该算法将具有足够密度的区域划分为簇, 并在具有噪声的空间数据库中发现任意形状的簇, 它将簇定义为密度相连的点的最大集合。<br>该方法主要有以下特点:</p><ul><li>发现任意类型的聚类</li><li>处理噪音</li><li>一编扫描</li><li>需要密度参数作为终止条件<br>在使用密度聚类算法的时候, 有两个超参数, 领域的最大半径 Eps 和领域中最少的点<br>数 MinPts。</li></ul><h2 id="1-2-2-基本概念"><a href="#1-2-2-基本概念" class="headerlink" title="1.2.2 基本概念"></a>1.2.2 基本概念</h2><p>此处需要定义几个概念:</p><ul><li>核心对象: 一个对象的 $\epsilon$-邻域至少包含最小数目 MinPts 个对象。不是核心点的 Eps 邻域内的对象称为边界点，不属于任何簇的对象为噪声。对于空间中的一个对象，如果它在给定半径 $\epsilon$ 的邻域中的对象个数大于密度阈值 MinPts，则该对象被称为核心对象，否则称为边界对象。</li><li>密度可达: 存在一个从 $p$ 到 $q$ 的 DDR 对象链（如果存在一条链 $&lt; p1, p2, \ldots, pi &gt;$，满足 $p1 &#x3D; p, pi &#x3D; q, p_{i}$ 直接密度可达 $p_{i + 1}$，则称 $p$ 密度可达 $q$）。</li><li>由一个核心对象和其密度可达的所有对象构成一个聚类。</li></ul><h2 id="1-3-轮廓系数"><a href="#1-3-轮廓系数" class="headerlink" title="1.3 轮廓系数"></a>1.3 轮廓系数</h2><p>轮廓系数是聚类好坏的一种评价方式，它结合内聚度和分离度两种因素。可以用来在相同原始数据的基础上用来评价不同算法、或者算法不同运行方式对聚类结果所产生的影响。其计算方法如下:<br>对于其中的一个点 $i$ 而言，首先计算 $a(i) &#x3D; \text{average} \left( \text{i 向量到所有它属于的簇中其它点的距离} \right)$ 然后计算 $b(i) &#x3D; \min \left( \text{i 向量到与它相邻最近的一簇内的所有点的平均距离} \right)$，那么 $i$ 向量轮廓系数为:</p><p>$$<br>S(i) &#x3D; \frac{b(i) - a(i)}{\max{a(i), b(i)}}<br>$$</p><p>轮廓系数的值是介于 $[-1,1]$，越趋近于 1 则代表内聚度和分离度都相对较优。</p><h2 id="2-Iris-数据集简介"><a href="#2-Iris-数据集简介" class="headerlink" title="2 Iris 数据集简介"></a>2 Iris 数据集简介</h2><p>Iris 数据集是著名的数据集之一。Iris 数据集包含 3 个类, 每个类有 50 个实例, 其中每一类都是指一种鸢尾属植物。有一类是与另外两类是线性可分的, 而另外两类之间是线性不可分的。</p><h2 id="3-实验环境"><a href="#3-实验环境" class="headerlink" title="3 实验环境"></a>3 实验环境</h2><ul><li>系统: Windows 10</li><li>程序运行环境: Python 3.8</li><li>Python 库: numpy、pandas、matplotlib、sklearn、random</li><li>开发工具: Spyder、VSCode</li></ul><h2 id="4-代码实现"><a href="#4-代码实现" class="headerlink" title="4 代码实现"></a>4 代码实现</h2><p>在代码实现中,对于 kmeans 我使用了两种数据集进行实现, 第一种使用了经典的数据集 Iris 鸢尾花, 为了更好的体现聚类的效果, 我使用了一张照片进行聚类, 对不同的聚类使用不同的颜色表示。在评估聚类的效果时,对于 kmeans 聚类, 这里使用了不同聚类的平均轮廓系数来进行分析。对于这两种数据, 都使用了 t-SNE 和 PCA 两种降维方式来展示效果。<br>对于 DBSCAN 聚类, 这里使用了一些聚类的数据并可视化, 可以很好的表达密度聚类<br>的效果。</p><h2 id="4-1-kmeans-代码实现"><a href="#4-1-kmeans-代码实现" class="headerlink" title="4.1 kmeans 代码实现"></a>4.1 kmeans 代码实现</h2><p>对于 kmeans 的 Iris 实现, 这里建立了一个类来进行处理, 在获取到数据后, 首先根据设置的 (\mathrm{k}) 值,选出 (\mathrm{k}) 个初始聚类中心,本代码使用的方法是从数据集中随机抽取 (\mathrm{k}) 个数据来初始化,并将数据的序号记录下来,其 (\mathrm{k}) 个点的四维的数据直接存放到建立好的 (k {\times} 4)<br>的数组中, 随后按照算法一步一步迭代, 直到达到终止条件, 这里终止条件设置的为迭代的次数, 最后可以得到聚类的中心点以及每个数据的标签, 随后运用两种降维方式可视化出来, 然后利用 sklearn 库来计算平均轮廓系数。<br>对于用 kmeans 处理照片, 主函数部分与 Iris 的实现相同, 但是多了一些部分, 首先读取照片, 并将三维转为二维, 从而方便进行处理, 随后进行聚类, 得出结果后, 把数据恢复成三维, 并将图片按照聚类着色为多种颜色, 并利用 t-SNE 和 PCA 进行降维可视化, 得到结果。<br>聚类部分建立的类代码如下: 初始化参数, 函数 fit 进行聚类, imshow 降维展示, plot_img 图片着色。</p><hr><p>class Kmeans () :<br>def <strong>init</strong>(self,dat,k):<br>data&#x3D;scale(dat)<br>self.data&#x3D;data<br>self.row,self.col ( &#x3D; ) data.shape<br>self.k&#x3D;k<br>self.centers&#x3D;np.ndarray((k,self.col))<br>choices&#x3D;random.choices (range (self.row), k&#x3D;k)<br>for i in range(k):<br>self.centers[i,:]&#x3D;self.data[choices[i],:]<br>def fit(self,counts&#x3D;15):<br>count ( &#x3D; 0)<br>while (count&lt;counts):<br>self.labels&#x3D;np.zeros((self.row))<br>for i in range(self.data.shape[0]):<br>dis&#x3D;[]<br>for (j) in range(self.k):<br>dis.append(np.linalg.norm(self.\&amp;<br>data (\lbrack i, : \rbrack) -self.centers (\lbrack j, : \rbrack) ,axis&#x3D;0))<br>lab&#x3D;np.argmin(dis,axis&#x3D;0)<br>self.labels [i]&#x3D;lab<br>self.result&#x3D;\{\}<br>for i in range(self.k):<br>type&#x3D;np.where(self.labels&#x3D;&#x3D;i) [0]<br>self.result[i]&#x3D;type<br>if (\operatorname{len}\left( \text{type} \right) &#x3D; &#x3D; 0) :<br>self.centers (\lbrack i, : \rbrack &#x3D; 0)<br>else:<br>self.centers [i,:]&#x3D;np.mean(self.data[type,:],axis&#x3D;0)<br>count ( + &#x3D; 1)<br>return self.centers, self.result<br>def imshow(self):</p><p>tsne ( &#x3D; TSNE) (n_components ( &#x3D; 2) ,</p><p>learning_rate&#x3D;100).fit_transform(self.data)<br>pca ( &#x3D; ) PCA().fit_transform(self.data)<br>plt.figure(figsize&#x3D;(12, 6))<br>plt.subplot(121)<br>plt.scatter(tsne[:, 0], tsne[:, 1], c&#x3D;self.labels)<br>plt.subplot(122)<br>plt.scatter(pca[:, 0], pca[:, 1], c&#x3D;self.labels)<br>plt.colorbar()<br>plt.show()<br>def plot_img(self,row,col):<br>img&#x3D;self.labels.reshape(row, col)<br>(\mathrm{im} &#x3D; ) Image.new(“RGB”,(row,col)) # 创建图片<br>for i in range(row):<br>for (j) in range(col):<br>if (\operatorname{img}\lbrack i,j\rbrack &#x3D; &#x3D; 0) :<br>im.putpixel((i, j), (255, 0, 0))<br>if (\operatorname{img}\lbrack i,j\rbrack &#x3D; &#x3D; 1) :<br>im.putpixel((i, j), (0, 255, 0))<br>if (\operatorname{img}\lbrack i,j\rbrack &#x3D; &#x3D; 2) :<br>im.putpixel((i,j), ((0,0,255)) )<br>im.show()<br>im.save(‘result.jpg’)</p><hr><p>主函数代码如下:<br>path&#x3D;’ .&#x2F;2.bmp’<br>file&#x3D;Image.open(path,’ (r) ’) file&#x3D;np.array(file) row,col,_&#x3D;file.shape data&#x3D;file.reshape (({-}1,3)) kmeans&#x3D;Kmeans(data,3)<br>centers, results&#x3D;kmeans. fit (10) kmeans.imshow()<br>kmeans.plot_img(row, col) print (centers) print (results)<br>此部分进行图片的读取与降维预处理, 然后进行聚类, 然后可视化。<br>Iris 的代码与之相差不大, 不再单独列出, 见附录。</p><h2 id="4-2-DBSCAN-代码实现"><a href="#4-2-DBSCAN-代码实现" class="headerlink" title="4.2 DBSCAN 代码实现"></a>4.2 DBSCAN 代码实现</h2><p>在代码实现的过程中, 主要有以下步骤: </p><ol><li>读取数据</li><li>构建密度聚类函数</li><li>将聚类后的结果可视化 4. 对聚类效果进行评价<br>读取数据采用了 scipy 中的 scio 来读取.mat 文件, 然后初步处理并传给聚类函数, 然后对结果可视化,最后利用 sklearn 中的库函数 metrics 来计算轮廓系数、 (\mathrm{CH}) score 以及 DBI 这三个指标。<br>首先定义了两个函数用于计算相关信息:<br>def calDist (\left( \mathrm{X}1,\mathrm{X}2 \right)) :<br>sum ( &#x3D; 0)<br>for (x1,x2) in (zip(x1,X2)) :<br>sum +&#x3D; ((x1 {-} x2) * * 2)<br>return sum ** 0.5<br>def getNeibor(data, dataSet, e):<br>res ( &#x3D; \lbrack\rbrack)<br>for i in range(dataSet.shape[0]):<br>if calDist(data, dataSet[i]) &lt; e: res.append(i)<br>return res<br>随后定义密度聚类的主函数:<br>def DBSCAN(dataSet, e, minPts):<br>coreObjs ( &#x3D; {}#) 初始化核心对象集合 (\mathrm{C} &#x3D; {})<br>(\mathrm{n} &#x3D; ) dataSet.shape (\lbrack 0\rbrack)<br># 找出所有核心对象, key 是核心对象的index, value是 -邻域中对象的index for i in range(n):<br>neibor ( &#x3D; ) getNeibor(dataSet[i],dataSet,e) if len(neibor) &gt;&#x3D; minPts:<br>coreObjs [i] &#x3D; neibor oldCoreObjs ( &#x3D; ) coreObjs.copy() (\mathrm{k} &#x3D; 0#) 初始化聚类簇数<br>notAccess &#x3D; list(range(n)) # 初始化未访问样本集合（索引） while len(coreObjs) &gt; 0: OldNotAccess ( &#x3D; \lbrack\rbrack)<br>OldNotAccess. extend(notAccess) cores ( &#x3D; ) coreObjs.keys() # 随机选取一个核心对象<br>randNum &#x3D; random.randint (\left( 0,\operatorname{len}\left( \operatorname{cores} \right) {-} 1 \right)) cores ( &#x3D; ) list(cores) core ( &#x3D; ) cores (\left\lbrack \text{randNum} \right\rbrack)</li></ol><hr><p>queue ( &#x3D; \lbrack\rbrack)<br>queue.append(core)<br>notAccess. remove (core)<br>while len(queue) &gt; 0:<br>(\mathrm{q} &#x3D; ) queue (\lbrack 0\rbrack)<br>del queue [0]<br>if (q) in oldCoreObjs.keys():<br>delte ( &#x3D; ) [val for val in oldCoreObjs[q] if val in notAccess]<br>(#\Delta &#x3D; \mathrm{N}\left( \mathrm{q} \right)\Gamma)<br>queue.extend(delte) # 将 (\Delta) 中的样本加入队列Q<br>notAccess ( &#x3D; ) [val for val in notAccess if val not in delte] #<br>(\Gamma &#x3D; \Gamma {\smallsetminus} \Delta)<br>(\mathrm{k} + &#x3D; 1)<br>(\mathrm{C}\left\lbrack \mathrm{k} \right\rbrack &#x3D; ) [val for val in OldNotAccess if val not in notAccess]<br>for (x) in (C\lbrack k\rbrack) :<br>if (x) in coreObjs.keys():<br>del coreObjs [x]<br>return (\mathrm{C})</p><p>随后定义了一个可视化函数, 主函数算出的聚类结果存在字典里, 这个函数将其标签<br>转化为数组形式, 代码如下:</p><p>def draw(C, D) :<br>colors &#x3D; list (mcolors. TABLEAU_COLORS.keys())<br>predict ( &#x3D; ) np.zeros ((D.shape [0],D.shape [1] + 1))<br>(j &#x3D; 0)<br>keys ( &#x3D; ) C. keys ()<br>print(keys)<br>for (\mathrm{k}) in keys:<br>for (i) in (C\lbrack k\rbrack) :<br>predict (\lbrack j,0 : 2\rbrack &#x3D; D\lbrack i\rbrack)<br>predict (\lbrack j,2\rbrack &#x3D; k)<br>(j &#x3D; j + 1)<br>plt.scatter(D[i, 0], D[i, 1], color&#x3D;colors[k + 1])<br>plt.show()<br>return predict</p><hr><p>随后定义主函数, 读取数据并进行聚类, 随后计算三个指标, 代码如下:<br>def main():<br>path ( &#x3D; ) ,&#x2F;data-密度聚类&#x2F;square1.mat’ data ( &#x3D; ) scio.loadmat(path) [‘square1’] # plt.scatter(data[:,0],data[:,1]) # plt.show()<br>(D &#x3D; \operatorname{data}\lbrack : ,0 : 2\rbrack)<br>label ( &#x3D; ) data (\lbrack 2\rbrack)<br>(\mathrm{C} &#x3D; \operatorname{DBSCAN}\left( \mathrm{D},0.9,15 \right)) predict ( &#x3D; \operatorname{draw}(C,D))<br>s1 &#x3D; metrics.silhouette_score(predict[:, 0:2], predict[:, 2],<br>metric&#x3D;’euclidean’)<br>s2 &#x3D; calinski_harabasz_score(predict[:,0:2], predict[:,2]) #计算CH<br>score<br>s3 &#x3D; davies_bouldin_score(predict[:,0:2], predict[:, 2]) # 计算 DBI print(s1, s2, s3)</p><h2 id="5-结果与分析"><a href="#5-结果与分析" class="headerlink" title="5 结果与分析"></a>5 结果与分析</h2><h2 id="5-1-kmeans-聚类"><a href="#5-1-kmeans-聚类" class="headerlink" title="5.1 kmeans 聚类"></a>5.1 kmeans 聚类</h2><p>利用 K-means 聚类对 Iris 数据的处理结果如图 1 所示,其中 (\mathrm{K}) 设置为 3,迭代次数<br>设置为 15 。</p><img src="https://cdn.noedgeai.com/a5fee367-df47-4713-89f7-58942dcd50cc_9.jpg?x=134&y=473&w=577&h=303 "/><p>图 1: kmeans 对 Iris 的聚类效果</p><p>由图片可以看出, 两种降维方式效果都非常好, 三类数据基本可以较好的分出来, 其中<br>两类较为相似, 这两类与另一类相差较大, 聚类效果较好。<br>此外, 对于 Iris 数据集, 这里还计算了轮廓系数, 在 3 分类迭代次数为 15 的情况下,<br>不同类别的平均轮廓系数为 0.4976 。<br>下面利用 kmeans 聚类对图像进行处理, 图 2 是一张照片:<br>对上面的这张照片聚类处理并着色后,结果如图 3 所示,其中 (\mathrm{K}) 设置为 3,迭代次数<br>设置为 15 。<br>由上图处理后的图像可以看出, 图片的聚类效果较好, 图片的轮廓信息可以较好的保<br>留下来, 聚类任务完成。<br>其中聚类处理后分别使用 t-SNE 和 PCA 降维可视化的效果如图 4 所示。<br><img src="https://cdn.noedgeai.com/a5fee367-df47-4713-89f7-58942dcd50cc_10.jpg?x=131&y=96&w=581&h=394 "/></p><p>图 2: 聚类前的原图</p><img src="https://cdn.noedgeai.com/a5fee367-df47-4713-89f7-58942dcd50cc_10.jpg?x=132&y=606&w=580&h=391 "/><p>图 3: kmeans 对图像的聚类效果<br><img src="https://cdn.noedgeai.com/a5fee367-df47-4713-89f7-58942dcd50cc_11.jpg?x=131&y=64&w=579&h=300 "/></p><p>图 4: kmeans 对图片的聚类效果降维展示</p><p>由上图可以看出, 两种降维方式中 PCA 的效果更好, 对图片的聚类任务完成的很好,<br>这也印证了图片的着色图效果较好。</p><h2 id="5-2-DBSCAN-聚类"><a href="#5-2-DBSCAN-聚类" class="headerlink" title="5.2 DBSCAN 聚类"></a>5.2 DBSCAN 聚类</h2><p>以下是利用一些数据进行密度聚类的效果图片。</p><img src="https://cdn.noedgeai.com/a5fee367-df47-4713-89f7-58942dcd50cc_11.jpg?x=147&y=584&w=250&h=187 "/><p>图 5: 密度聚类 1</p><img src="https://cdn.noedgeai.com/a5fee367-df47-4713-89f7-58942dcd50cc_11.jpg?x=429&y=584&w=255&h=187 "/><p>图 6: 密度聚类 2</p><p>设置半径 (\mathrm{Eps}) 为 (0.04,\mathrm{Minpts}) 为 5 时,可以将数据三分类,得到图像如图 5 所示,轮<br>廓系数、 (\mathrm{CH}) score、 (\mathrm{DBI}) 分别为 (0.356{、}79.043{、}1.265) 。<br>设置半径 Eps 为 0.75, Minpts 为 5 时, 可以将数据四分类, 得到图像如图 6所示, 轮<br>廓系数、 (\mathrm{CH}) score、 (\mathrm{DBI}) 分别为 (0.674{、}5185.453{、}0.397) 。<br>设置半径 Eps 为 0.87, Minpts 为 16 时, 可以将数据三分类, 得到图像如图 7 所示,<br>轮廓系数、 (\mathrm{CH}) score、 (\mathrm{DBI}) 分别为 (0.572{、}2147.144{、}5.919) 。<br>设置半径 Eps 为 0.2, Minpts 为 5 时, 可以将数据二分类, 得到图像如图 8 所示, 轮<br>廓系数、 (\mathrm{CH}) score、 (\mathrm{DBI}) 分别为 (0.321{、}156.074{、}1.017) 。<br>设置半径 (\mathrm{Eps}) 为 (0.2,\mathrm{Minpts}) 为 5 时,可以将数据二分类,得到图像如图 9 所示,轮<br>廓系数、 (\mathrm{CH}) score、 (\mathrm{DBI}) 分别为 ( {-} 0.062{、}151.734{、}5.350) 。<br><img src="https://cdn.noedgeai.com/a5fee367-df47-4713-89f7-58942dcd50cc_12.jpg?x=153&y=206&w=245&h=187 "/></p><p>图 7: 密度聚类 3</p><img src="https://cdn.noedgeai.com/a5fee367-df47-4713-89f7-58942dcd50cc_12.jpg?x=432&y=205&w=251&h=189 "/><p>图 8: 密度聚类 4</p><img src="https://cdn.noedgeai.com/a5fee367-df47-4713-89f7-58942dcd50cc_12.jpg?x=143&y=714&w=255&h=186 "/><p>图 9: 密度聚类 5</p><img src="https://cdn.noedgeai.com/a5fee367-df47-4713-89f7-58942dcd50cc_12.jpg?x=431&y=715&w=255&h=186 "/><p>图 10: 密度聚类 6<br>设置半径 Eps 为 1.1, Minpts 为 10 时, 可以将数据四分类, 得到图像如图 10 所示,<br>轮廓系数、 (\mathrm{CH}) score、 (\mathrm{DBI}) 分别为 (0.664{、}1509.256{、}3.146) 。</p><img src="https://cdn.noedgeai.com/a5fee367-df47-4713-89f7-58942dcd50cc_13.jpg?x=437&y=140&w=246&h=187 "/><p>图 12: 密度聚类 8</p><img src="https://cdn.noedgeai.com/a5fee367-df47-4713-89f7-58942dcd50cc_13.jpg?x=150&y=139&w=248&h=187 "/><p>图 11: 密度聚类 7</p><p>设置半径 (\mathrm{Eps}) 为 0.2,Minpts 为 5 时,可以将数据二分类,得到图像如图 11 所示,轮<br>廓系数、 (\mathrm{CH}) score、 (\mathrm{DBI}) 分别为 (0.045{、}13.449{、}5.843) 。<br>设置半径 Eps 为 0.9, Minpts 为 15 时, 可以将数据四分类, 得到图像如图 12 所示,<br>轮廓系数、 (\mathrm{CH}) score、 (\mathrm{DBI}) 分别为 (0.664{、}4527.194{、}1.435) 。<br>从上面对八个数据集进行的密度聚类, 我们可以看出聚类达到了很好的效果, 不同分布结构的数据在设置不同的参数后都可以很好的被分类, 这样相比 kmeans 适用的范围更广, 缺点是算法相对于 kmeans 更复杂, 而且需要调整合适的参数才能得到较好的结果。</p><h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6 总结"></a>6 总结</h2><p>这次的实验任务相对较多, 完成任务花费了不少的时间, 但在这个过程中我也收获了很多东西, 学习到了新的知识, 也加强了自己的代码能力, 在这个过程中也多方请假同学, 并广泛查阅了资料, 能力得到了提升, 对于聚类的了解增强了, 运用能力也得到了强化。</p><h2 id="A-K-means-程序代码"><a href="#A-K-means-程序代码" class="headerlink" title="A K-means 程序代码"></a>A K-means 程序代码</h2><p>KMEANS IRIS 程序 - kmeans.py </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># Author : JackZhu</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Data : 2021/5/10 23:10</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> scale</span><br><span class="line"><span class="keyword">from</span> sklearn.manifold <span class="keyword">import</span> TSNE</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Kmeans</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,dat,k</span>):</span><br><span class="line">        data=scale(dat)</span><br><span class="line">        self.data=data</span><br><span class="line">        self.row, self.col = data.shape</span><br><span class="line">        self.k=k</span><br><span class="line">        self.centers=np.ndarray((k,self.col))</span><br><span class="line">        choices=random.choices(<span class="built_in">range</span>(self.row),k=k)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">            self.centers[i,:]=self.data[choices[i],:]</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self</span>):</span><br><span class="line">        count=<span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span>(count&lt;<span class="number">15</span>):</span><br><span class="line">            self.labels=np.zeros((self.row))</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.data.shape[<span class="number">0</span>]):</span><br><span class="line">                dis=[]</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.k):</span><br><span class="line">                    dis.append(np.linalg.norm(self.data[i,:]-self.centers[j,:],axis=<span class="number">0</span>))</span><br><span class="line">                lab=np.argmin(dis,axis=<span class="number">0</span>)</span><br><span class="line">                self.labels[i]=lab</span><br><span class="line">            self.result=&#123;&#125;</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.k):</span><br><span class="line">                <span class="built_in">type</span>=np.where(self.labels==i)[<span class="number">0</span>]</span><br><span class="line">                self.result[i]=<span class="built_in">type</span></span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(<span class="built_in">type</span>)==<span class="number">0</span>:</span><br><span class="line">                    self.centers[i, :] =<span class="number">0</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    self.centers[i,:]=np.mean(self.data[<span class="built_in">type</span>,:],axis=<span class="number">0</span>)</span><br><span class="line">            count+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> self.centers, self.result,self.labels</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">imshow</span>(<span class="params">self</span>):</span><br><span class="line">        tsne = TSNE(n_components=<span class="number">2</span>, learning_rate=<span class="number">100</span>).fit_transform(self.data)</span><br><span class="line">        pca = PCA().fit_transform(self.data)</span><br><span class="line">        plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">        plt.subplot(<span class="number">121</span>)</span><br><span class="line">        plt.scatter(tsne[:, <span class="number">0</span>], tsne[:, <span class="number">1</span>], c=self.labels)</span><br><span class="line">        plt.title(<span class="string">&#x27;t-SNE&#x27;</span>)</span><br><span class="line">        plt.subplot(<span class="number">122</span>)</span><br><span class="line">        plt.scatter(pca[:, <span class="number">0</span>], pca[:, <span class="number">1</span>], c=self.labels)</span><br><span class="line">        plt.title(<span class="string">&#x27;PCA&#x27;</span>)</span><br><span class="line">        plt.colorbar()</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    iris=datasets.load_iris()</span><br><span class="line">    data=iris.data</span><br><span class="line">    target=iris.target</span><br><span class="line">    kmeans=Kmeans(data,<span class="number">3</span>)</span><br><span class="line">    centers,results,labels=kmeans.fit()</span><br><span class="line">    kmeans.imshow()</span><br><span class="line">    s = silhouette_score(data, labels)</span><br><span class="line">    <span class="built_in">print</span>(centers)</span><br><span class="line">    <span class="built_in">print</span>(results)</span><br><span class="line">    <span class="built_in">print</span>(s)</span><br></pre></td></tr></table></figure><p>KMEANS 处理照片程序 - kmeans_photo.py </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># Author : JackZhu</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Data : 2021/5/13 12:56</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> scale</span><br><span class="line"><span class="keyword">from</span> sklearn.manifold <span class="keyword">import</span> TSNE</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Kmeans</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,dat,k</span>):</span><br><span class="line">        data=scale(dat)</span><br><span class="line">        self.data=data</span><br><span class="line">        self.row, self.col = data.shape</span><br><span class="line">        self.k=k</span><br><span class="line">        self.centers=np.ndarray((k,self.col))</span><br><span class="line">        choices=random.choices(<span class="built_in">range</span>(self.row),k=k)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">            self.centers[i,:]=self.data[choices[i],:]</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,counts=<span class="number">15</span></span>):</span><br><span class="line">        count=<span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span>(count&lt;counts):</span><br><span class="line">            self.labels=np.zeros((self.row))</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.data.shape[<span class="number">0</span>]):</span><br><span class="line">                dis=[]</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.k):</span><br><span class="line">                    dis.append(np.linalg.norm(self.data[i,:]-self.centers[j,:],axis=<span class="number">0</span>))</span><br><span class="line">                lab=np.argmin(dis,axis=<span class="number">0</span>)</span><br><span class="line">                self.labels[i]=lab</span><br><span class="line">            self.result=&#123;&#125;</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.k):</span><br><span class="line">                <span class="built_in">type</span>=np.where(self.labels==i)[<span class="number">0</span>]</span><br><span class="line">                self.result[i]=<span class="built_in">type</span></span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(<span class="built_in">type</span>)==<span class="number">0</span>:</span><br><span class="line">                    self.centers[i, :] =<span class="number">0</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    self.centers[i,:]=np.mean(self.data[<span class="built_in">type</span>,:],axis=<span class="number">0</span>)</span><br><span class="line">            count+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.centers, self.result</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">imshow</span>(<span class="params">self</span>):</span><br><span class="line">        tsne = TSNE(n_components=<span class="number">2</span>, learning_rate=<span class="number">100</span>).fit_transform(self.data)</span><br><span class="line">        pca = PCA().fit_transform(self.data)</span><br><span class="line">        plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">        plt.subplot(<span class="number">121</span>)</span><br><span class="line">        plt.scatter(tsne[:, <span class="number">0</span>], tsne[:, <span class="number">1</span>], c=self.labels)</span><br><span class="line">        plt.title(<span class="string">&#x27;t-SNE&#x27;</span>)</span><br><span class="line">        plt.subplot(<span class="number">122</span>)</span><br><span class="line">        plt.scatter(pca[:, <span class="number">0</span>], pca[:, <span class="number">1</span>], c=self.labels)</span><br><span class="line">        plt.title(<span class="string">&#x27;PCA&#x27;</span>)</span><br><span class="line">        plt.colorbar()</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">plot_img</span>(<span class="params">self,row,col</span>):</span><br><span class="line">        img=self.labels.reshape(row,col)</span><br><span class="line">        im = Image.new(<span class="string">&quot;RGB&quot;</span>, (row, col))  <span class="comment"># 创建图片</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(row):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(col):</span><br><span class="line">                <span class="keyword">if</span> img[i, j] == <span class="number">0</span>:</span><br><span class="line">                    im.putpixel((i, j), (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">                <span class="keyword">if</span> img[i, j] == <span class="number">1</span>:</span><br><span class="line">                    im.putpixel((i, j), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>))</span><br><span class="line">                <span class="keyword">if</span> img[i, j] == <span class="number">2</span>:</span><br><span class="line">                    im.putpixel((i, j), (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>))</span><br><span class="line">        im.show()</span><br><span class="line">        im.save(<span class="string">&#x27;result.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">path=<span class="string">&#x27;./2.bmp&#x27;</span></span><br><span class="line"><span class="comment"># path=f&#x27;H:/Python_code/Pattern Recognition/kmeans/kmeans图片/3.bmp&#x27;</span></span><br><span class="line">file=Image.<span class="built_in">open</span>(path,<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">file=np.array(file)</span><br><span class="line">row,col,_=file.shape</span><br><span class="line">data=file.reshape(-<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">kmeans=Kmeans(data,<span class="number">3</span>)</span><br><span class="line">centers,results=kmeans.fit(<span class="number">10</span>)</span><br><span class="line">kmeans.imshow()</span><br><span class="line">kmeans.plot_img(row,col)</span><br><span class="line"><span class="built_in">print</span>(centers)</span><br><span class="line"><span class="built_in">print</span>(results)</span><br></pre></td></tr></table></figure><h2 id="B-DBSCAN-程序代码"><a href="#B-DBSCAN-程序代码" class="headerlink" title="B DBSCAN 程序代码"></a>B DBSCAN 程序代码</h2><p>DBSCAN 程序 - 密度聚类.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># Author : JackZhu</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Data : 2021/5/9 15:16</span></span><br><span class="line"><span class="comment"># 调用科学计算包与绘图包</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> scio</span><br><span class="line"><span class="keyword">import</span> matplotlib.colors <span class="keyword">as</span> mcolors</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score, calinski_harabasz_score, davies_bouldin_score</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calDist</span>(<span class="params">X1, X2</span>):</span><br><span class="line">    <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> x1, x2 <span class="keyword">in</span> <span class="built_in">zip</span>(X1, X2):</span><br><span class="line">        <span class="built_in">sum</span> += (x1 - x2) ** <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span> ** <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getNeibor</span>(<span class="params">data, dataSet, e</span>):</span><br><span class="line">    res = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(dataSet.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">if</span> calDist(data, dataSet[i]) &lt; e:</span><br><span class="line">            res.append(i)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">DBSCAN</span>(<span class="params">dataSet, e, minPts</span>):</span><br><span class="line">    coreObjs = &#123;&#125;  <span class="comment"># 初始化核心对象集合</span></span><br><span class="line">    C = &#123;&#125;</span><br><span class="line">    n = dataSet.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 找出所有核心对象，key是核心对象的index，value是ε-邻域中对象的index</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        neibor = getNeibor(dataSet[i], dataSet, e)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(neibor) &gt;= minPts:</span><br><span class="line">            coreObjs[i] = neibor</span><br><span class="line">    oldCoreObjs = coreObjs.copy()</span><br><span class="line">    k = <span class="number">0</span>  <span class="comment"># 初始化聚类簇数</span></span><br><span class="line">    notAccess = <span class="built_in">list</span>(<span class="built_in">range</span>(n))  <span class="comment"># 初始化未访问样本集合（索引）</span></span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">len</span>(coreObjs) &gt; <span class="number">0</span>:</span><br><span class="line">        OldNotAccess = []</span><br><span class="line">        OldNotAccess.extend(notAccess)</span><br><span class="line">        cores = coreObjs.keys()</span><br><span class="line">        <span class="comment"># 随机选取一个核心对象</span></span><br><span class="line">        randNum = random.randint(<span class="number">0</span>, <span class="built_in">len</span>(cores) - <span class="number">1</span>)</span><br><span class="line">        cores = <span class="built_in">list</span>(cores)</span><br><span class="line">        core = cores[randNum]</span><br><span class="line">        queue = []</span><br><span class="line">        queue.append(core)</span><br><span class="line">        notAccess.remove(core)</span><br><span class="line">        <span class="keyword">while</span> <span class="built_in">len</span>(queue) &gt; <span class="number">0</span>:</span><br><span class="line">            q = queue[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">del</span> queue[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">if</span> q <span class="keyword">in</span> oldCoreObjs.keys():</span><br><span class="line">                delte = [val <span class="keyword">for</span> val <span class="keyword">in</span> oldCoreObjs[q] <span class="keyword">if</span> val <span class="keyword">in</span> notAccess]  <span class="comment"># Δ = N(q)∩Γ</span></span><br><span class="line">                queue.extend(delte)  <span class="comment"># 将Δ中的样本加入队列Q</span></span><br><span class="line">                notAccess = [val <span class="keyword">for</span> val <span class="keyword">in</span> notAccess <span class="keyword">if</span> val <span class="keyword">not</span> <span class="keyword">in</span> delte]  <span class="comment"># Γ = Γ\Δ</span></span><br><span class="line">        k += <span class="number">1</span></span><br><span class="line">        C[k] = [val <span class="keyword">for</span> val <span class="keyword">in</span> OldNotAccess <span class="keyword">if</span> val <span class="keyword">not</span> <span class="keyword">in</span> notAccess]</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> C[k]:</span><br><span class="line">            <span class="keyword">if</span> x <span class="keyword">in</span> coreObjs.keys():</span><br><span class="line">                <span class="keyword">del</span> coreObjs[x]</span><br><span class="line">    <span class="keyword">return</span> C</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw</span>(<span class="params">C, D</span>):</span><br><span class="line">    colors = <span class="built_in">list</span>(mcolors.TABLEAU_COLORS.keys())</span><br><span class="line">    predict = np.zeros((D.shape[<span class="number">0</span>], D.shape[<span class="number">1</span>] + <span class="number">1</span>))</span><br><span class="line">    j = <span class="number">0</span></span><br><span class="line">    keys = C.keys()</span><br><span class="line">    <span class="built_in">print</span>(keys)</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> keys:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> C[k]:</span><br><span class="line">            predict[j, <span class="number">0</span>:<span class="number">2</span>] = D[i]</span><br><span class="line">            predict[j, <span class="number">2</span>] = k</span><br><span class="line">            j = j + <span class="number">1</span></span><br><span class="line">            plt.scatter(D[i, <span class="number">0</span>], D[i, <span class="number">1</span>], color=colors[k + <span class="number">1</span>])</span><br><span class="line">    plt.show()</span><br><span class="line">    <span class="keyword">return</span> predict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    path = <span class="string">&#x27;./data-密度聚类/square1.mat&#x27;</span></span><br><span class="line">    data = scio.loadmat(path)[<span class="string">&#x27;square1&#x27;</span>]</span><br><span class="line">    <span class="comment"># plt.scatter(data[:,0],data[:,1])</span></span><br><span class="line">    <span class="comment"># plt.show()</span></span><br><span class="line">    D = data[:, <span class="number">0</span>:<span class="number">2</span>]</span><br><span class="line">    label = data[<span class="number">2</span>]</span><br><span class="line">    C = DBSCAN(D, <span class="number">0.9</span>, <span class="number">15</span>)</span><br><span class="line">    predict = draw(C, D)</span><br><span class="line">    s1 = metrics.silhouette_score(predict[:, <span class="number">0</span>:<span class="number">2</span>], predict[:, <span class="number">2</span>], metric=<span class="string">&#x27;euclidean&#x27;</span>)</span><br><span class="line">    s2 = calinski_harabasz_score(predict[:, <span class="number">0</span>:<span class="number">2</span>], predict[:, <span class="number">2</span>])  <span class="comment"># 计算CH score</span></span><br><span class="line">    s3 = davies_bouldin_score(predict[:, <span class="number">0</span>:<span class="number">2</span>], predict[:, <span class="number">2</span>])  <span class="comment"># 计算 DBI</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(s1, s2, s3)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">本文使用了 K-means 和 DBSCAN 两种聚类方法, 较好的完成了聚类任务, 并将得到的结果使用了 t-SNE 和 PCA 两种方法进行降维可视化,从而更好的得到聚类的效果,并计算了轮廓系数、 \(\mathrm{CH}\) score、 DBI 这些聚类指标, 对于 K-means 方法还使用了图片进行聚类, 使得效果更加直观, 实验效果非常好。</summary>
    
    
    
    <category term="机器学习" scheme="http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习作业——高光谱遥感特征选择</title>
    <link href="http://example.com/2021/04/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%A5%E5%91%8A%E2%80%94%E2%80%94%E9%AB%98%E5%85%89%E8%B0%B1%E9%81%A5%E6%84%9F%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/"/>
    <id>http://example.com/2021/04/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%A5%E5%91%8A%E2%80%94%E2%80%94%E9%AB%98%E5%85%89%E8%B0%B1%E9%81%A5%E6%84%9F%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/</id>
    <published>2021-04-28T12:29:37.000Z</published>
    <updated>2024-04-09T15:27:47.760Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目-录"><a href="#目-录" class="headerlink" title="目 录"></a>目 录</h2><p>1 实验说明 1<br>2 数据集 1<br>3 特征选择 2<br>3.1 基本方法 2<br>3.2 单变量选择法 2<br>3.3 递归特征消除法 2<br>4 代码实现 2<br>4.1 获取数据 2<br>4.2 数据预处理 3<br>4.3 定义单变量选择函数 3<br>4.4 定义递归特征选择法函数 4<br>4.5 定义获得数据函数 4<br>4.6 定义评定函数 5<br>4.7 主函数 5<br>5 结果分析 6<br>6 优缺点分析 6<br>6.1 Filter 6<br>6.2 Wrapper 7<br>7 总结 7<br>A 作业代码 8</p><h2 id="1-实验说明"><a href="#1-实验说明" class="headerlink" title="1 实验说明"></a>1 实验说明</h2><p>本次实验的目标为利用提供的高光谱遥感数据集进行特征选择, 有以下实验要求:</p><ul><li>利用给定的数据集, 进行数据特征 (波段) 选择。</li><li>具体选择方法和策略不限制。</li><li>实验结果度量标准不少于 4 种, 结合课程学习中的指标。</li><li>建议对比不同类型的选择方法, 给出各种方法的优缺点。<br>数据集给出的数据维数较高, 其中存在了许多冗余的信息以及无关信息, 如果把这些实际的数据直接放到神经网络中则很难得出较好的结果, 而且计算量大大增加, 因此需要进行特征提取, 把影响实验效果的特征清除掉, 用较少的特征对实验结果进行分析。</li></ul><h2 id="2-数据集"><a href="#2-数据集" class="headerlink" title="2 数据集"></a>2 数据集</h2><p>在本次实验中, 提供了多种数据可以选择, 由于目标在于实现过程, 数据集选择无关,<br>此处选择了肯尼迪航天中心数据 KSC。<br>NASA AVIRIS (机载可见光&#x2F;红外成像光谱仪) 仪器于 1996 年 3 月 23 日在佛罗里达州肯尼迪航天中心 (KSC) 上空获取数据。AVIRIS 采集 224 个波段的数据, 这些波段的宽度为 10 纳米, 中心波长为 400-2500 纳米。从大约 20 公里的高度获得的 KSC 数据具有 18 米的空间分辨率。去除吸水率和低信噪比波段后, 用 176 个波段进行分析。训练数据是利用肯尼迪航天中心提供的彩色红外摄影和陆地卫星专题制图仪 (TM) 图像绘制的土地覆盖图选择的。植被分类方案是由 KSC 人员制定的, 目的是确定在陆地卫星和这些 AVIRIS 数据的空间分辨率上可辨别的功能类型。由于某些植被类型的光谱特征具有相似性, 因此很难区分这种环境下的土地覆盖。为便于分类, 为现场定义了 13 个类别, 代表该环境中出现的各种土地覆盖类型。<br>数据集预览如下图所示:</p><img src="https://cdn.noedgeai.com/34077bd4-b209-4949-97d0-44f33cab3459_2.jpg?x=251&y=680&w=342&h=294 "/><p>图 1: KSC 数据预览图</p><p>数据集尺寸为 $512 \times 614 \times 176$, 大小为 $56.8\mathrm{MB}$, 相应的结果尺寸为 $512 \times 614$, 大小为 $3.2\mathrm{KB}$。</p><h2 id="3-特征选择"><a href="#3-特征选择" class="headerlink" title="3 特征选择"></a>3 特征选择</h2><h2 id="3-1-基本方法"><a href="#3-1-基本方法" class="headerlink" title="3.1 基本方法"></a>3.1 基本方法</h2><p>一个典型机器学习问题是通过样本特征预测对应的值, 如果样本特征少, 可以增加特征, 而有时候特征较多, 则需要较少一些特征, 较少过拟合, 提高模型泛化能力, 加快模型训练速度并获得更好的性能,<br>特征选择主要有三种选择方法:</p><ol><li>过滤法 (Filter) : 按照发散性或者相关性对各个特征进行评分, 设定阈值或者待选择阈值的个数, 选择特征。</li><li>包裹法 (Wrapper): 根据目标函数, 每次选择若干特征或者排除若干特征, 直到选择出最佳的子集。</li><li>嵌入法 (Embedding): 先使用某些机器学习的算法和模型进行训练, 得到各个特征的权值系数, 根据系数从大到小选择特征。类似于 Filter 方法, 但是是通过训练来确定特征的优劣。</li></ol><h2 id="3-2-单变量选择法"><a href="#3-2-单变量选择法" class="headerlink" title="3.2 单变量选择法"></a>3.2 单变量选择法</h2><p>单变量特征选择是通过选择那些基于单变量统计检验 (univariate statistical tests) 得出的最优特征来实现的, 这是 Filter 法的一种。它可以看作是估计器的一个预处理步骤。这里使用了 Sklearn 中的 Select KBest 对每个特征进行评分, 并选择出指定数目的特征, 从而达到选择的效果, 这种方法并未考虑到不同特征之间的相互关系, 本题中选择了 50 个特征。</p><h2 id="3-3-递归特征消除法"><a href="#3-3-递归特征消除法" class="headerlink" title="3.3 递归特征消除法"></a>3.3 递归特征消除法</h2><p>递归特征消除 (Recursive feature elimination) 是 Wrapper 法中的一种, 其主要思想是反复构建模型, 然后选出最好的 (或者最差的) 特征 (根据系数来选), 把选出来的特征放到一边, 然后在剩余的特征上重复这个过程, 直到遍历了所有的特征。在这个过程中被消除的次序就是特征的排序, 本题中选择了 30 个特征的组合。<br>RFE 的稳定性很大程度上取决于迭代时, 底层用的哪种模型。比如 RFE 采用的是普通的回归 (LR), 没有经过正则化的回归是不稳定的, 那么 RFE 就是不稳定的。假如采用的是 Lasso&#x2F;Ridge, 正则化的回归是稳定的, 那么 RFE 就是稳定的。</p><h2 id="4-代码实现"><a href="#4-代码实现" class="headerlink" title="4 代码实现"></a>4 代码实现</h2><h2 id="4-1-获取数据"><a href="#4-1-获取数据" class="headerlink" title="4.1 获取数据"></a>4.1 获取数据</h2><p>此处建立函数读取获取数据并将数据从三维降到二维, 将对应的标签从二维降到一维,<br>降维后数据的尺寸为 (314368 {\times} 176) 。<br>其中一个重要的问题是提供的大部分数据是无用的, 即数据对应的标签为 0 , 因此这里<br>仅提取出标签不为零的数据,提取后数据尺寸为 (5211 {\times} 176) ,相关代码如下:</p><hr><p>def get_data():<br>dat &#x3D; loadmat(‘.&#x2F;高光谱数据集&#x2F;KSC.mat’) [‘KSC’]</p><hr><hr><p>(1\mathrm{ab} &#x3D; 1) oadmat(’.&#x2F;高光谱数据集&#x2F;KSC_gt.mat’) [‘KSC_gt’]<br>dat ( &#x3D; ) dat.reshape (({-}1,176))<br>lab ( &#x3D; ) lab.reshape (({-}1))<br>print(dat.shape)<br>data, label &#x3D; [], []<br>for i in range(dat.shape[0]):<br>if lab[i].all() !&#x3D; 0:<br>data.append(dat[i, :])<br>label.append(lab[i])<br>data ( &#x3D; ) np.array (data)<br>label ( &#x3D; ) np.array(label)<br>return data, label</p><hr><h2 id="4-2-数据预处理"><a href="#4-2-数据预处理" class="headerlink" title="4.2 数据预处理"></a>4.2 数据预处理</h2><p>这里首先利用 sklearn 中的 processing 对数据进行标准化处理, 然后消除方差为 0 的<br>特征, 并利用中位数进行变量的选择。 def process(data):<br>data ( &#x3D; ) preprocessing. StandardScaler (). fit_transform(data) print(‘shape&#x3D;{}’.format(data.shape))<br>selector ( &#x3D; \operatorname{VarianceThreshold}()#) 实例化,不填参数默认方差为 0 data ( &#x3D; ) selector.fit_transform(data) print(data.shape)<br>median_num &#x3D; np.median(data)<br>data ( &#x3D; ) VarianceThreshold (median_num).fit_transform(data) print(data.shape) return data</p><h2 id="4-3-定义单变量选择函数"><a href="#4-3-定义单变量选择函数" class="headerlink" title="4.3 定义单变量选择函数"></a>4.3 定义单变量选择函数</h2><p>此处定义了单变量选择函数, 利用 SelectKBest 进行评分, 得到不同特征的得分以及<br>pvalue, 并得出是否选择, 并得到选出的 50 个特征的索引。</p><hr><p>def select_k(data, label, k):<br>results ( &#x3D; ) SelectKBest (f_classif,k&#x3D;k).fit(data,label)<br>print(results)<br>features ( &#x3D; ) pd.DataFrame({<br>“score”: results.scores_<br>“pvalue”: results.pvalues_,<br>“select”: results.get_support()</p><hr><hr><p>\})<br>features.sort_values(“score”, ascending&#x3D;False)<br>print(features)<br>index ( &#x3D; ) results.get_support(indices&#x3D;True)<br>print(index)<br>return index</p><hr><p>此处简要列出几种特征得分、pvalue 以及选择情况如下图所示。</p><table><thead><th>Index</th><th>score</th><th>pvalue</th><th>select</th></thead><tr><td>128</td><td>2727.83</td><td>0</td><td>True</td></tr><tr><td>129</td><td>2721.86</td><td>0</td><td>True</td></tr><tr><td>130</td><td>2713.15</td><td>0</td><td>True</td></tr><tr><td>131</td><td>3.10662</td><td>0.000214373</td><td>False</td></tr><tr><td>132</td><td>8.8046</td><td>6.66051e-17</td><td>False</td></tr><tr><td>133</td><td>1.56247</td><td>0.0951564</td><td>False</td></tr><tr><td>134</td><td>2085.42</td><td>0</td><td>False</td></tr><tr><td>135</td><td>2101.52</td><td>0</td><td>False</td></tr><tr><td>136</td><td>2107.9</td><td>0</td><td>False</td></tr><tr><td>137</td><td>2116.73</td><td>0</td><td>False</td></tr><tr><td>138</td><td>1.36264</td><td>0.17608</td><td>False</td></tr><tr><td>139</td><td>2165.66</td><td>日</td><td>True</td></tr><tr><td>140</td><td>2219.98</td><td>®</td><td>True</td></tr><tr><td>141</td><td>1.06688</td><td>0.383812</td><td>False</td></tr></table><p>图 2: 特征得分预览图</p><p> 4.4 定义递归特征选择法函数<br>此处同样获取索引, 在本题中, 选择了 30 个特征的组合进行特征选择, 代码如下。<br>def rfe(data, label, n):<br>results ( &#x3D; ) RFE(estimator&#x3D;LogisticRegression(),n_features_to_select&#x3D;n) print(results)<br>results.fit(data, label)<br>index &#x3D; results.get_support(indices&#x3D;True) print(index) return index</p><h2 id="4-5-定义获得数据函数"><a href="#4-5-定义获得数据函数" class="headerlink" title="4.5 定义获得数据函数"></a>4.5 定义获得数据函数</h2><h2 id="此函数目的为获取指定索引特征的数据并划分训练测试集-即将上文中选出的指定特征索引数据选出来。"><a href="#此函数目的为获取指定索引特征的数据并划分训练测试集-即将上文中选出的指定特征索引数据选出来。" class="headerlink" title="此函数目的为获取指定索引特征的数据并划分训练测试集, 即将上文中选出的指定特征索引数据选出来。"></a>此函数目的为获取指定索引特征的数据并划分训练测试集, 即将上文中选出的指定特征索引数据选出来。</h2><p>def select_index_data(index, data, label):<br>data_after ( &#x3D; )<br>for i in index:<br>data_after.append(data[:, i])<br>data_after ( &#x3D; ) np.array (data_after).transpose()<br>print(data_after.shape)<br>print(label.shape)<br>return train_test_split(data_after,label,test_size&#x3D;0.3,<br>random_state&#x3D;1)</p><hr><h2 id="4-6-定义评定函数"><a href="#4-6-定义评定函数" class="headerlink" title="4.6 定义评定函数"></a>4.6 定义评定函数</h2><p>此处利用 SVM 来测定特征选择的效果, 并利用 sklearn 中的库函数来进行评定, 相关<br>代码如下。</p><p>def measure_feature(train_data, test_data, train_label, test_label, gamma,<br>c):<br>clf &#x3D; sklearn.svm. SVC (kernel&#x3D;’poly’, gamma&#x3D;gamma, C&#x3D;c) clf.fit(train_data, train_label) predict ( &#x3D; ) clf.predict(test_data) clf.get_params(deep&#x3D;True)<br>acc ( &#x3D; ) sklearn.metrics.accuracy_score(test_label,predict)<br>(f1 &#x3D; ) sklearn.metrics.f1_score(test_label,predict,average&#x3D;’micro’) recall ( &#x3D; ) metrics.recall_score(test_label,predict,average&#x3D;’micro’) precision ( &#x3D; ) metrics.precision_score(test_label,predict,<br>average&#x3D;’micro’)<br>return acc, f1, recall, precision</p><h2 id="4-7-主函数"><a href="#4-7-主函数" class="headerlink" title="4.7 主函数"></a>4.7 主函数</h2><p>这部分使用了上文中定义的函数, 首先读取数据, 然后进行数据预处理, 之后分别利用这两种方法, 并提取出特征对应的索引, 之后划分出训练集和测试集来对特征提取的结果进行测试, 最后分别展示出分别用分类准确率, f1 分数, 召回率, 精确度等指标来测试训练集和测试集的效果, 代码如下。</p><hr><p>if _<em>name</em> &#x3D;&#x3D; ‘<strong>main</strong>‘:<br>data, label &#x3D; get_data()<br>data ( &#x3D; ) process(data)<br># rfc(data,label)<br>index ( &#x3D; ) select_k(data,label,k&#x3D;50)<br># index &#x3D; rfe(data, label,n&#x3D;30)<br>train_data, test_data, train_label, test_label &#x3D;<br>select_index_data(index, data, label)</p><hr><hr><p>print(train_data.shape, test_data.shape, train_label.shape,<br>test_label.shape)<br>gamma, (c &#x3D; 0.125,60)<br>train_acc,train_f1,train_recall,train_precision ( &#x3D; )<br>measure_feature(train_data, train_data, train_label, train_label,<br>gamma, c)<br>test_acc, test_f1, test_recall, test_precision &#x3D;<br>measure_feature(train_data, test_data, train_label,<br>test_label, gamma, c)<br>print(train_acc, test_acc)<br>print(train_f1, test_f1)<br>print(train_recall, test_recall)<br>print(train_precision, test_precision)</p><hr><h2 id="5-结果分析"><a href="#5-结果分析" class="headerlink" title="5 结果分析"></a>5 结果分析</h2><p>表 1: 训练测试结果</p><table><thead><th></th><th>accuracy</th><th>f1 score</th><th>recall</th><th>precision</th></thead><tr><td>UFS 训练集</td><td>0.943</td><td>0.943</td><td>0.943</td><td>0.943</td></tr><tr><td>UFS 测试集</td><td>0.902</td><td>0.902</td><td>0.902</td><td>0.902</td></tr><tr><td>RFE 训练集</td><td>0.994</td><td>0.994</td><td>0.994</td><td>0.994</td></tr><tr><td>RFE 测试集</td><td>0.948</td><td>0.948</td><td>0.948</td><td>0.948</td></tr></table><p>由上表可知, RFE 在选择的特征数少于 UFS 的情况下, 效果仍好于 UFS。在本数据集下, 四种指标结果相同。对于 UFS 法, 优点是直观, 可解释性更好, 但是最优的组合效果并不一定是最好的。对于 RFE 法, 计算量更大, 需要考虑不同组合的效果。递归式特征消除的主要思路是反复建立多种模型, 每一次根据系数的不挑出差的特征, 并去除挑出来的特征, 然后在剩余的特征上重复该过程, 直到遍历了所有的特征。</p><h2 id="6-优缺点分析"><a href="#6-优缺点分析" class="headerlink" title="6 优缺点分析"></a>6 优缺点分析</h2><h2 id="6-1-Filter"><a href="#6-1-Filter" class="headerlink" title="6.1 Filter"></a>6.1 Filter</h2><p>过滤式特征选择的评价标准从数据集本身的内在性质获得, 与特定的学习算法无关, 因此具有具有较好的通用性。通常选择和类别相关度大的特征或者特征子集。过滤式特征选择的研究者认为, 相关度较大的特征或者特征自己会在分类器上获得较高的准确率, dash 和 liu 把过滤式特征选择的评价标准分为四种, 即距离度量, 信息度量, 关联度量以及一致性度量<br>优点: 算法的通用性强, 省去了分类器的训练步骤, 算法复杂性低, 因而适用于大规模<br>数据集, 可以快速去除大量不相关的特征, 作为特征的预筛选器非常合适的<br>缺点: 由于算法的评价标准独立于特定的学习算法, 所选的特征子集在分类准确率方<br>面通常低于 wrapper 方法。</p><h2 id="6-2-Wrapper"><a href="#6-2-Wrapper" class="headerlink" title="6.2 Wrapper"></a>6.2 Wrapper</h2><p>封装式特征选择即 wrapper 方法利用学习算法的性能来评价特征自己的优劣, 因此, 对<br>于一个待评价的特征子集, wrapper 方法需要<br>训练一个分类器, 根据分类器的性能对该特征子集进行评价, wrapper 方法中用以评价特征的学习算法是多种多样的, 例如决策树、神经网路、贝叶斯分类器、近邻法以及支持向量机等等, 本文就使用的支持向量机来进行评价。<br>优点: 相对于 filter 方法, wrapper 方法找到的特征子集分类性能通常更好<br>缺点: wrapper 方法选出的特征通用性不强, 当改变学习算法时, 需要针对该学习算法重新进行特征选择, 由于每次对子集的评价都要进行分类器的训练和测试, 所以算法计算复杂度很高, 尤其对于大规模数据集来说, 算法的执行时间越长。</p><h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7 总结"></a>7 总结</h2><p>在这次实验中, 开始在理解题意方面遇到了很多问题, 后来经过多方询问才明白特征提取的几种方法如何实现。这次实验中我通过广泛查询资料了解到了相关的知识, 也认真写代码来完成任务, 这份作业的完成确实比较艰巨, 一份顶多份, 但是我还是有很大的收获, 能力也得到了提升。</p><h2 id="A-作业代码"><a href="#A-作业代码" class="headerlink" title="A 作业代码"></a>A 作业代码</h2><p>程序 - 高光谱.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.io <span class="keyword">import</span> loadmat</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier <span class="keyword">as</span> RFC</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest, f_classif</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_data</span>():</span><br><span class="line">    dat = loadmat(<span class="string">&#x27;./高光谱数据集/KSC.mat&#x27;</span>)[<span class="string">&#x27;KSC&#x27;</span>]</span><br><span class="line">    lab = loadmat(<span class="string">&#x27;./高光谱数据集/KSC_gt.mat&#x27;</span>)[<span class="string">&#x27;KSC_gt&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    dat = dat.reshape(-<span class="number">1</span>, <span class="number">176</span>)</span><br><span class="line">    lab = lab.reshape(-<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(dat.shape)</span><br><span class="line"></span><br><span class="line">    data, label = [], []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(dat.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">if</span> lab[i].<span class="built_in">all</span>() != <span class="number">0</span>:</span><br><span class="line">            data.append(dat[i, :])</span><br><span class="line">            label.append(lab[i])</span><br><span class="line"></span><br><span class="line">    data = np.array(data)</span><br><span class="line">    label = np.array(label)</span><br><span class="line">    <span class="keyword">return</span> data, label</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process</span>(<span class="params">data</span>):</span><br><span class="line">    data = preprocessing.StandardScaler().fit_transform(data)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;shape=&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(data.shape))</span><br><span class="line">    selector = VarianceThreshold()  <span class="comment"># 实例化，不填参数默认方差为0</span></span><br><span class="line">    data = selector.fit_transform(data)</span><br><span class="line">    <span class="built_in">print</span>(data.shape)</span><br><span class="line">    median_num = np.median(data)</span><br><span class="line">    data = VarianceThreshold(median_num).fit_transform(data)</span><br><span class="line">    <span class="built_in">print</span>(data.shape)</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># acc = cross_val_score(KNN(), data, label, cv=5).mean()</span></span><br><span class="line"><span class="comment"># print(&quot;accuracy:&#123;&#125;,time:&#123;&#125;&quot;.format(acc,time.time()-start))</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">select_k</span>(<span class="params">data, label, k</span>):</span><br><span class="line">    results = SelectKBest(f_classif, k=k).fit(data, label)</span><br><span class="line">    <span class="built_in">print</span>(results)</span><br><span class="line">    features = pd.DataFrame(&#123;</span><br><span class="line">        <span class="string">&quot;score&quot;</span>: results.scores_,</span><br><span class="line">        <span class="string">&quot;pvalue&quot;</span>: results.pvalues_,</span><br><span class="line">        <span class="string">&quot;select&quot;</span>: results.get_support()</span><br><span class="line">    &#125;)</span><br><span class="line">    features.sort_values(<span class="string">&quot;score&quot;</span>, ascending=<span class="literal">False</span>)</span><br><span class="line">    <span class="built_in">print</span>(features)</span><br><span class="line">    index = results.get_support(indices=<span class="literal">True</span>)</span><br><span class="line">    <span class="built_in">print</span>(index)</span><br><span class="line">    <span class="keyword">return</span> index</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rfe</span>(<span class="params">data, label, n</span>):</span><br><span class="line">    results = RFE(estimator=LogisticRegression(), n_features_to_select=n)</span><br><span class="line">    <span class="built_in">print</span>(results)</span><br><span class="line">    results.fit(data, label)</span><br><span class="line">    index = results.get_support(indices=<span class="literal">True</span>)</span><br><span class="line">    <span class="built_in">print</span>(index)</span><br><span class="line">    <span class="keyword">return</span> index</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rfc</span>(<span class="params">data, label</span>):</span><br><span class="line">    RFC_ = RFC(n_estimators=<span class="number">50</span>, random_state=<span class="number">0</span>)</span><br><span class="line">    X_embedded = SelectFromModel(RFC_, threshold=<span class="number">0.005</span>).fit_transform(data, label)</span><br><span class="line">    result = sklearn.model_selection.cross_val_score(RFC_, X_embedded, label, cv=<span class="number">5</span>).mean()</span><br><span class="line">    <span class="built_in">print</span>(result)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">select_index_data</span>(<span class="params">index, data, label</span>):</span><br><span class="line">    data_after = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> index:</span><br><span class="line">        data_after.append(data[:, i])</span><br><span class="line">    data_after = np.array(data_after).transpose()</span><br><span class="line">    <span class="built_in">print</span>(data_after.shape)</span><br><span class="line">    <span class="built_in">print</span>(label.shape)</span><br><span class="line">    <span class="keyword">return</span> train_test_split(data_after, label, test_size=<span class="number">0.3</span>, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">measure_feature</span>(<span class="params">train_data, test_data, train_label, test_label, gamma, c</span>):</span><br><span class="line">    clf = sklearn.svm.SVC(kernel=<span class="string">&#x27;poly&#x27;</span>, gamma=gamma, C=c)</span><br><span class="line">    clf.fit(train_data, train_label)</span><br><span class="line">    predict = clf.predict(test_data)</span><br><span class="line">    clf.get_params(deep=<span class="literal">True</span>)</span><br><span class="line">    acc = sklearn.metrics.accuracy_score(test_label, predict)</span><br><span class="line">    f1 = sklearn.metrics.f1_score(test_label, predict, average=<span class="string">&#x27;micro&#x27;</span>)</span><br><span class="line">    recall = metrics.recall_score(test_label, predict, average=<span class="string">&#x27;micro&#x27;</span>)</span><br><span class="line">    precision = metrics.precision_score(test_label, predict, average=<span class="string">&#x27;micro&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> acc, f1, recall, precision</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    data, label = get_data()</span><br><span class="line">    data = process(data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># rfc(data,label)</span></span><br><span class="line">    index = select_k(data, label, k=<span class="number">50</span>)</span><br><span class="line">    <span class="comment"># index = rfe(data, label,n=30)</span></span><br><span class="line">    train_data, test_data, train_label, test_label = select_index_data(index, data, label)</span><br><span class="line">    <span class="built_in">print</span>(train_data.shape, test_data.shape, train_label.shape, test_label.shape)</span><br><span class="line">    gamma, c = <span class="number">0.125</span>, <span class="number">60</span></span><br><span class="line">    train_acc, train_f1, train_recall, train_precision = measure_feature(train_data, train_data, train_label,</span><br><span class="line">                                                                         train_label, gamma, c)</span><br><span class="line">    test_acc, test_f1, test_recall, test_precision = measure_feature(train_data, test_data, train_label, test_label,</span><br><span class="line">                                                                     gamma, c)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(train_acc, test_acc)</span><br><span class="line">    <span class="built_in">print</span>(train_f1, test_f1)</span><br><span class="line">    <span class="built_in">print</span>(train_recall, test_recall)</span><br><span class="line">    <span class="built_in">print</span>(train_precision, test_precision)</span><br><span class="line">    <span class="comment"># print(&#x27;训练集准确率为&#123;:.4f&#125;，测试集准确率为&#123;:.4f&#125;&#x27;.format(train_acc, test_acc))</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;目-录&quot;&gt;&lt;a href=&quot;#目-录&quot; class=&quot;headerlink&quot; title=&quot;目 录&quot;&gt;&lt;/a&gt;目 录&lt;/h2&gt;&lt;p&gt;1 实验说明 1&lt;br&gt;2 数据集 1&lt;br&gt;3 特征选择 2&lt;br&gt;3.1 基本方法 2&lt;br&gt;3.2 单变量选择法 2&lt;br&gt;3</summary>
      
    
    
    
    <category term="机器学习" scheme="http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>计算智能导论作业——遗传算法的实现</title>
    <link href="http://example.com/2021/04/16/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/"/>
    <id>http://example.com/2021/04/16/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/</id>
    <published>2021-04-16T12:29:37.000Z</published>
    <updated>2024-04-09T15:27:47.760Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目-录"><a href="#目-录" class="headerlink" title="目 录"></a>目 录</h2><p>1 背景知识 1<br>1.1 最优化问题 1<br>1.2 进化算法 1<br>1.3 遗传算法的基本知识 1<br>1.3.1 生物背景 2<br>1.3.2 基本思想 2<br>1.4 遗传算法的组成部分 2<br>1.4.1 编码机制 3<br>1.4.2 种群初始化 3<br>1.4.3 适应度函数 3<br>1.4.4 遗传算子 3<br>2 算法步骤 4<br>3 实验过程 4<br>3.1 代码实现 4<br>4 结果分析 5<br>5 总结 5<br>A 程序代码 7</p><h2 id="1-背景知识"><a href="#1-背景知识" class="headerlink" title="1 背景知识"></a>1 背景知识</h2><h2 id="1-1-最优化问题"><a href="#1-1-最优化问题" class="headerlink" title="1.1 最优化问题"></a>1.1 最优化问题</h2><p>工程设计中最优化问题 (optimization problem) 的一般提法是要选择一组参数 (变量),<br>在满足一系列有关的限制条件 (约束) 下, 使设计指标 (目标) 达到最优值。<br>最优化问题一般包括两方面问题: 线性问题和非线性问题。一方面是线性问题的求解, 主要在经济活动及工程技术中出现。这类问题一般采用单纯形法来求解。另一方面是非线性问题的求解, 这类问题在工程中经常碰到, 是最为常见的一类问题, 尤其是在物理学和决策中, 许多问题常常可以归结为非线性规划问题。这类问题一般需要先建立一个数学模型, 再进行求解。<br>最优化问题的求解实质就是将物理问题数学化, 把最优化问题的求解转化为目标函数<br>最优解的求解, 利用遗传算法在求解最优解方面的特点, 达到事半功倍的效果。</p><h2 id="1-2-进化算法"><a href="#1-2-进化算法" class="headerlink" title="1.2 进化算法"></a>1.2 进化算法</h2><p>进化算法, 或 “演化算法” (evolutionary algorithms) 是一个 “算法簇”, 是在达尔文 (Darwin) 的进化论和孟德尔 (Mendel) 的遗传变异理论的基础上产生的一种在基因和种群层次上模拟自然界生物进化过程与机制, 进行问题求解的自组织、自适应的随机搜索技术。它以达尔文进化论的 “物竞天择、适者生存” 作为算法的进化规则, 并结合孟德尔的遗传变异理论, 将生物进化过程中的繁殖 (Reproduction), 变异 (Mutation), 竞争 (Competition)、选择 (Selection) 引入到了算法中, 是一种对人类智能的演化模拟, 主要有遗传算法、演化策略、演化规划和遗传规划四大分支。<br>尽管它有很多的变化, 有不同的遗传基因表达方式, 不同的交叉和变异算子, 特殊算子的引用, 以及不同的再生和选择方法, 但它们产生的灵感都来自于大自然的生物进化。<br>与传统的基于微积分的方法和穷举法等优化算法相比, 进化计算是一种成熟的具有高鲁棒性和广泛适用性的全局优化方法, 具有自组织、自适应、自学习的特性, 能够不受问题性质的限制, 有效地处理传统优化算法难以解决的复杂问题。</p><h2 id="1-3-遗传算法的基本知识"><a href="#1-3-遗传算法的基本知识" class="headerlink" title="1.3 遗传算法的基本知识"></a>1.3 遗传算法的基本知识</h2><p>遗传算法 (Genetic Algorithm, GA) 是进化算法的一个分支, 是一种模拟自然界生物进化过程的随机搜索算法。其将 “优胜劣汰, 适者生存” 的生物进化原理引入优化参数形成的编码串联群体中, 按所选择的适应度函数并通过遗传中的复制、交叉及变异对个体进行筛选, 使适应度高的个体被保留下来, 组成新的群体。<br>新的群体既继承了上一代的信息, 又优于上一代, 这样周而复始, 群体中个体适应度不断提高, 直到满足一定的条件。同时, 遗传算法的原理简单, 可并行处理, 并能得到全局最优解。<br>遗传算法是模拟达尔文生物进化论的自然选择和遗传学机理的生物进化过程的计算模型, 是一种通过模拟自然进化过程搜索最优解的方法。该算法通过数学的方式, 利用计算机仿真运算, 将问题的求解过程转换成类似生物进化中的染色体基因的交叉、变异等过程。在求解较为复杂的组合优化问题时, 相对一些常规的优化算法, 通常能够较快地获得较好的优化结果。遗传算法已被人们广泛地应用于组合优化、机器学习、信号处理、自适应控制和人工生命等领域。<br>遗传算法直接以目标函数值作为搜索信息。传统的优化算法往往不只需要目标函数值,<br>还需要目标函数的导数等其它信息。这样对许多目标函数无法求导或很难求导的函数, 遗传算法就比较方便。<br>同常规算法相比, 遗传算法有以下特点:<br>遗传算法是对决策变量的编码进行操作, 这样提供的参数信息量大, 优化效果好。遗传算法是从许多点开始并行操作, 因而可以有效地防止搜索过程收玫于局部最优解。遗传算法通过目标函数来计算适配值, 而不需要其他推导和附加信息, 从而对问题的依赖性小。遗传算法的寻优规则是由概率决定的, 而非确定性的。遗传算法在解空间进行高效启发式搜索, 而非盲目地穷举或完全随机搜索。遗传算法对于待寻优的函数基本无限制, 因而应用范围较广。遗传算法具有并行计算的特点, 因而可通过大规模并行计算来提高计算速度。遗传算法更适合大规模复杂问题的优化。遗传算法计算简单, 功能强。</p><h2 id="1-3-1-生物背景"><a href="#1-3-1-生物背景" class="headerlink" title="1.3.1 生物背景"></a>1.3.1 生物背景</h2><ul><li>基因: 一个遗传因子。</li><li>染色体: 包含一组的基因。</li><li>个体: 组成种群的单个生物。</li><li>种群: 生物的进化以群体的形式进行, 这样的一个群体称为种群。</li><li>生存竞争, 适者生存: 对环境适应度高的个体参与繁殖的机会比较多, 后代就会越来越多: 适应度低的个体参与繁殖的机会比较少, 后代就会越来越少。</li></ul><h2 id="1-3-2-基本思想"><a href="#1-3-2-基本思想" class="headerlink" title="1.3.2 基本思想"></a>1.3.2 基本思想</h2><ul><li>遗传算法把问题的解表示成 “染色体”, 在算法中即是以一定方式编码的串。</li><li>在执行遗传算法之前, 给出一群 “染色体”, 也即一组候选解 (种群)。</li><li>把这些假设解置于问题的 “环境” 中, 并按适者生存的原则, 从中选择出较适应环境的 “染色体” 进行复制, 再通过交叉, 变异过程产生更适应环境的新一代 “染色体”群。<br>这样, 一代一代地进化, 最后就会收玫到最适应环境的一个 “染色体” 上, 它就是求解<br>到的最优解。</li></ul><h2 id="1-4-遗传算法的组成部分"><a href="#1-4-遗传算法的组成部分" class="headerlink" title="1.4 遗传算法的组成部分"></a>1.4 遗传算法的组成部分</h2><p>一般的遗传算法由四个部分组成: 1. 编码机制 2. 种群初始化 3. 适应度函数<br>4. 遗传算子 (选择、交叉、变异)</p><h2 id="1-4-1-编码机制"><a href="#1-4-1-编码机制" class="headerlink" title="1.4.1 编码机制"></a>1.4.1 编码机制</h2><p>用遗传算法解决问题时, 首先要对待解决问题的模型结构和参数进行编码, 一般用字符串表示。GA 中的编码方法: 二进制编码、浮点数编码方法、格雷码编码、符号编码等。<br>二进制编码所构成的个体的基因型是一个由 0 或 1 组成的编码串,其符号串的长度 $L$ 与问题所要求的求解精度有关。设某一变量的取值范围是 $\left[ X_{\min}, X_{\max} \right]$, $X_{\min} &lt; X_{\max}$ 则二进制编码的编码精度为:</p><p>$$<br>\delta &#x3D; \frac{X_{\max} - X_{\min}}{2^{L} - 1}<br>$$</p><p>如果某一个体的编码是: $b_{L}b_{L - 1}b_{L - 2} \cdots b_{2}b_{1}$, 则对应的解码公式为:</p><p>$$<br>X &#x3D; X_{\min} + \frac{X_{\max} - X_{\min}}{2^{L} - 1} \left( \sum_{i &#x3D; 1}^L b_{i} 2^{i - 1} \right)<br>$$</p><h2 id="1-4-2-种群初始化"><a href="#1-4-2-种群初始化" class="headerlink" title="1.4.2 种群初始化"></a>1.4.2 种群初始化</h2><p>对种群个体的编码进行随机初始化。首先, 我们需要建立种群个体与遗传算法中有效解的对应概念。其次针对于每个个体,在固定长度的染色体下,对每个基因位进行随机 (0&#x2F;1) 赋值, 也就是对有效解进行初始化的过程。</p><h2 id="1-4-3-适应度函数"><a href="#1-4-3-适应度函数" class="headerlink" title="1.4.3 适应度函数"></a>1.4.3 适应度函数</h2><p>遗传算法以个体适应度的大小来评定各个个体的优劣程度, 从而决定其遗传机会的大小。一般情况下, 可以将目标函数作为适应度函数, 也就是求解问题的优化目标。将种群中的个体的染色体进行解码, 可以得到对应的十进制值, 代入适应度函数即可求得适应值。</p><h2 id="1-4-4-遗传算子"><a href="#1-4-4-遗传算子" class="headerlink" title="1.4.4 遗传算子"></a>1.4.4 遗传算子</h2><p>(1)选择操作<br>选择是对当前种群内的所有个体进行筛选, 流出进入到后续繁殖环节的父代个体的过程, 常采用轮盘赌选择。轮盘赌选择依据个体的适应度值计算每个个体在下一代中出现的概率, 并按照此概率随机选择个体构成子代种群。选择某个体的概率为</p><p>$$<br>p(I_{i}) &#x3D; \frac{f(I_{i})}{\sum_{i &#x3D; 1}^N f(I_{i})}<br>$$</p><p>其中, $f(I_{i})$ 是个体 $I_{i}$ 的适应度值, $N$ 是种群大小。轮盘赌选择的流程如下:</p><ul><li>计算种群中所有个体的适应度值之和, $F &#x3D; \sum_{k &#x3D; 1}^N \text{eval}(v_{k})$ ;</li><li>计算每个个体 $v_{k}$ 的选择概率 $p_{k}$, $p_{k} &#x3D; \frac{\text{eval}(v_{k})}{F}$, $k &#x3D; 1, 2, \ldots, \text{popSize}$ ;</li><li>计算每个个体 $v_{k}$ 的累积概率 $q_{k}$, $q_{k} &#x3D; \sum_{j &#x3D; 1}^k p_{j}$, $k &#x3D; 1, 2, \ldots, \text{popSize}$ ;</li><li>随机产生 $N$ 个 $[0,1]$ 的随机数 $r_{i}$ ;</li><li>对于每一个 $r_{i}$ : 如果 $r_{i} \leq q_{1}$, 选择第一个个体 $v_{1}$; 否则, 如果 $q_{k - 1} &lt; r_{i} &lt; q_{k}$, 选择第 $k$ 个个体 $v_{k}(2 \leq k \leq \text{popSize})$ 。</li></ul><h2 id="2-交叉操作"><a href="#2-交叉操作" class="headerlink" title="(2)交叉操作"></a>(2)交叉操作</h2><p>交叉操作是选中的两个父代个体交换莱些基因位形成子代个体的过程。交叉概率 (P_{c}) 是在种群中个体被选择出进行交叉的概率, 一般的交叉方式有单点交叉、两点交叉、多点交叉、均匀交叉等。其中, 单点交叉是随机产生一个有效的交叉位置, 染色体交换位于该交叉位置后的所有基因。<br>(3)变异操作<br>变异操作是编码按小概率扰动产生的变化,类似于基因的突变。变异概率 (P_{m}) 是控制算法中变异操作的使用频率。常用的变异方式有单点变异、均匀变异、高斯变异等。其中, 单点变异指的是对于某一基因位,产生的随机数小于 (P_{m}) 则改变该基因的取值,否则该基因不发生变异, 保持不变。</p><h2 id="2-算法步骤"><a href="#2-算法步骤" class="headerlink" title="2 算法步骤"></a>2 算法步骤</h2><p>该算法可分为以下 7 步。<br>Step1: 初始化种群;<br>Step2: 计算种群中每个个体的适应度值;<br>Step3: 按由个体适应度值决定的某个规则选择将进入下一代的个体; Step4: 按概率 (P_{c}) 进行交叉操作; Step5: 按概率 (P_{m}) 进行变异操作;<br>Step6: 若没有满足某种终止条件, 则转第 2 步, 否则进入下一步; Step7: 输出种群中适应度值最优的染色体作为问题的满意解或最优解。</p><h2 id="3-实验过程"><a href="#3-实验过程" class="headerlink" title="3 实验过程"></a>3 实验过程</h2><p>本文中采用的函数为 (f(x) &#x3D; {\sum}<em>{i &#x3D; 1}^n\left\lbrack x</em>{i}^{2} {-} 10\cos\left( 2\pi x_{i} + 10 \right) \right\rbrack) ,自变量的定义域为 (\lbrack{-}5.12,5.12\rbrack) , 函数的最小值为 0 。</p><h2 id="3-1-代码实现"><a href="#3-1-代码实现" class="headerlink" title="3.1 代码实现"></a>3.1 代码实现</h2><p>作为遗传算法中较为重要的交叉模块, 我们进行了如下设计。首先, 遍历种群中的每一个个体, 将该个体作为父代, 而子代首先得到父代的全部基因, 父代产生子代时不是必然发生交叉, 而是以一定的概率发生交叉。从种群中选择令一个个体, 将该个体作为另一个附带, 随机产生交叉点后, 子代得到此父代交叉点后的全部基因。同时, 此子代也具有相应的变异概率。<br>这里首先确定了相关参数, 然后定义主要的几个函数, 包括三维作图函数、解码函数、适应度计算函数、交叉变异函数, 然后进行操作整合, 并将函数整合起来, 代码见附录。<br>在本代码中, 不仅对遗传算法中不同个体的适应度情况实时展示, 而且对迭代过程中<br>最小的值进行记录, 画出折线图, 从而使得展示过程更加直观。<br><img src="https://cdn.noedgeai.com/e291bc60-ee22-4de1-aca0-eb54cd5a99af_6.jpg?x=242&y=62&w=409&h=397 "/></p><p>图 1: 函数图</p><h2 id="4-结果分析"><a href="#4-结果分析" class="headerlink" title="4 结果分析"></a>4 结果分析</h2><p>上图为运算过程中的函数以及整个种群的情况:<br>当迭代完成后, 可以看到仅函数中心处有一点, 说明整个种群都收玫到了一处, 如下图<br>所示。<br>下图为迭代过程的最小适应度函数值的变化折线图。<br>由图中可以看出, 所求适应度函数最小的值在不断下降, 最终达到稳定值, 而且最终所<br>处数值接近 5 , 与题中一直条件相吻合, 证明了该遗传算法解决问题的效果较好。<br>最终得到最优的基因型为 [1100000000000000000001100100101111110100010100001], 其中 (x) 和 (y) 分别为 0.006485290913897046,0.003113098330086217,此时的值为: 0.01027 。</p><h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5 总结"></a>5 总结</h2><p>在这次实验中, 开始在理解题意方面遇到了很多问题, 后来经过多方询问才明白。这次实验中我通过广泛查询资料了解到了相关的知识, 也认真写代码来完成任务, 这份作业的完成确实比较艰巨, 一份顶多份, 但是我还是有很大的收获, 能力也得到了提升。<br><img src="https://cdn.noedgeai.com/e291bc60-ee22-4de1-aca0-eb54cd5a99af_7.jpg?x=193&y=172&w=415&h=275 "/></p><p>图 2: 函数图</p><img src="https://cdn.noedgeai.com/e291bc60-ee22-4de1-aca0-eb54cd5a99af_7.jpg?x=189&y=643&w=442&h=348 "/><p>图 3: 函数图</p><h2 id="A-程序代码"><a href="#A-程序代码" class="headerlink" title="A 程序代码"></a>A 程序代码</h2><p>遗传算法程序 - GA.py </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> cm</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">DNA_SIZE = <span class="number">24</span></span><br><span class="line">POP_SIZE = <span class="number">200</span></span><br><span class="line">CROSSOVER_RATE = <span class="number">0.8</span></span><br><span class="line">MUTATION_RATE1 = <span class="number">0.03</span></span><br><span class="line">MUTATION_RATE2 = <span class="number">0.001</span></span><br><span class="line">N_GENERATIONS = <span class="number">100</span></span><br><span class="line">arr = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 取值范围</span></span><br><span class="line">X_BOUND = [-<span class="number">5.12</span>, <span class="number">5.12</span>]</span><br><span class="line">Y_BOUND = [-<span class="number">5.12</span>, <span class="number">5.12</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">F</span>(<span class="params">x, y</span>):</span><br><span class="line">    <span class="keyword">return</span> x**<span class="number">2</span> - <span class="number">10</span>* np.cos(<span class="number">2</span>*math.pi*x) + <span class="number">10</span> + y**<span class="number">2</span> - <span class="number">10</span>* np.cos(<span class="number">2</span>*math.pi*y) + <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 画图</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_3D</span>(<span class="params">ax</span>):</span><br><span class="line">    X = np.linspace(*X_BOUND, <span class="number">100</span>)</span><br><span class="line">    Y = np.linspace(*Y_BOUND, <span class="number">100</span>)</span><br><span class="line">    X, Y = np.meshgrid(X, Y)</span><br><span class="line">    Z = F(X, Y)</span><br><span class="line">    ax.plot_surface(X, Y, Z, rstride=<span class="number">1</span>, cstride=<span class="number">1</span>, cmap=cm.coolwarm)</span><br><span class="line">    ax.set_zlim(-<span class="number">10</span>, <span class="number">100</span>)</span><br><span class="line">    ax.set_xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line">    ax.set_zlabel(<span class="string">&#x27;Z&#x27;</span>)</span><br><span class="line">    plt.pause(<span class="number">3</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解码DNA</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">translateDNA</span>(<span class="params">pop</span>):</span><br><span class="line">    x_pop = pop[:, <span class="number">1</span>::<span class="number">2</span>]</span><br><span class="line">    y_pop = pop[:, ::<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    x = x_pop.dot(<span class="number">2</span> ** np.arange(DNA_SIZE)[::-<span class="number">1</span>]) / <span class="built_in">float</span>(<span class="number">2</span> ** DNA_SIZE - <span class="number">1</span>) * (X_BOUND[<span class="number">1</span>] - X_BOUND[<span class="number">0</span>]) + X_BOUND[<span class="number">0</span>]</span><br><span class="line">    y = y_pop.dot(<span class="number">2</span> ** np.arange(DNA_SIZE)[::-<span class="number">1</span>]) / <span class="built_in">float</span>(<span class="number">2</span> ** DNA_SIZE - <span class="number">1</span>) * (Y_BOUND[<span class="number">1</span>] - Y_BOUND[<span class="number">0</span>]) + Y_BOUND[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"><span class="comment"># 适应度</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_fitness</span>(<span class="params">pop</span>):</span><br><span class="line">    x, y = translateDNA(pop)</span><br><span class="line">    pred = F(x, y)</span><br><span class="line">    arr.append(np.<span class="built_in">min</span>(pred))</span><br><span class="line">    <span class="keyword">return</span> - (pred - np.<span class="built_in">max</span>(pred)) + <span class="number">1e-3</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#淘汰机制</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">select</span>(<span class="params">pop, fitness</span>):</span><br><span class="line">    idx = np.random.choice(np.arange(POP_SIZE), size=POP_SIZE, replace=<span class="literal">True</span>, p=fitness/fitness.<span class="built_in">sum</span>())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> pop[idx]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 交叉变异</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">crossover_and_mutation</span>(<span class="params">pop, CROSSOVER_RATE = <span class="number">0.8</span>, MUTATIONS_RATE = <span class="number">0.01</span></span>):</span><br><span class="line">    new_pop = []</span><br><span class="line">    <span class="keyword">for</span> father <span class="keyword">in</span> pop:</span><br><span class="line">        child = father</span><br><span class="line">        <span class="keyword">if</span> np.random.rand() &lt; CROSSOVER_RATE:</span><br><span class="line">            mother = pop[np.random.randint(POP_SIZE)]</span><br><span class="line">            cross_points = np.random.randint(low=<span class="number">0</span>, high=DNA_SIZE*<span class="number">2</span>)</span><br><span class="line">            child[cross_points:] = mother[cross_points:]</span><br><span class="line">        mutation(child, MUTATIONS_RATE)</span><br><span class="line">        new_pop.append(child)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> new_pop</span><br><span class="line"></span><br><span class="line"><span class="comment"># 变异</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mutation</span>(<span class="params">child, MUTATION_RATE</span>):</span><br><span class="line">    <span class="keyword">if</span> np.random.rand() &lt; MUTATION_RATE:  <span class="comment"># 以MUTATION_RATE的概率进行变异</span></span><br><span class="line">        mutate_point = np.random.randint(<span class="number">0</span>, DNA_SIZE)  <span class="comment"># 随机产生一个实数，代表要变异基因的位置</span></span><br><span class="line">        child[mutate_point] = child[mutate_point] ^ <span class="number">1</span>  <span class="comment"># 将变异点的二进制为反转</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">print_info</span>(<span class="params">pop</span>):</span><br><span class="line">    fitness = get_fitness(pop)</span><br><span class="line">    max_fitness_index = np.argmax(fitness)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;max_fitness:&quot;</span>, fitness[max_fitness_index])</span><br><span class="line">    x,y = translateDNA(pop)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;最优的基因型:&quot;</span>, pop[max_fitness_index])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;(x, y ):&#x27;</span>, (x[max_fitness_index], y[max_fitness_index]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;此时的值为:&quot;</span>, F(x[max_fitness_index], y[max_fitness_index]))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = Axes3D(fig)</span><br><span class="line">    plt.ion()</span><br><span class="line">    plot_3D(ax)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 随机生成种群矩阵，奇数列表示X，偶数列表示Y</span></span><br><span class="line">    pop = np.random.randint(<span class="number">2</span>, size=(POP_SIZE, DNA_SIZE * <span class="number">2</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N_GENERATIONS):</span><br><span class="line">        x, y = translateDNA(pop)</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;sca&#x27;</span> <span class="keyword">in</span> <span class="built_in">locals</span>():</span><br><span class="line">            sca.remove()</span><br><span class="line"></span><br><span class="line">        sca = ax.scatter(x, y, F(x, y), c=<span class="string">&#x27;black&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line">        plt.pause(<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> i &lt; <span class="number">7</span>*i/<span class="number">10</span>:</span><br><span class="line">            pop = np.array(crossover_and_mutation(pop, CROSSOVER_RATE, MUTATIONS_RATE = MUTATION_RATE1 ))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            pop = np.array(crossover_and_mutation(pop, CROSSOVER_RATE, MUTATIONS_RATE = MUTATION_RATE2 ))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        fitness = get_fitness(pop)</span><br><span class="line">        pop = select(pop, fitness)</span><br><span class="line"></span><br><span class="line">    print_info(pop)</span><br><span class="line">    plt.ioff()</span><br><span class="line">    plot_3D(ax)</span><br><span class="line"></span><br><span class="line">    x = np.arange(<span class="number">0</span>, <span class="number">101</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;n&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Minimum&#x27;</span>)</span><br><span class="line">    <span class="comment"># plt.ylim((-0.1, 5))  # y坐标的范围</span></span><br><span class="line">    <span class="comment"># 画图</span></span><br><span class="line">    plt.plot(x, arr, <span class="string">&#x27;b&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, markersize=<span class="number">4</span>)</span><br><span class="line">    plt.savefig(<span class="string">&quot;折线图F5_2.png&quot;</span>, dpi=<span class="number">2000</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;目-录&quot;&gt;&lt;a href=&quot;#目-录&quot; class=&quot;headerlink&quot; title=&quot;目 录&quot;&gt;&lt;/a&gt;目 录&lt;/h2&gt;&lt;p&gt;1 背景知识 1&lt;br&gt;1.1 最优化问题 1&lt;br&gt;1.2 进化算法 1&lt;br&gt;1.3 遗传算法的基本知识 1&lt;br&gt;1.3.1 </summary>
      
    
    
    
    <category term="计算智能" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD/"/>
    
    
    <category term="计算智能" scheme="http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>机器学习报告——数据分类的实现</title>
    <link href="http://example.com/2021/04/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%A5%E5%91%8A%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E5%88%86%E7%B1%BB%E7%9A%84%E5%AE%9E%E7%8E%B0/"/>
    <id>http://example.com/2021/04/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%A5%E5%91%8A%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E5%88%86%E7%B1%BB%E7%9A%84%E5%AE%9E%E7%8E%B0/</id>
    <published>2021-04-11T12:29:37.000Z</published>
    <updated>2024-04-09T15:27:47.760Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目-录"><a href="#目-录" class="headerlink" title="目 录"></a>目 录</h2><p>1 数据集 1<br>2 logistic 回归与神经网络 1<br>2.1 背景知识 1<br>2.1.1 线性及 sigmoid 函数 1<br>2.1.2 计算误差及修正参数 1<br>2.2 代码实现及结果分析 2<br>3 高斯判别分析 3<br>3.1 背景知识 3<br>3.2 代码实现 4<br>4 贝叶斯分类 4<br>4.1 背景知识 4<br>4.2 代码实现 4<br>5 性能分析 4<br>6 时效分析 4<br>7 影响因素分析 5<br>7.1 logistic 分类 5<br>8 总结 5<br>A logistic 分类代码 6<br>B GDA 分类代码 8<br>C 贝叶斯分类代码 11<br>D 贝叶斯库函数调用分类代码 12</p><h2 id="1-数据集"><a href="#1-数据集" class="headerlink" title="1 数据集"></a>1 数据集</h2><p>在本次作业中, 在 UCI 中选取了 Sonar 数据集进行分类, 该数据集具有 208 个样本,<br>一共 60 个维度。<br>任务是训练网络以区分反弹的声纳信号从金属圆柱上弹下来和从大致呈圆柱形的岩石弹起。每个模式是一组 60 个数字, 范围在 0.0 到 1.0 之间。每个数字代表在特定时间段内积分的特定频段内的能量。较高频率的积分孔径在时间上较晚出现, 因为这些频率是在线性调频期间稍后传输的。如果对象是岩石,则与每个记录关联的标签包含字母 “ $\mathrm{R}$ ”,如果是地雷 (金属圆柱体) 则包含字母 “M”。标签中的数字按长宽比的高低顺序排列, 但它们不直接对角度进行编码。</p><h2 id="2-logistic-回归与神经网络"><a href="#2-logistic-回归与神经网络" class="headerlink" title="2 logistic 回归与神经网络"></a>2 logistic 回归与神经网络</h2><p>由于 logistic 分类本质为线性求和以及激活函数的作用, 因此这里使用了神经网络框架来实现 logistic 回归, 即神经网络框架只有一个线性层, 然后使用 sigmoid 激活函数, 在结果的判定中对得到的结果进行分类, 即当结果大于 0.5 的时候为一类, 否则为另一类, 即可得出结果, 因此这两种方法同时实现了。</p><h2 id="2-1-背景知识"><a href="#2-1-背景知识" class="headerlink" title="2.1 背景知识"></a>2.1 背景知识</h2><h2 id="2-1-1-线性及-sigmoid-函数"><a href="#2-1-1-线性及-sigmoid-函数" class="headerlink" title="2.1.1 线性及 sigmoid 函数"></a>2.1.1 线性及 sigmoid 函数</h2><p>logistic 分类为一个线性求和和一个 sigmoid 激活组成，假设有一个 $n$ 维的输入列向量 $x$，也有一个 $n$ 维的参数列向量 $h$，还有一个偏置量 $b$ 那么就可以线性求和得到 $z_{\mathrm{s}}$：</p><p>$$<br>z &#x3D; h^T x + b<br>$$</p><p>这个时候值的范围仍是 $({-}\infty, +\infty)$，无法判断出来分类，这个时候就需要一个激活函数来将值进行划分，这里使用的激活函数是 sigmoid 函数：</p><p>$$<br>\sigma(x) &#x3D; \frac{1}{1 + e^{-x}}<br>$$</p><p>其导数有以下规律：</p><p>$$<br>\sigma’(x) &#x3D; \sigma(x)(1 - \sigma(x))<br>$$</p><p>其图像如下图所示：</p><p>$$<br>a &#x3D; \sigma(z) &#x3D; \sigma\left( h^T x + b \right)<br>$$</p><p>这样进行判别，当 $a$ 大于 0.5 的时候，可以判定 $x$ 属于一类，否则属于另一类，即可进行分类。</p><h2 id="2-1-2-计算误差及修正参数"><a href="#2-1-2-计算误差及修正参数" class="headerlink" title="2.1.2 计算误差及修正参数"></a>2.1.2 计算误差及修正参数</h2><p>在凸优化问题中, 可以通过导数为零进行计算。</p>\[\frac{\partial C}{\partial h} = 0, \quad \frac{\partial C}{\partial b} = 0\]<img src="https://cdn.noedgeai.com/d053b280-ea92-40ab-9212-b8dc526c4b19_3.jpg?x=158&y=61&w=520&h=338 "/><p>图 1: sigmoid 函数图像</p><p>这种直接的计算在小规模情况下可行, 但在大规模数据以及非凸优化的情况下, 采用迭代的方法得到局部最优解的方式更加可行，即如下方法：</p><p>$$<br>h &#x3D; h - \eta \frac{\partial C}{\partial h}<br>$$</p><p>$$<br>b &#x3D; b - \eta \frac{\partial C}{\partial b}<br>$$</p><p>其中 $\eta$ 表示学习率，这里损失函数可以使用平方差损失。即 $C &#x3D; \frac{1}{2}(a - y)$，并进行迭代，即可求出结果。</p><h2 id="2-2-代码实现及结果分析"><a href="#2-2-代码实现及结果分析" class="headerlink" title="2.2 代码实现及结果分析"></a>2.2 代码实现及结果分析</h2><p>这里首先导入数据并将标签进行二值化, 然后利用 sklearn 来将数据进行划分, 得到训练集以及测试集。随后定义网络结构, 即仅有一个线性层并使用 sigmoid 激活函数的神经网络, 并将特征设置为数据的维度, 之后分别定义训练函数以及测试函数。然后将上文划分好的测试集以及训练集利用 TensorDataset 以及 DataLoader 得到可以送入神经网络的迭代器, 定义损失函数使用均方损失, 优化器这里使用了著名的不需要调参数的 Adadelta, 因为之前使用 SGD 的时候结果在参数调整不合适的情况会出现很大问题。最后训练并测试结果, 并将其可视化出来, 得到结果如下图所示:<br>又上图可知, 随着迭代次数的增多, 损失在不断下降, 而训练的精度则为先升后降的趋势,最高可以达到 (83%) 的精度。因为随着迭代次数过多,出现了过拟合的情况,使得模型在训练数据中取得的误差更小, 但是在测试数据中准确率反而不够高, 这也反映了仅使用线性网络可能导致的结果问题, 可以通过调整结果正则化以及控制迭代次数等方法来提高模型的性能。</p><img src="https://cdn.noedgeai.com/d053b280-ea92-40ab-9212-b8dc526c4b19_4.jpg?x=133&y=64&w=574&h=239 "/><p>图 2: logistic 分类结果</p><h2 id="3-高斯判别分析"><a href="#3-高斯判别分析" class="headerlink" title="3 高斯判别分析"></a>3 高斯判别分析</h2><h2 id="3-1-背景知识"><a href="#3-1-背景知识" class="headerlink" title="3.1 背景知识"></a>3.1 背景知识</h2><p>高斯判别分析是一个比较直观的模型, 一个基本的假设就是得到的数据是独立同分布<br>的, 虽然这种假设在实际中很难达到, 但是在有了好的假设后可以得到较好的结果。<br>一维正态分布为:</p><p>$$<br>f(x) &#x3D; \frac{1}{\sqrt{2\pi}\sigma} \exp \left( -\frac{(x - \mu)^2}{2\sigma^2} \right)<br>$$</p><p>其中 $x$ 为样本特征, $\sigma$ 为标准差, $\mu$ 为样本期望值，并将该分布记为 $N(\mu, \sigma^2)$，当 $\mu &#x3D; 0$，$\sigma &#x3D; 1$ 时候的正态分布是标准正态分布。</p><p>$n$ 维正态分布表示为：</p><p>$$<br>p(x; \mu, \Sigma) &#x3D; \frac{1}{(2\pi)^{n&#x2F;2} |\Sigma|^{1&#x2F;2}} \exp\left( -\frac{1}{2} (x - \mu)^T \Sigma^{-1} (x - \mu) \right)<br>$$</p><p>其中 (p(x; \mu, \Sigma)) 中的 (\mu, \Sigma) 分别表示均值向量以及协方差矩阵。</p><p>将 (n) 维高斯分布应用到监督学习中，假设输入数据为 (x)，输出类别为 (y \in {0,1})，则对应分类问题可以描述为：</p><p>$$<br>y \approx \operatorname{Bernoulli}(\phi)<br>$$</p><p>$$<br>x | y &#x3D; 0 \approx \mathcal{N}(\mu_0, \Sigma)<br>$$</p><p>$$<br>x | y &#x3D; 1 \approx \mathcal{N}(\mu_1, \Sigma)<br>$$</p><p>其中 Bernoulli((\phi)) 表示伯努利分布，通过推导可以得出样本分类的依据：</p><p>$$<br>p(y | x) &#x3D; \frac{p(x | y) p(y)}{p(x)}<br>$$</p><p>$$<br>y &#x3D; \underset{y}{\arg\max} , p(y | x)<br>$$</p><p>$$<br>&#x3D; \underset{y}{\arg\max} , p(x | y) p(y)<br>$$</p><h2 id="3-2-代码实现"><a href="#3-2-代码实现" class="headerlink" title="3.2 代码实现"></a>3.2 代码实现</h2><p>首先求出训练数据的均值向量以及协方差矩阵, 然后利用公式分布求出正负样本的概<br>率,最后将测试数据传入并与实际结果对比,得出准确率为 (75.00%) 。</p><h2 id="4-贝叶斯分类"><a href="#4-贝叶斯分类" class="headerlink" title="4 贝叶斯分类"></a>4 贝叶斯分类</h2><h2 id="4-1-背景知识"><a href="#4-1-背景知识" class="headerlink" title="4.1 背景知识"></a>4.1 背景知识</h2><p>贝叶斯分类是一类分类算法的总称, 一类算法以贝叶斯定理为基础, 统称为贝叶斯分类。朴素贝叶斯是贝叶斯分类中最简单常见的一种分类方法。理论上朴素贝叶斯模型比其他分类方法误差率更小, 但是由于朴素贝叶斯模型假设属性之间相互独立, 但是这个假设在实际中往往不成立, 在属性个数多或者属性相关性较大的时候, 分类效果差。朴素贝叶斯逻辑简单, 易于实现, 而且分类过程中开销比较小, 其核心算法是贝叶斯公式:<br>[P(B {\mid} A) &#x3D; \frac{P(A {\mid} B)P(B)}{P(A)}]<br>其中 (A) 为特征, (B) 为类别。</p><h2 id="4-2-代码实现"><a href="#4-2-代码实现" class="headerlink" title="4.2 代码实现"></a>4.2 代码实现</h2><p>这里首先定义一个 gaussion_pdf 函数,这个函数的作用就是利用 (n) 维正态分布的公式,从而求得 (n) 维正态分布的分布情况,从而为预测函数提供概率基础,然后定义一个预测函数 predict,利用 numpy 的 unique 求得分类数,并对每一类分布,求得 (P(y)) 以及 (P(x {\mid} y)) ,最后将测试集传入,并与测试集的标签对比得出结果。<br>经过实践,得到准确率为 (63.46%) 。</p><h2 id="5-性能分析"><a href="#5-性能分析" class="headerlink" title="5 性能分析"></a>5 性能分析</h2><p>从性能上来说, 贝叶斯分类开销比较小, 而 logistic 神经网络法则比较大, 这是因为神经网络使用的空间等相对较大, 而贝叶斯由于采用的仅为样本空间, 因此性能相对较好。<br>从结果来说, (\operatorname{logistic}) 分类的结果在迭代次数合适的时候可以达到 (80%) 以上,高斯判别<br>分析可以达到 (75%) ,贝叶斯分类的准确率为 (63.46%) ,因此 logistic 效果最好。</p><h2 id="6-时效分析"><a href="#6-时效分析" class="headerlink" title="6 时效分析"></a>6 时效分析</h2><p>代码中已经利用了库函数 <code>time</code> 来计算程序运行的时间, 经过测试, logistic 分类经过 100 次迭代使用的时间为 $2.35\mathrm{\ s}$ ,而高斯判别分析用时为 $0.02\mathrm{\ s}$ ,贝叶斯分类用时 $0.01\mathrm{\ s}$ ,调用的贝叶斯分类函数,其用时同样为 $0.01\mathrm{\ s}$ 。<br>从时间上来说, 采用神经网络的 logistic 分类使用的轮次较多, 平均下来, 每训练一轮为 $0.02\mathrm{\ s}$ ,与高斯判别分析时间近似相等,两者都差于贝叶斯分类,自己时间的贝叶斯与库函数实现的贝叶斯时间上相差不大。<br>对于时间, logistic 分类每一轮都遍历一遍样本, 贝叶斯分类只遍历一次样本, 高斯判别分析需要便利每个样本的每个特征。<br>对于空间, logistic 分类只需用一个样本的空间, 贝叶斯分类需要有数据的类别空间, 高斯判别分析需要有正负样本的存储空间。<br>表 1: 时效分析</p><table><thead><tr><th></th><th>logistic 分类</th><th>贝叶斯分类</th><th>GDA 分类</th></tr></thead><tbody><tr><td>时间复杂度</td><td>$\theta(m \cdot k)$</td><td>$\theta(m)$</td><td>$\theta(m \cdot d)$</td></tr><tr><td>空间复杂度</td><td>$\theta(d)$</td><td>$\theta(d \cdot K)$</td><td>$\theta(d^{2})$</td></tr></tbody></table><p>其中 $m$ 为样本数, $d$ 为特征维数, $k$ 为迭代次数。</p><h2 id="7-影响因素分析"><a href="#7-影响因素分析" class="headerlink" title="7 影响因素分析"></a>7 影响因素分析</h2><h2 id="7-1-logistic-分类"><a href="#7-1-logistic-分类" class="headerlink" title="7.1 logistic 分类"></a>7.1 logistic 分类</h2><p>在这个方法中, 我在写的过程中遇到的一个问题就是优化器的选取, 在开始使用 SGD 的时候, 损失在很短的时间就达到很大, 显示出 nan, 经过多次尝试才明白出问题的地方, 修改后, 效果较好。</p><h2 id="8-总结"><a href="#8-总结" class="headerlink" title="8 总结"></a>8 总结</h2><p>在这次的机器学习大作业中我收获很大, 这次的作用并不容易, 不仅仅要完成三个方法的分类任务, 一个重要方面是对方法的分析, 包括性能分析, 时效分析等, 这也是对能力的一次锻炼, 收获很大。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] 详解朴素贝叶斯分类算法 <a href="https://blog.csdn.net/ccblogger/article/details/81712351">https://blog.csdn.net/ccblogger/article/details/81712351</a>? ivk_sa&#x3D;1024320u</p><p>[2] <a href="https://www.cnblogs.com/phoenixzq/p/3539619.html">贝叶斯分类</a> </p><p>[3] <a href="https://zhuanlan.zhihu.com/p/38269530">高斯判别分析</a></p><h2 id="A-logistic-分类代码"><a href="#A-logistic-分类代码" class="headerlink" title="A logistic 分类代码"></a>A logistic 分类代码</h2><ul><li>logistic 分类.py</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Created on Sat Apr 10 16:56:09 2021</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: tremble</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">start=time.time()</span><br><span class="line">file=pd.read_csv(<span class="string">&#x27;D:/桌面/sonar.csv&#x27;</span>,header=<span class="literal">None</span>)</span><br><span class="line">data=file.iloc[:,:<span class="number">40</span>]</span><br><span class="line">target=file.iloc[:,-<span class="number">1</span>]</span><br><span class="line">data=np.array(data,dtype=<span class="built_in">float</span>)</span><br><span class="line">target=pd.get_dummies(target).iloc[:,<span class="number">0</span>]</span><br><span class="line">data=torch.tensor(data,dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">target=torch.tensor(target,dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">x_train,x_test,y_train,y_test=train_test_split(data,\</span><br><span class="line">    target,test_size=<span class="number">0.25</span>,random_state=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">logistic_net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,features</span>):</span><br><span class="line">        <span class="built_in">super</span>(logistic_net,self).__init__()</span><br><span class="line">        self.linear=nn.Linear(features,<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x=self.linear(x)</span><br><span class="line">        x=torch.sigmoid(x)</span><br><span class="line">        x = x.squeeze(-<span class="number">1</span>)    </span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">model=logistic_net(<span class="number">40</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model, train_loader, optimizer, epoch, criterion</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(data)</span><br><span class="line">        loss = criterion(output, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                epoch, i * <span class="built_in">len</span>(data), <span class="built_in">len</span>(train_loader.dataset),</span><br><span class="line">                       <span class="number">100.</span> * i / <span class="built_in">len</span>(train_loader), loss.item()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">model,test_loader, criterion</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">            pred=torch.Tensor(<span class="built_in">len</span>(target),<span class="number">1</span>)</span><br><span class="line">            output = model(data)</span><br><span class="line">            test_loss += criterion(output, target).item()  <span class="comment"># sum up batch loss</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(target)):</span><br><span class="line">                <span class="keyword">if</span> output[i]&gt;<span class="number">0.5</span>:</span><br><span class="line">                    pred[i]=torch.tensor(<span class="number">1</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    pred[i]=torch.tensor(<span class="number">0</span>)</span><br><span class="line">            <span class="comment">#pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability</span></span><br><span class="line">            correct += pred.eq(target.view_as(pred)).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">    test_loss /= <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        test_loss, correct, <span class="built_in">len</span>(test_loader.dataset),</span><br><span class="line">        <span class="number">100.</span> * correct / <span class="built_in">len</span>(test_loader.dataset)))</span><br><span class="line">    <span class="keyword">return</span> test_loss,<span class="number">100.</span> * correct / <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">trainset=torch.utils.data.TensorDataset(x_train,y_train)</span><br><span class="line">testset=torch.utils.data.TensorDataset(x_test,y_test)</span><br><span class="line">trainloader=torch.utils.data.DataLoader(trainset,batch_size=<span class="number">4</span>,shuffle=<span class="literal">True</span>)</span><br><span class="line">testloader=torch.utils.data.DataLoader(testset,batch_size=<span class="number">4</span>,shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = optim.Adadelta(model.parameters(), lr=<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">epoch_list,ls_list,accuracy_list=[],[],[]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">100</span>):</span><br><span class="line">    train(model,trainloader, optimizer, epoch, criterion)</span><br><span class="line">    ls,accuracy=test(model, testloader, criterion)</span><br><span class="line">    epoch_list.append(epoch)</span><br><span class="line">    ls_list.append(ls)</span><br><span class="line">    accuracy_list.append(accuracy)</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">10</span>,<span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">121</span>)</span><br><span class="line">plt.plot(epoch_list,ls_list,linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">122</span>)</span><br><span class="line">plt.plot(epoch_list,accuracy_list,linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch &#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;用时&#123;:.2f&#125;s&#x27;</span>.<span class="built_in">format</span>(time.time()-start))</span><br></pre></td></tr></table></figure><h2 id="B-GDA-分类代码"><a href="#B-GDA-分类代码" class="headerlink" title="B GDA 分类代码"></a>B GDA 分类代码</h2><ul><li>GDA 分类.py</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Created on Sat Apr 10 18:11:49 2021</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: tremble</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> time </span><br><span class="line"></span><br><span class="line">start=time.time()</span><br><span class="line">file=pd.read_csv(<span class="string">&#x27;D:/桌面/sonar.csv&#x27;</span>,header=<span class="literal">None</span>)</span><br><span class="line">data=file.iloc[:,:<span class="number">40</span>]</span><br><span class="line">target=file.iloc[:,-<span class="number">1</span>]</span><br><span class="line">data=np.array(data,dtype=<span class="built_in">float</span>)</span><br><span class="line">target=pd.get_dummies(target).iloc[:,<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">x_train,x_test,y_train,y_test=train_test_split(data,\</span><br><span class="line">                target,test_size=<span class="number">0.25</span>,random_state=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">positive_data=[]</span><br><span class="line">negative_data=[]</span><br><span class="line">positive_num=<span class="number">0</span></span><br><span class="line">negative_num=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> (data,label)<span class="keyword">in</span> <span class="built_in">zip</span>(x_train,y_train):</span><br><span class="line">    <span class="keyword">if</span> label ==<span class="number">1</span>:</span><br><span class="line">        positive_data.append(<span class="built_in">list</span>(data))</span><br><span class="line">        positive_num+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        negative_data.append(<span class="built_in">list</span>(data))</span><br><span class="line">        negative_num+=<span class="number">1</span></span><br><span class="line">        </span><br><span class="line">row,col=np.shape(x_train)   </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">positive=positive_num*<span class="number">1.0</span>/row</span><br><span class="line">negative=<span class="number">1</span>-positive</span><br><span class="line">        </span><br><span class="line">positive_data=np.array(positive_data)</span><br><span class="line">negative_data=np.array(negative_data)        </span><br><span class="line">mean_positive=np.mean(positive_data,axis=<span class="number">0</span>)       </span><br><span class="line">mean_negative=np.mean(negative_data,axis=<span class="number">0</span>)        </span><br><span class="line">positive_deta=positive_data-mean_positive</span><br><span class="line">negative_deta=negative_data-mean_negative        </span><br><span class="line">        </span><br><span class="line">sigma=[]</span><br><span class="line"><span class="keyword">for</span> deta <span class="keyword">in</span> positive_deta:</span><br><span class="line">    deta=deta.reshape(<span class="number">1</span>,col)</span><br><span class="line">    ans = deta.T.dot(deta)</span><br><span class="line">    sigma.append(ans)</span><br><span class="line"><span class="keyword">for</span> deta <span class="keyword">in</span> negative_deta:</span><br><span class="line">    deta=deta.reshape(<span class="number">1</span>,col)</span><br><span class="line">    ans = deta.T.dot(deta)</span><br><span class="line">    sigma.append(ans)</span><br><span class="line">sigma=np.array(sigma)</span><br><span class="line">sigma=np.mean(sigma,axis=<span class="number">0</span>)        </span><br><span class="line">        </span><br><span class="line">mean_positive=mean_positive.reshape(<span class="number">1</span>,col)</span><br><span class="line">mean_negative=mean_negative.reshape(<span class="number">1</span>,col)        </span><br><span class="line">        </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Gaussian</span>(<span class="params">x,mean,cov</span>):</span><br><span class="line">    dim=np.shape(cov)[<span class="number">0</span>]</span><br><span class="line">    covdet = np.linalg.det(cov + np.eye(dim) * <span class="number">0.001</span>)</span><br><span class="line">    covinv = np.linalg.inv(cov + np.eye(dim) * <span class="number">0.001</span>)</span><br><span class="line">    xdiff = (x - mean).reshape((<span class="number">1</span>, dim))</span><br><span class="line">    prob = <span class="number">1.0</span> / (np.power(np.power(<span class="number">2</span> * np.pi, dim) *\</span><br><span class="line">                           np.<span class="built_in">abs</span>(covdet), <span class="number">0.5</span>)) * \</span><br><span class="line">    np.exp(-<span class="number">0.5</span> * xdiff.dot(covinv).dot(xdiff.T))[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> prob        </span><br><span class="line">        </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">x_test,mean_positive,mean_negetive</span>):</span><br><span class="line">    predict_label=[]</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> x_test:</span><br><span class="line">        positive_pro=Gaussian(data, mean_positive, sigma)</span><br><span class="line">        negative_pro=Gaussian(data, mean_negetive, sigma)</span><br><span class="line">        <span class="keyword">if</span> positive_pro&gt;=negative_pro:</span><br><span class="line">            predict_label.append(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            predict_label.append(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> predict_label        </span><br><span class="line">        </span><br><span class="line">test_predict=predict(x_test,mean_positive,mean_negative)        </span><br><span class="line">        </span><br><span class="line">test_predict=np.array(test_predict)</span><br><span class="line">y_test=np.array(y_test)        </span><br><span class="line">        </span><br><span class="line">accuracy=(test_predict==y_test).<span class="built_in">sum</span>().item()/<span class="built_in">len</span>(y_test)        </span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;用时&#123;:.2f&#125;s,准确率为&#123;:.2f&#125;%&#x27;</span>.\</span><br><span class="line">      <span class="built_in">format</span>(time.time()-start,accuracy*<span class="number">100.0</span>))        </span><br></pre></td></tr></table></figure><h2 id="C-贝叶斯分类代码"><a href="#C-贝叶斯分类代码" class="headerlink" title="C 贝叶斯分类代码"></a>C 贝叶斯分类代码</h2><ul><li>贝叶斯分类.py<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Created on Sat Apr 10 18:36:49 2021</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: tremble</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">start=time.time()</span><br><span class="line">file=pd.read_csv(<span class="string">&#x27;D:/桌面/sonar.csv&#x27;</span>,header=<span class="literal">None</span>)</span><br><span class="line">data=file.iloc[:,:<span class="number">40</span>]</span><br><span class="line">target=file.iloc[:,-<span class="number">1</span>]</span><br><span class="line">data=np.array(data,dtype=<span class="built_in">float</span>)</span><br><span class="line">target=pd.get_dummies(target).iloc[:,<span class="number">0</span>]</span><br><span class="line">data=np.array(data,dtype=<span class="built_in">float</span>)</span><br><span class="line">target=np.array(target,dtype=<span class="built_in">float</span>)</span><br><span class="line">x_train,x_test,y_train,y_test=train_test_split(data,\</span><br><span class="line">            target,test_size=<span class="number">0.25</span>,random_state=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gaussion_pdf</span>(<span class="params">x_test, x</span>):</span><br><span class="line">        temp1 = (x_test - x.mean(<span class="number">0</span>)) * (x_test - x.mean(<span class="number">0</span>))</span><br><span class="line">        temp2 = x.std(<span class="number">0</span>) * x.std(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> np.exp(-temp1 / (<span class="number">2</span> * temp2)) / np.sqrt(<span class="number">2</span> * np.pi * temp2)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">x_train,y_train,x_test</span>):</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(x_test.shape) == <span class="number">2</span></span><br><span class="line">        classes = np.unique(y_train)</span><br><span class="line">        pred_probs = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> classes:</span><br><span class="line">            idx_i = y_train == i</span><br><span class="line">            p_y = <span class="built_in">len</span>(idx_i) / <span class="built_in">len</span>(y_train)</span><br><span class="line">            p_x_y = np.prod(gaussion_pdf(x_test,x_train[idx_i]), <span class="number">1</span>)</span><br><span class="line">            prob_i = p_y * p_x_y</span><br><span class="line">            pred_probs.append(prob_i)</span><br><span class="line">        pred_probs = np.vstack(pred_probs)</span><br><span class="line">        label_idx = pred_probs.argmax(<span class="number">0</span>)</span><br><span class="line">        y_pred = classes[label_idx]</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line">    </span><br><span class="line">y_predict=predict(x_train,y_train,x_test)</span><br><span class="line"></span><br><span class="line">accuracy=(y_predict==y_test).<span class="built_in">sum</span>().item()/<span class="built_in">len</span>(y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;准确率为&#123;:.2f&#125;%,用时&#123;:.2f&#125;s&#x27;</span>.<span class="built_in">format</span>(accuracy*<span class="number">100.0</span>,\</span><br><span class="line">                                     time.time()-start))</span><br></pre></td></tr></table></figure></li></ul><h2 id="D-贝叶斯库函数调用分类代码"><a href="#D-贝叶斯库函数调用分类代码" class="headerlink" title="D 贝叶斯库函数调用分类代码"></a>D 贝叶斯库函数调用分类代码</h2><ul><li>贝叶斯调用实现.py<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Created on Sat Apr 10 19:53:00 2021</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: tremble</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">start=time.time()</span><br><span class="line">file=pd.read_csv(<span class="string">&#x27;D:/桌面/sonar.csv&#x27;</span>,header=<span class="literal">None</span>)</span><br><span class="line">data=file.iloc[:,:<span class="number">40</span>]</span><br><span class="line">target=file.iloc[:,-<span class="number">1</span>]</span><br><span class="line">data=np.array(data,dtype=<span class="built_in">float</span>)</span><br><span class="line">target=pd.get_dummies(target).iloc[:,<span class="number">0</span>]</span><br><span class="line">data=np.array(data,dtype=<span class="built_in">float</span>)</span><br><span class="line">target=np.array(target,dtype=<span class="built_in">float</span>)</span><br><span class="line">x_train,x_test,y_train,y_test=train_test_split(data,\</span><br><span class="line">            target,test_size=<span class="number">0.25</span>,random_state=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = GaussianNB()</span><br><span class="line">model.fit(x_train,y_train)</span><br><span class="line">test_predict_model = model.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;逻辑回归的正确率为：&#123;:.2f&#125;%,用时为&#123;:.2f&#125;s&quot;</span>.\</span><br><span class="line">      <span class="built_in">format</span>(accuracy_score(y_test,\</span><br><span class="line">        test_predict_model)*<span class="number">100.0</span>,time.time() - start))</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;目-录&quot;&gt;&lt;a href=&quot;#目-录&quot; class=&quot;headerlink&quot; title=&quot;目 录&quot;&gt;&lt;/a&gt;目 录&lt;/h2&gt;&lt;p&gt;1 数据集 1&lt;br&gt;2 logistic 回归与神经网络 1&lt;br&gt;2.1 背景知识 1&lt;br&gt;2.1.1 线性及 sigmoid</summary>
      
    
    
    
    <category term="机器学习" scheme="http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>记录我的第一次搭建博客</title>
    <link href="http://example.com/2020/10/31/%E8%AE%B0%E5%BD%95%E7%AC%AC%E4%B8%80%E6%AC%A1%E6%90%AD%E5%8D%9A%E5%AE%A2/"/>
    <id>http://example.com/2020/10/31/%E8%AE%B0%E5%BD%95%E7%AC%AC%E4%B8%80%E6%AC%A1%E6%90%AD%E5%8D%9A%E5%AE%A2/</id>
    <published>2020-10-31T00:00:00.000Z</published>
    <updated>2024-04-09T15:27:47.760Z</updated>
    
    <content type="html"><![CDATA[<h1 id="艰难的第一次搭博客"><a href="#艰难的第一次搭博客" class="headerlink" title="艰难的第一次搭博客"></a>艰难的第一次搭博客</h1><p>其实我在很早之前就想搭博客，大概大一开始的时候，就想着做一些有意义，有兴趣的事，结果一直拖到了现在才开始真正意义上的实践，我也是趁着这次对大一的培训搭建博客，顺便才开始做，看上去不是很难的一件事，实际去做，我却遇到了很多困难，就光配置markdown的front-matter的时候，因为不知道里面还有其他东西，就一直报错，而且和其他一起弄的，我还找不到原因，就导致我花了很大的时间，最后遇到的一个问题是图片的在线存储问题，最后用的码云的仓库来放的，最后头像也解决了，我才能说，我基本才算是搭建成了一个基本的框架。<br>哎，之前跟现在相比，其实并不忙的，但也是懒，还有各种找的原因，结果到现在，对这样搭博客的基本知识都还都不太了解，有点小愧疚，以后还是得加把劲了。<br>现在还有一堆大作业要去写，剩下的时间也不多了，就先这样吧。</p>]]></content>
    
    
    <summary type="html">我太难了</summary>
    
    
    
    <category term="生活" scheme="http://example.com/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
    <category term="记录生活" scheme="http://example.com/tags/%E8%AE%B0%E5%BD%95%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
</feed>
